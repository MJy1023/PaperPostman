[
  {
    "id": null,
    "title": "#1Generalized Linear Mode Connectivity for Transformers[PDF193][Copy][Kimi229][REL]",
    "authors": [
      "Authors:\n                Alexander Theus",
      "Alessandro Cabodi",
      "Sotiris Anagnostidis",
      "Antonio Orvieto",
      "Sidak Pal Singh",
      "Valentina Boeva"
    ],
    "affiliations": [],
    "summary": "Authors:Alexander Theus,Alessandro Cabodi,Sotiris Anagnostidis,Antonio Orvieto,Sidak Pal Singh,Valentina Boeva",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#2Deep Compositional Phase Diffusion for Long Motion Sequence Generation[PDF92][Copy][Kimi95][REL]",
    "authors": [
      "Authors:\n                Ho Yin Au",
      "Jie Chen",
      "Junkun Jiang",
      "Jingyu Xiang"
    ],
    "affiliations": [],
    "summary": "Recent research on motion generation has shown significant progress in generating semantically aligned motion with singular semantics. However, when employing these models to create composite sequences containing multiple semantically generated motion clips, they often struggle to preserve the continuity of motion dynamics at the transition boundaries between clips, resulting in awkward transitions and abrupt artifacts. To address these challenges, we present Compositional Phase Diffusion, which leverages the Semantic Phase Diffusion Module (SPDM) and Transitional Phase Diffusion Module (TPDM) to progressively incorporate semantic guidance and phase details from adjacent motion clips into the diffusion process. Specifically, SPDM and TPDM operate within the latent motion frequency domain established by the pre-trained Action-Centric Motion Phase Autoencoder (ACT-PAE). This allows them to learn semantically important and transition-aware phase information from variable-length motion clips during training. Experimental results demonstrate the competitive performance of our proposed framework in generating compositional motion sequences that align semantically with the input conditions, while preserving phase transitional continuity between preceding and succeeding motion clips. Additionally, motion inbetweening task is made possible by keeping the phase parameter of the input motion sequences fixed throughout the diffusion process, showcasing the potential for extending the proposed framework to accommodate various application scenarios. Codes are available at https://github.com/asdryau/TransPhase.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#3GnnXemplar: Exemplars to Explanations - Natural Language Rules for Global GNN Interpretability[PDF44][Copy][Kimi52][REL]",
    "authors": [
      "Authors:\n                Burouj Armgaan",
      "Eshan Jain",
      "Harsh Pandey",
      "Mahesh Chandran",
      "Sayan Ranu"
    ],
    "affiliations": [],
    "summary": "Graph Neural Networks (GNNs) are widely used for node classification, yet their opaque decision-making limits trust and adoption. While local explanations offer insights into individual predictions, global explanation methods—those that characterize an entire class—remain underdeveloped. Existing global explainers rely on motif discovery in small graphs, an approach that breaks down in large, real-world settings where subgraph repetition is rare, node attributes are high-dimensional, and predictions arise from complex structure-attribute interactions. We propose GnnXemplar, a novel global explainer inspired from Exemplar Theory from cognitive science. GnnXemplar identifies representative nodes in the GNN embedding space—exemplars—and explains predictions using natural language rules derived from their neighborhoods. Exemplar selection is framed as a coverage maximization problem over reverse $k$-nearest neighbors, for which we provide an efficient greedy approximation. To derive interpretable rules, we employ a self-refining prompt strategy using large language models (LLMs). Experiments across diverse benchmarks show that GnnXemplar significantly outperforms existing methods in fidelity, scalability, and human interpretability, as validated by a user study with 60 participants.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#6Learning Linear Attention in Polynomial Time[PDF62][Copy][Kimi72][REL]",
    "authors": [
      "Authors:\n                Morris Yau",
      "Ekin Akyürek",
      "Jiayuan Mao",
      "Joshua B. Tenenbaum",
      "Stefanie Jegelka",
      "Jacob Andreas"
    ],
    "affiliations": [],
    "summary": "Previous research has explored the expressivity of Transformer models in simulating Boolean circuits or Turing machines. However, the efficient learnability of Transformers from data has remained an open question. Our study addresses this gap by providing the first polynomial-time learnability results (specifically strong, agnostic PAC learning) for single-layer Transformers with linear attention. We show that learning the optimal multi head linear attention can be recast as finding the optimal kernel predictor in a suitably defined RKHS. Moving to generalization, we construct an algorithm that, given a dataset, checks in polynomial time whether the set of best fit multi head linear attention networks on this data all perform an identical computation--a powerful notion for out of distribution generalization. We empirically validate our theoretical findings on several canonical tasks: learning random linear attention networks, key--value associations, and learning to execute finite automata. Our findings bridge a critical gap between theoretical expressivity and learnability of Transformer models.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#8State Entropy Regularization for Robust Reinforcement Learning[PDF37][Copy][Kimi50][REL]",
    "authors": [
      "Authors:\n                Yonatan Ashlag",
      "Uri Koren",
      "Mirco Mutti",
      "Esther Derman",
      "Pierre-Luc Bacon",
      "Shie Mannor"
    ],
    "affiliations": [],
    "summary": "State entropy regularization has empirically shown better exploration and sample complexity in reinforcement learning (RL). However, its theoretical guarantees have not been studied. In this paper, we show that state entropy regularization improves robustness to structured and spatially correlated perturbations. These types of variation are common in transfer learning but often overlooked by standard robust RL methods, which typically focus on small, uncorrelated changes. We provide a comprehensive characterization of these robustness properties, including formal guarantees under reward and transition uncertainty, as well as settings where the method performs poorly. Much of our analysis contrasts state entropy with the widely used policy entropy regularization, highlighting their different benefits. Finally, from a practical standpoint, we illustrate that compared with policy entropy, the robustness advantages of state entropy are more sensitive to the number of rollouts used for policy evaluation.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#9On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity[PDF36][Copy][Kimi38][REL]",
    "authors": [
      "Authors:\n                Quentin Bertrand",
      "Anne Gagneux",
      "Mathurin Massias",
      "Rémi Emonet"
    ],
    "affiliations": [],
    "summary": "Modern deep generative models can now produce high-quality synthetic samples that are often indistinguishable from real training data. A growing body of research aims to understand why recent methods, such as diffusion and flow matching techniques, generalize so effectively. Among the proposed explanations are the inductive biases of deep learning architectures and the stochastic nature of the conditional flow matching loss. In this work, we rule out the noisy nature of the loss as a key factor driving generalization in flow matching. First, we empirically show that in high-dimensional settings, the stochastic and closed-form versions of the flow matching loss yield nearly equivalent losses. Then, using state-of-the-art flow matching models on standard image datasets, we demonstrate that both variants achieve comparable statistical performance, with the surprising observation that using the closed-form can even improve performance.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#10Why Diffusion Models Don’t Memorize: The Role of Implicit Dynamical Regularization in Training[PDF52][Copy][Kimi43][REL]",
    "authors": [
      "Authors:\n                Tony Bonnaire",
      "Raphaël Urfin",
      "Giulio Biroli",
      "Marc Mezard"
    ],
    "affiliations": [],
    "summary": "Diffusion models have achieved remarkable success across a wide range of generative tasks. A key challenge is understanding the mechanisms that prevent their memorization of training data and allow generalization. In this work, we investigate the role of the training dynamics in the transition from generalization to memorization. Through extensive experiments and theoretical analysis, we identify two distinct timescales: an early time $\\tau_\\mathrm{gen}$ at which models begin to generate high-quality samples, and a later time $\\tau_\\mathrm{mem}$ beyond which memorization emerges. Crucially, we find that $\\tau_\\mathrm{mem}$ increases linearly with the training set size $n$, while $\\tau_\\mathrm{gen}$ remains constant. This creates a growing window of training times with $n$ where models generalize effectively, despite showing strong memorization if training continues beyond it. It is only when $n$ becomes larger than a model-dependent threshold that overfitting disappears at infinite training times. These findings reveal a form of implicit dynamical regularization in the training dynamics, which allow to avoid memorization even in highly overparameterized settings. Our results are supported by numerical experiments with standard U-Net architectures on realistic and synthetic datasets, and by a theoretical analysis using a tractable random features model studied in the high-dimensional limit.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#11Adjoint Schrödinger Bridge Sampler[PDF26][Copy][Kimi28][REL]",
    "authors": [
      "Authors:\n                Guan-Horng Liu",
      "Jaemoo Choi",
      "Yongxin Chen",
      "Benjamin Kurt Miller",
      "Ricky T. Q. Chen"
    ],
    "affiliations": [],
    "summary": "Computational methods for learning to sample from the Boltzmann distribution—where the target distribution is known only up to an unnormalized energy function—have advanced significantly recently. Due to the lack of explicit target samples, however, prior diffusion-based methods, known as _diffusion samplers_, often require importance-weighted estimation or complicated learning processes. Both trade off scalability with extensive evaluations of the energy and model, thereby limiting their practical usage. In this work, we propose **Adjoint Schrödinger Bridge Sampler (ASBS)**, a new diffusion sampler that employs simple and scalable matching-based objectives yet without the need to estimate target samples during training. ASBS is grounded on a mathematical model—the Schrödinger Bridge—which enhances sampling efficiency via kinetic-optimal transportation. Through a new lens of stochastic optimal control theory, we demonstrate how SB-based diffusion samplers can be learned at scale via Adjoint Matching and prove convergence to the global solution. Notably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to arbitrary source distributions by relaxing the so-called memoryless condition that largely restricts the design space. Through extensive experiments, we demonstrate the effectiveness of ASBS on sampling from classical energy functions, amortized conformer generation, and molecular Boltzmann distributions. Codes are available at https://github.com/facebookresearch/adjoint_samplers",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#12Breaking the Performance Ceiling in Reinforcement Learning requires Inference Strategies[PDF43][Copy][Kimi55][REL]",
    "authors": [
      "Authors:\n                Felix Chalumeau",
      "Daniel Rajaonarivonivelomanantsoa",
      "Ruan John de Kock",
      "Juan Claude Formanek",
      "Sasha Abramowitz",
      "Omayma Mahjoub",
      "Wiem Khlifi",
      "Simon Verster Du Toit",
      "Louay Ben Nessir",
      "Refiloe Shabe",
      "Arnol Manuel Fokam",
      "Siddarth Singh",
      "Ulrich Armel Mbou Sob",
      "Arnu Pretorius"
    ],
    "affiliations": [],
    "summary": "Authors:Felix Chalumeau,Daniel Rajaonarivonivelomanantsoa,Ruan John de Kock,Juan Claude Formanek,Sasha Abramowitz,Omayma Mahjoub,Wiem Khlifi,Simon Verster Du Toit,Louay Ben Nessir,Refiloe Shabe,Arnol Manuel Fokam,Siddarth Singh,Ulrich Armel Mbou Sob,Arnu Pretorius",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#14In Search of Adam’s Secret Sauce[PDF28][Copy][Kimi29][REL]",
    "authors": [
      "Authors:\n                Antonio Orvieto",
      "Robert M. Gower"
    ],
    "affiliations": [],
    "summary": "Understanding the remarkable efficacy of Adam when training transformer-based language models has become a central research topic within the optimization community. To gain deeper insights, several simplifications of Adam have been proposed, such as the signed gradient and signed momentum methods. In this work, we conduct an extensive empirical study — training over 1,500 language models across different data configurations and scales — comparing Adam to several known simplified variants. We find that signed momentum methods are faster than SGD, but consistently underperform relative to Adam, even after careful tuning of momentum, clipping setting and learning rates. However, our analysis reveals a compelling option that preserves near-optimal performance while allowing for new insightful reformulations: constraining the Adam momentum parameters to be equal, $\\beta_1=\\beta_2$. Beyond robust performance, this choice affords new theoretical insights, highlights the \"secret sauce\" on top of signed momentum, and grants a precise statistical interpretation: we show that Adam in this setting implements a natural online algorithm for estimating the mean and variance of gradients—one that arises from a mean-field Gaussian variational inference perspective.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#16MaxSup: Overcoming Representation Collapse in Label Smoothing[PDF27][Copy][Kimi24][REL]",
    "authors": [
      "Authors:\n                Yuxuan Zhou",
      "Heng Li",
      "Zhi-Qi Cheng",
      "Xudong Yan",
      "Yifei Dong",
      "Mario Fritz",
      "Margret Keuper"
    ],
    "affiliations": [],
    "summary": "Label Smoothing (LS) is widely adopted to reduce overconfidence in neural network predictions and improve generalization. Despite these benefits, recent studies reveal two critical issues with LS. First, LS induces overconfidence in misclassified samples. Second, it compacts feature representations into overly tight clusters, diluting intra-class diversity, although the precise cause of this phenomenon remained elusive. In this paper, we analytically decompose the LS-induced loss, exposing two key terms: (i) a regularization term that dampens overconfidence only when the prediction is correct, and (ii) an error-amplification term that arises under misclassifications. This latter term compels the network to reinforce incorrect predictions with undue certainty, exacerbating representation collapse. To address these shortcomings, we propose Max Suppression (MaxSup), which applies uniform regularization to both correct and incorrect predictions by penalizing the top-1 logit rather than the ground-truth logit. Through extensive feature-space analyses, we show that MaxSup restores intra-class variation and sharpens inter-class boundaries. Experiments on large-scale image classification and multiple downstream tasks confirm that MaxSup is a more robust alternative to LS.Code and reproducibility scripts are available at https://github.com/ZhouYuxuanYX/Maximum-Suppression-Regularization.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#17Memory Mosaics at scale[PDF34][Copy][Kimi35][REL]",
    "authors": [
      "Authors:\n                Jianyu Zhang",
      "Leon Bottou"
    ],
    "affiliations": [],
    "summary": "Memory Mosaics, networks of associative memories, have demonstrated appealing compositional and in-context learning capabilities on medium-scale networks (GPT-2 scale) and synthetic small datasets. This work shows that these favorable properties remain when we scale memory mosaics to large language model sizes (llama-8B scale) and real-world datasets. To this end, we scale memory mosaics to 10B size, we train them on one trillion tokens, we introduce a couple architectural modifications (*memory mosaics v2*), we assess their capabilities across three evaluation dimensions: training-knowledge storage, new-knowledge storage, and in-context learning. Throughout the evaluation, memory mosaics v2 match transformers on the learning of training knowledge (first dimension) and significantly outperforms transformers on carrying out new tasks at inference time (second and third dimensions). These improvements cannot be easily replicated by simply increasing the training data for transformers. A memory mosaics v2 trained on one trillion tokens still perform better on these tasks than a transformer trained on eight trillion tokens.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#18The emergence of sparse attention: impact of data distribution and benefits of repetition[PDF40][Copy][Kimi35][REL]",
    "authors": [
      "Authors:\n                Nicolas Zucchet",
      "Francesco D'Angelo",
      "Andrew Kyle Lampinen",
      "Stephanie C.Y. Chan"
    ],
    "affiliations": [],
    "summary": "Emergence is a fascinating property of large language models and neural networks more broadly: as models scale and train for longer, they sometimes develop new abilities in sudden ways. Despite initial studies, we still lack a comprehensive understanding of how and when these abilities emerge. To address this gap, we study the emergence over training of sparse attention, a critical and frequently observed attention pattern in Transformers. By combining theoretical analysis of a toy model with empirical observations on small Transformers trained on a linear regression variant, we uncover the mechanics driving sparse attention emergence and reveal that emergence timing follows power laws based on task structure, architecture, and optimizer choice. We additionally find that repetition can greatly speed up emergence. Finally, we confirm these results on a well-studied in-context associative recall task. Our findings provide a simple, theoretically grounded framework for understanding how data distributions and model design influence the learning dynamics behind one form of emergence.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#20Identifiability of Deep Polynomial Neural Networks[PDF11][Copy][Kimi18][REL]",
    "authors": [
      "Authors:\n                Konstantin Usevich",
      "Ricardo Augusto Borsoi",
      "Clara Dérand",
      "Marianne Clausel"
    ],
    "affiliations": [],
    "summary": "Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability-a key property for ensuring interpretability-remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly compared to the activation degrees. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. We also settle an open conjecture on the dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach the expected dimension.",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#21Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference[PDF34][Copy][Kimi32][REL]",
    "authors": [
      "Authors:\n                Jiayi Yuan",
      "Hao Li",
      "Xinheng Ding",
      "Wenya Xie",
      "Yu-Jhe Li",
      "Wentian Zhao",
      "Kun Wan",
      "Jing Shi",
      "Xia Hu",
      "Zirui Liu"
    ],
    "affiliations": [],
    "summary": "Authors:Jiayi Yuan,Hao Li,Xinheng Ding,Wenya Xie,Yu-Jhe Li,Wentian Zhao,Kun Wan,Jing Shi,Xia Hu,Zirui Liu",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#22PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models[PDF20][Copy][Kimi26][REL]",
    "authors": [
      "Authors:\n                Ruiqi Wang",
      "Dezhong Zhao",
      "Ziqin Yuan",
      "Tianyu Shao",
      "Guohua Chen",
      "Dominic Kao",
      "Sungeun Hong",
      "Byung-Cheol Min"
    ],
    "affiliations": [],
    "summary": "Authors:Ruiqi Wang,Dezhong Zhao,Ziqin Yuan,Tianyu Shao,Guohua Chen,Dominic Kao,Sungeun Hong,Byung-Cheol Min",
    "link": null,
    "published_date": null,
    "conference": "NeurIPS",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#2Oscillatory State-Space Models[PDF193][Copy][Kimi234][REL]",
    "authors": [
      "Authors:\n                T. Konstantin Rusch",
      "Daniela Rus"
    ],
    "affiliations": [],
    "summary": "We propose Linear Oscillatory State-Space models (LinOSS) for efficiently learning on long sequences. Inspired by cortical dynamics of biological neural networks, we base our proposed LinOSS model on a system of forced harmonic oscillators. A stable discretization, integrated over time using fast associative parallel scans, yields the proposed state-space model. We prove that LinOSS produces stable dynamics only requiring nonnegative diagonal state matrix. This is in stark contrast to many previous state-space models relying heavily on restrictive parameterizations. Moreover, we rigorously show that LinOSS is universal, i.e., it can approximate any continuous and causal operator mapping between time-varying functions, to desired accuracy. In addition, we show that an implicit-explicit discretization of LinOSS perfectly conserves the symmetry of time reversibility of the underlying dynamics. Together, these properties enable efficient modeling of long-range interactions, while ensuring stable and accurate long-horizon forecasting. Finally, our empirical results, spanning a wide range of time-series tasks from mid-range to very long-range classification and regression, as well as long-horizon forecasting, demonstrate that our proposed LinOSS model consistently outperforms state-of-the-art sequence models. Notably, LinOSS outperforms Mamba by nearly 2x and LRU by 2.5x on a sequence modeling task with sequences of length 50k.",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#3Feedback Favors the Generalization of Neural ODEs[PDF120][Copy][Kimi169][REL]",
    "authors": [
      "Authors:\n                Jindou Jia",
      "Zihan Yang",
      "Meng Wang",
      "Kexin Guo",
      "Jianfei Yang",
      "Xiang Yu",
      "Lei Guo"
    ],
    "affiliations": [],
    "summary": "The well-known generalization problem hinders the application of artificial neural networks in continuous-time prediction tasks with varying latent dynamics. In sharp contrast, biological systems can neatly adapt to evolving environments benefiting from real-time feedback mechanisms. Inspired by the feedback philosophy, we present feedback neural networks, showing that a feedback loop can flexibly correct the learned latent dynamics of neural ordinary differential equations (neural ODEs), leading to a prominent generalization improvement. The feedback neural network is a novel two-DOF neural network, which possesses robust performance in unseen scenarios with no loss of accuracy performance on previous tasks. A linear feedback form is presented to correct the learned latent dynamics firstly, with a convergence guarantee. Then, domain randomization is utilized to learn a nonlinear neural feedback form. Finally, extensive tests including trajectory prediction of a real irregular object and model predictive control of a quadrotor with various uncertainties, are implemented, indicating significant improvements over state-of-the-art model-based and learning-based methods.",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#5Homomorphism Expressivity of Spectral Invariant Graph Neural Networks[PDF83][Copy][Kimi103][REL]",
    "authors": [
      "Authors:\n                Jingchu Gai",
      "Yiheng Du",
      "Bohang Zhang",
      "Haggai Maron",
      "Liwei Wang"
    ],
    "affiliations": [],
    "summary": "Graph spectra are an important class of structural features on graphs that have shown promising results in enhancing Graph Neural Networks (GNNs). Despite their widespread practical use, the theoretical understanding of the power of spectral invariants --- particularly their contribution to GNNs --- remains incomplete. In this paper, we address this fundamental question through the lens of homomorphism expressivity, providing a comprehensive and quantitative analysis of the expressive power of spectral invariants. Specifically, we prove that spectral invariant GNNs can homomorphism-count exactly a class of specific tree-like graphs which we refer to as \\emph{parallel trees}. We highlight the significance of this result in various contexts, including establishing a quantitative expressiveness hierarchy across different architectural variants, offering insights into the impact of GNN depth, and understanding the subgraph counting capabilities of spectral invariant GNNs. In particular, our results significantly extend \\citet{arvind2024hierarchy} and settle their open questions. Finally, we generalize our analysis to higher-order GNNs and answer an open question raised by \\citet{zhang2024expressive}.",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#6DEPT: Decoupled Embeddings for Pre-training Language Models[PDF168][Copy][Kimi214][REL]",
    "authors": [
      "Authors:\n                Alex Iacob",
      "Lorenzo Sani",
      "Meghdad Kurmanji",
      "William Shen",
      "Xinchi Qiu",
      "Dongqi Cai",
      "Yan Gao",
      "Nic Lane"
    ],
    "affiliations": [],
    "summary": "Past works have shown that lexical, syntactical, and semantical differences in heterogeneous data sources can cause challenges such as negative interference or the ``curse of multilinguality''. Because of this, training on such heterogeneous corpora requires extensive and costly efforts to balance data mixtures. We propose a novel pre-training framework to alleviate this curse. Our method, DEPT, decouples embeddings from the transformer body while simultaneously training the latter in multiple contexts without a shared global vocabulary. DEPT: (1) trains robustly and effectively under significant data heterogeneity, (2) reduces token embedding parameters by up to 80% and communication costs by 714x for billion-scale models, (3) enhances transformer body plasticity and generalization, improving average perplexity upward of 15.3-20% and improving performance for downstream fine-tuning in our experiments, and (4) permits training with custom optimized vocabularies per data source. We demonstrate DEPT's potential via the first vocabulary-agnostic federated multilingual pre-training of a billion-scale model, reducing total parameters by 24% versus standard training.",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#7Diffusion-Based Planning for Autonomous Driving with Flexible Guidance[PDF108][Copy][Kimi111][REL]",
    "authors": [
      "Authors:\n                Yinan Zheng",
      "Ruiming Liang",
      "Kexin ZHENG",
      "Jinliang Zheng",
      "Liyuan Mao",
      "Jianxiong Li",
      "Weihao Gu",
      "Rui Ai",
      "Shengbo Li",
      "Xianyuan Zhan",
      "Jingjing Liu"
    ],
    "affiliations": [],
    "summary": "Authors:Yinan Zheng,Ruiming Liang,Kexin ZHENG,Jinliang Zheng,Liyuan Mao,Jianxiong Li,Weihao Gu,Rui Ai,Shengbo Li,Xianyuan Zhan,Jingjing Liu",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#9Accelerated training through iterative gradient propagation along the residual path[PDF77][Copy][Kimi90][REL]",
    "authors": [
      "Authors:\n                Erwan Fagnou",
      "Paul Caillon",
      "Blaise Delattre",
      "Alexandre Allauzen"
    ],
    "affiliations": [],
    "summary": "Despite being the cornerstone of deep learning, backpropagation is criticized for its inherent sequentiality, which can limit the scalability of very deep models.Such models faced convergence issues due to vanishing gradient, later resolved using residual connections. Variants of these are now widely used in modern architectures.However, the computational cost of backpropagation remains a major burden, accounting for most of the training time.Taking advantage of residual-like architectural designs, we introduce Highway backpropagation, a parallelizable iterative algorithm that approximates backpropagation, by alternatively i) accumulating the gradient estimates along the residual path, and ii) backpropagating them through every layer in parallel. This algorithm is naturally derived from a decomposition of the gradient as the sum of gradients flowing through all paths, and is adaptable to a diverse set of common architectures, ranging from ResNets and Transformers to recurrent neural networks.Through an extensive empirical study on a large selection of tasks and models, we evaluate Highway-BP and show that major speedups can be achieved with minimal performance degradation.",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#13MoDeGPT: Modular Decomposition for Large Language Model Compression[PDF67][Copy][Kimi89][REL]",
    "authors": [
      "Authors:\n                Chi-Heng Lin",
      "Shangqian Gao",
      "James Smith",
      "Abhishek Patel",
      "Shikhar Tuli",
      "Yilin Shen",
      "Hongxia Jin",
      "Yen-Chang Hsu"
    ],
    "affiliations": [],
    "summary": "Authors:Chi-Heng Lin,Shangqian Gao,James Smith,Abhishek Patel,Shikhar Tuli,Yilin Shen,Hongxia Jin,Yen-Chang Hsu",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#14Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues[PDF36][Copy][Kimi50][REL]",
    "authors": [
      "Authors:\n                Riccardo Grazzi",
      "Julien Siems",
      "Jörg Franke",
      "Arber Zela",
      "Frank Hutter",
      "massimiliano pontil"
    ],
    "affiliations": [],
    "summary": "Linear Recurrent Neural Networks (LRNNs) such as Mamba, RWKV, GLA, mLSTM, and DeltaNet have emerged as efficient alternatives to Transformers in large language modeling, offering linear scaling with sequence length and improved training efficiency. However, LRNNs struggle to perform state-tracking which may impair performance in tasks such as code evaluation or tracking a chess game. Even parity, the simplest state-tracking task, which non-linear RNNs like LSTM handle effectively, cannot be solved by current LRNNs. Recently, Sarrof et al. (2024) demonstrated that the failure of LRNNs like Mamba to solve parity stems from restricting the value range of their diagonal state-transition matrices to $[0, 1]$ and that incorporating negative values can resolve this issue. We extend this result to non-diagonal LRNNs, which have recently shown promise in models such as DeltaNet. We prove that finite precision LRNNs with state-transition matrices having only positive eigenvalues cannot solve parity, while complex eigenvalues are needed to count modulo $3$. Notably, we also prove that LRNNs can learn any regular language when their state-transition matrices are products of identity minus vector outer product matrices, each with eigenvalues in the range $[-1, 1]$. Our empirical results confirm that extending the eigenvalue range of models like Mamba and DeltaNet to include negative values not only enables them to solve parity but consistently improves their performance on state-tracking tasks. Furthermore, pre-training LRNNs with an extended eigenvalue range for language modeling achieves comparable performance and stability while showing promise on code and math data. Our work enhances the expressivity of modern LRNNs, broadening their applicability without changing the cost of training or inference.",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#15Learning and aligning single-neuron invariance manifolds in visual cortex[PDF37][Copy][Kimi42][REL]",
    "authors": [
      "Authors:\n                Mohammad Bashiri",
      "Luca Baroni",
      "Ján Antolík",
      "Fabian Sinz"
    ],
    "affiliations": [],
    "summary": "Understanding how sensory neurons exhibit selectivity to certain features and invariance to others is central to uncovering the computational principles underlying robustness and generalization in visual perception. Most existing methods for characterizing selectivity and invariance identify single or finite discrete sets of stimuli. Since these are only isolated measurements from an underlying continuous manifold, characterizing invariance properties accurately and comparing them across neurons with varying receptive field size, position, and orientation, becomes challenging. Consequently, a systematic analysis of invariance types at the population level remains under-explored. Building on recent advances in learning continuous invariance manifolds, we introduce a novel method to accurately identify and align invariance manifolds of visual sensory neurons, overcoming these challenges. Our approach first learns the continuous invariance manifold of stimuli that maximally excite a neuron modeled by a response-predicting deep neural network. It then learns an affine transformation on the pixel coordinates such that the same manifold activates another neuron as strongly as possible, effectively aligning their invariance manifolds spatially. This alignment provides a principled way to quantify and compare neuronal invariances irrespective of receptive field differences. Using simulated neurons, we demonstrate that our method accurately learns and aligns known invariance manifolds, robustly identifying functional clusters. When applied to macaque V1 neurons, it reveals functional clusters of neurons, including simple and complex cells. Overall, our method enables systematic, quantitative exploration of the neural invariance landscape, to gain new insights into the functional properties of visual sensory neurons.",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#16ProtComposer: Compositional Protein Structure Generation with 3D Ellipsoids[PDF31][Copy][Kimi35][REL]",
    "authors": [
      "Authors:\n                Hannes Stärk",
      "Bowen Jing",
      "Tomas Geffner",
      "Jason Yim",
      "Tommi Jaakkola",
      "Arash Vahdat",
      "Karsten Kreis"
    ],
    "affiliations": [],
    "summary": "We develop ProtComposer to generate protein structures conditioned on spatial protein layouts that are specified via a set of 3D ellipsoids capturing substructure shapes and semantics. At inference time, we condition on ellipsoids that are hand-constructed, extracted from existing proteins, or from a statistical model, with each option unlocking new capabilities. Hand-specifying ellipsoids enables users to control the location, size, orientation, secondary structure, and approximate shape of protein substructures. Conditioning on ellipsoids of existing proteins enables redesigning their substructure's connectivity or editing substructure properties. By conditioning on novel and diverse ellipsoid layouts from a simple statistical model, we improve protein generation with expanded Pareto frontiers between designability, novelty, and diversity. Further, this enables sampling designable proteins with a helix-fraction that matches PDB proteins, unlike existing generative models that commonly oversample conceptually simple helix bundles.",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#17Proteina: Scaling Flow-based Protein Structure Generative Models[PDF51][Copy][Kimi43][REL]",
    "authors": [
      "Authors:\n                Tomas Geffner",
      "Kieran Didi",
      "Zuobai Zhang",
      "Danny Reidenbach",
      "Zhonglin Cao",
      "Jason Yim",
      "Mario Geiger",
      "Christian Dallago",
      "Emine Kucukbenli",
      "Arash Vahdat",
      "Karsten Kreis"
    ],
    "affiliations": [],
    "summary": "Authors:Tomas Geffner,Kieran Didi,Zuobai Zhang,Danny Reidenbach,Zhonglin Cao,Jason Yim,Mario Geiger,Christian Dallago,Emine Kucukbenli,Arash Vahdat,Karsten Kreis",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#20Interpreting Emergent Planning in Model-Free Reinforcement Learning[PDF68][Copy][Kimi87][REL]",
    "authors": [
      "Authors:\n                Thomas Bush",
      "Stephen Chung",
      "Usman Anwar",
      "Adrià Garriga-Alonso",
      "David Krueger"
    ],
    "affiliations": [],
    "summary": "We present the first mechanistic evidence that model-free reinforcement learning agents can learn to plan. This is achieved by applying a methodology based on concept-based interpretability to a model-free agent in Sokoban -- a commonly used benchmark for studying planning. Specifically, we demonstrate that DRC, a generic model-free agent introduced by [Guez et al. (2019)](https://arxiv.org/abs/1901.03559), uses learned concept representations to internally formulate plans that both predict the long-term effects of actions on the environment and influence action selection. Our methodology involves: (1) probing for planning-relevant concepts, (2) investigating plan formation within the agent's representations, and (3) verifying that discovered plans (in agent's representations) have causal effect on agent's behavior through interventions. We also show that the emergence of these plans coincides with the emergence of a planning-like property: the ability to benefit from additional test-time compute. Finally, we perform a qualitative analysis of the planning algorithm learned by the agent and discover a strong resemblance to parallelized bidirectional search. Our findings advance understanding of the internal mechanisms underlying planning behavior in agents, enabling improved diagnosis, interpretation, and control of agent planning processes.",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#22MLE-Bench: Evaluating Machine Learning Agents on Machine Learning Engineering[PDF35][Copy][Kimi42][REL]",
    "authors": [
      "Authors:\n                Jun Shern Chan",
      "Neil Chowdhury",
      "Oliver Jaffe",
      "James Aung",
      "Dane Sherburn",
      "Evan Mays",
      "Giulio Starace",
      "Kevin Liu",
      "Leon Maksin",
      "Tejal Patwardhan",
      "Aleksander Madry",
      "Lilian Weng"
    ],
    "affiliations": [],
    "summary": "Authors:Jun Shern Chan,Neil Chowdhury,Oliver Jaffe,James Aung,Dane Sherburn,Evan Mays,Giulio Starace,Kevin Liu,Leon Maksin,Tejal Patwardhan,Aleksander Madry,Lilian Weng",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#24Do as We Do, Not as You Think: the Conformity of Large Language Models[PDF119][Copy][Kimi169][REL]",
    "authors": [
      "Authors:\n                Zhiyuan Weng",
      "Guikun Chen",
      "Wenguan Wang"
    ],
    "affiliations": [],
    "summary": "Recent advancements in large language models (LLMs) revolutionize the field of intelligent agents, enabling collaborative multi-agent systems capable of tackling complex problems across various domains. However, the potential of conformity within these systems, analogous to phenomena like conformity bias and group-think in human group dynamics, remains largely unexplored, raising concerns about their collective problem-solving capabilities and possible ethical implications. This paper presents a comprehensive study on conformity in LLM-driven multi-agent systems, focusing on three aspects: the existence of conformity, the factors influencing conformity, and potential mitigation strategies. In particular, we introduce BENCHFORM, a new conformity-oriented benchmark, featuring reasoning-intensive tasks and five distinct interaction protocols designed to probe LLMs’ behavior in collaborative scenarios. Several representative LLMs are evaluated on BENCHFORM, using metrics such as conformity rate and independence rate to quantify conformity’s impact. Our analysis delves into factors influencing conformity, including interaction time and majority size, and examines how the subject agent rationalize its conforming behavior. Furthermore, we explore two strategies to mitigate conformity effects, i.e., developing enhanced persona and implementing a reflection mechanism. Several interesting findings regarding LLMs’ conformity are derived from empirical results and case studies. We hope that these insights can pave the way for more robust and ethically-aligned collaborative AI systems. Our benchmark and code will be publicly available.",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#25Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo[PDF51][Copy][Kimi81][REL]",
    "authors": [
      "Authors:\n                João Loula",
      "Benjamin LeBrun",
      "Li Du",
      "Ben Lipkin",
      "Clemente Pasti",
      "Gabriel Grand",
      "Tianyu Liu",
      "Yahya Emara",
      "Marjorie Freedman",
      "Jason Eisner",
      "Ryan Cotterell",
      "Vikash Mansinghka",
      "Alexander Lew",
      "Tim Vieira",
      "Timothy O'Donnell"
    ],
    "affiliations": [],
    "summary": "Authors:João Loula,Benjamin LeBrun,Li Du,Ben Lipkin,Clemente Pasti,Gabriel Grand,Tianyu Liu,Yahya Emara,Marjorie Freedman,Jason Eisner,Ryan Cotterell,Vikash Mansinghka,Alexander Lew,Tim Vieira,Timothy O'Donnell",
    "link": null,
    "published_date": null,
    "conference": "ICLR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#1Real-Time Calibration Model for Low-Cost Sensor in Fine-Grained Time Series[PDF295][Copy][Kimi424][REL]",
    "authors": [
      "Authors:\n                Seokho Ahn",
      "Hyungjin Kim",
      "Sungbok Shin",
      "Young-Duk Seo"
    ],
    "affiliations": [],
    "summary": "Precise measurements from sensors are crucial, but data is usually collected from low-cost, low-tech systems, which are often inaccurate. Thus, they require further calibrations. To that end, we first identify three requirements for effective calibration under practical low-tech sensor conditions. Based on the requirements, we develop a model called TESLA, Transformer for effective sensor calibration utilizing logarithmic-binned attention. TESLA uses a high-performance deep learning model, Transformers, to calibrate and capture non-linear components. At its core, it employs logarithmic binning, to minimize attention complexity. TESLA achieves consistent real-time calibration, even with longer sequences and finer-grained time series in hardware-constrained systems. Experiments show that TESLA outperforms existing novel deep learning and newly crafted linear models in accuracy, calibration speed, and energy efficiency.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#3Scalable Surrogate Verification of Image-Based Neural Network Control Systems Using Composition and Unrolling[PDF51][Copy][Kimi46][REL]",
    "authors": [
      "Authors:\n                Feiyang Cai",
      "Chuchu Fan",
      "Stanley Bak"
    ],
    "affiliations": [],
    "summary": "Verifying safety of neural network control systems that use images as input is a difficult problem because, from a given system state, there is no known way to mathematically model what images are possible in the real-world. We build upon recent work that considers a surrogate verification approach, training a conditional generative adversarial network (cGAN) as an image generator in place of the real world. This setup enables set-based formal analysis of the closed-loop system, providing analysis beyond simulation and testing. While existing work is effective on small examples, excessive overapproximation both within a single control period (one-step error) and across multiple periods (multi-step error) limits its scalability. We propose approaches to overcome these errors. First, we address one-step error by composing the system's dynamics along with the cGAN and neural network controller, without losing the dependencies between input states and the control outputs as in the monotonic analysis of the system dynamics. Second, we reduce multi-step error by repeating the single-step composition, essentially unrolling multiple steps of the control loop into a large neural network. We then leverage existing network verification algorithms to compute accurate reachable sets for multiple steps, avoiding the accumulation of abstraction error at each step.We demonstrate the effectiveness of our approach in terms of both accuracy and scalability using two case studies. On the aircraft taxiing system, the converged reachable set is 175% larger using the prior baseline method compared with our proposed approach. On the emergency braking system, with 24x the number of image output variables from the cGAN, the baseline method fails to prove any states are safe, whereas our improvements enable set-based safety analysis.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#5Holistic Semantic Representation for Navigational Trajectory Generation[PDF38][Copy][Kimi18][REL]",
    "authors": [
      "Authors:\n                Ji Cao",
      "Tongya Zheng",
      "Qinghong Guo",
      "Yu Wang",
      "Junshu Dai",
      "Shunyu Liu",
      "Jie Yang",
      "Jie Song",
      "Mingli Song"
    ],
    "affiliations": [],
    "summary": "Trajectory generation has garnered significant attention from researchers in the field of spatio-temporal analysis, as it can generate substantial synthesized human mobility trajectories that enhance user privacy and alleviate data scarcity. However, existing trajectory generation methods often focus on improving trajectory generation quality from a singular perspective, lacking a comprehensive semantic understanding across various scales. Consequently, we are inspired to develop a HOlistic SEmantic Representation (HOSER) framework for navigational trajectory generation. Given an origin-and-destination (OD) pair and the starting time point of a latent trajectory, we first propose a Road Network Encoder to expand the receptive field of road- and zone-level semantics. Second, we design a Multi-Granularity Trajectory Encoder to integrate the spatio-temporal semantics of the generated trajectory at both the point and trajectory levels. Finally, we employ a Destination-Oriented Navigator to seamlessly integrate destination-oriented guidance. Extensive experiments on three real-world datasets demonstrate that HOSER outperforms state-of-the-art baselines by a significant margin. Moreover, the model's performance in few-shot learning and zero-shot learning scenarios further verifies the effectiveness of our holistic semantic representation.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#6SQLFixAgent: Towards Semantic-Accurate Text-to-SQL Parsing via Consistency-Enhanced Multi-Agent Collaboration[PDF34][Copy][Kimi35][REL]",
    "authors": [
      "Authors:\n                Jipeng Cen",
      "Jiaxin Liu",
      "Zhixu Li",
      "Jingjing Wang"
    ],
    "affiliations": [],
    "summary": "While fine-tuned large language models (LLMs) excel in generating grammatically valid SQL in Text-to-SQL parsing, they often struggle to ensure semantic accuracy in queries, leading to user confusion and diminished system usability. To tackle this challenge, we introduce SQLFixAgent, a new consistency-enhanced multi-agent collaborative framework designed for detecting and repairing erroneous SQL. Our framework comprises a core agent, SQLRefiner, alongside two auxiliary agents: SQLReviewer and QueryCrafter. The SQLReviewer agent employs the rubber duck debugging method to identify potential semantic mismatches between SQL and user query. If the error is detected, the QueryCrafter agent generates multiple SQL as candidate repairs using a fine-tuned SQLTool. Subsequently, leveraging similar repair retrieval and failure memory reflection, the SQLRefiner agent selects the most fitting SQL statement from the candidates as the final repair. We evaluated our proposed framework on five Text-to-SQL benchmarks. The experimental results show that our method consistently enhances the performance of the baseline model, specifically achieving an execution accuracy improvement of over 3% on the Bird benchmark. Our framework also has a higher token efficiency compared to other advanced methods, making it more competitive.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#7mmFAS: Multimodal Face Anti-Spoofing Using Multi-Level Alignment and Switch-Attention Fusion[PDF28][Copy][Kimi22][REL]",
    "authors": [
      "Authors:\n                Geng Chen",
      "Wuyuan Xie",
      "Di Lin",
      "Ye Liu",
      "Miaohui Wang"
    ],
    "affiliations": [],
    "summary": "The increasing number of presentation attacks on reliable face matching has raised concerns and garnered attention towards face anti-spoofing (FAS). However, existing methods for FAS modeling commonly fuse multiple visual modalities (e.g., RGB, Depth, and Infrared) in a straightforward manner, disregarding latent feature gaps that can hinder representation learning. To address this challenge, we propose a novel multimodal FAS framework (mmFAS) that focuses on explicit alignment and fusion of latent features across different modalities. Specifically, we develop a multimodal alignment module to alleviate the latent feature gap by using instance-level contrastive learning and class-level matching simultaneously. Further, we explore a new switch-attention based fusion module to automatically aggregate complementary information and control model complexity. To evaluate the anti-spoofing performance more effectively, we adopt a challenging yet meaningful cross-database protocol involving four benchmark multimodal FAS datasets to simulate realworld scenarios. Extensive experimental results demonstrate the effectiveness of mmFAS in improving the accuracy of FAS systems, outperforming 10 representative methods.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#114D Diffusion for Dynamic Protein Structure Prediction with Reference and Motion Guidance[PDF17][Copy][Kimi14][REL]",
    "authors": [
      "Authors:\n                Kaihui Cheng",
      "Ce Liu",
      "Qingkun Su",
      "Jun Wang",
      "Liwei Zhang",
      "Yining Tang",
      "Yao Yao",
      "Siyu Zhu",
      "Yuan Qi"
    ],
    "affiliations": [],
    "summary": "Protein structure prediction is pivotal for understanding the structure-function relationship of proteins, advancing biological research, and facilitating pharmaceutical development and experimental design. While deep learning methods and the expanded availability of experimental 3D protein structures have accelerated structure prediction, the dynamic nature of protein structures has received limited attention. This study introduces an innovative 4D diffusion model incorporating molecular dynamics (MD) simulation data to learn dynamic protein structures. Our approach is distinguished by the following components: (1) a unified diffusion model capable of generating dynamic protein structures, including both the backbone and side chains, utilizing atomic grouping and side-chain dihedral angle predictions; (2) a reference network that enhances structural consistency by integrating the latent embeddings of the initial 3D protein structures; and (3) a motion alignment module aimed at improving temporal structural coherence across multiple time steps. To our knowledge, this is the first diffusion-based model aimed at predicting protein trajectories across multiple time steps simultaneously. Validation on benchmark datasets demonstrates that our model exhibits high accuracy in predicting dynamic 3D structures of proteins containing up to 256 amino acids over 32 time steps, effectively capturing both local flexibility in stable states and significant conformational changes.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#18RingFormer: A Ring-Enhanced Graph Transformer for Organic Solar Cell Property Prediction[PDF9][Copy][Kimi8][REL]",
    "authors": [
      "Authors:\n                Zhihao Ding",
      "Ting Zhang",
      "Yiran Li",
      "Jieming Shi",
      "Chen Jason Zhang"
    ],
    "affiliations": [],
    "summary": "Organic Solar Cells (OSCs) are a promising technology for sustainable energy production. However, the identification of molecules with desired OSC properties typically involves laborious experimental research. To accelerate progress in the field, it is crucial to develop machine learning models capable of accurately predicting the properties of OSC molecules. While graph representation learning has demonstrated success in molecular property prediction, it remains underexplored for OSC-specific tasks. Existing methods fail to capture the unique structural features of OSC molecules, particularly the intricate ring systems that critically influence OSC properties, leading to suboptimal performance. To fill the gap, we present RingFormer, a novel graph transformer framework specially designed to capture both atom and ring level structural patterns in OSC molecules. RingFormer constructs a hierarchical graph that integrates atomic and ring structures and employs a combination of local message passing and global attention mechanisms to generate expressive graph representations for accurate OSC property prediction. We evaluate RingFormer's effectiveness on five curated OSC molecule datasets through extensive experiments. The results demonstrate that RingFormer consistently outperforms existing methods, achieving a 22.77% relative improvement over the nearest competitor on the CEPDB dataset.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#19Knowledge Is Power: Harnessing Large Language Models for Enhanced Cognitive Diagnosis[PDF16][Copy][Kimi13][REL]",
    "authors": [
      "Authors:\n                Zhiang Dong",
      "Jingyuan Chen",
      "Fei Wu"
    ],
    "affiliations": [],
    "summary": "Cognitive Diagnosis Models (CDMs) are designed to assess students' cognitive states by analyzing their performance across a series of exercises. However, existing CDMs often struggle with diagnosing infrequent students and exercises due to a lack of rich prior knowledge. With the advancement in large language models (LLMs), which possess extensive domain knowledge, their integration into cognitive diagnosis presents a promising opportunity. Despite this potential, integrating LLMs with CDMs poses significant challenges. LLMs are not well-suited for capturing the fine-grained collaborative interactions between students and exercises, and the disparity between the semantic space of LLMs and the behavioral space of CDMs hinders effective integration. To address these issues, we propose a novel Knowledge-enhanced Cognitive Diagnosis (KCD) framework, which is a model-agnostic framework utilizing LLMs to enhance CDMs and compatible with various CDM architectures. The KCD framework operates in two stages: LLM Diagnosis and Cognitive Level Alignment. In the LLM Diagnosis stage, both students and exercises are diagnosed to achieve comprehensive and detailed modeling. In the Cognitive Level Alignment stage, we bridge the gap between the CDMs' behavioral space and the LLMs' semantic space using contrastive learning and mask-reconstruction approaches. Experiments on several real-world datasets demonstrate the effectiveness of our proposed framework.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#20FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction[PDF9][Copy][Kimi6][REL]",
    "authors": [
      "Authors:\n                Yitong Duan",
      "Weiran Wang",
      "Jian Li"
    ],
    "affiliations": [],
    "summary": "As a fundamental method in economics and finance, the factor model has been extensively utilized in quantitative investment. In recent years, there has been a paradigm shift from traditional linear models with expert-designed factors to more flexible nonlinear machine learning-based models with data-driven factors, aiming to enhance the effectiveness of these factor models. However, due to the low signal-to-noise ratio in market data, mining effective factors in data-driven models remains challenging. In this work, we propose a hypergraph-based factor model with temporal residual contrastive learning (FactorGCL) that employs a hypergraph structure to better capture high-order nonlinear relationships among stock returns and factors. To mine hidden factors that supplement human-designed prior factors for predicting stock returns, we design a cascading residual hypergraph architecture, in which the hidden factors are extracted from the residual information after removing the influence of prior factors. Additionally, we propose a temporal residual contrastive learning method to guide the extraction of effective and comprehensive hidden factors by contrasting stock-specific residual information over different time periods. Our extensive experiments on real stock market data demonstrate that FactorGCL not only outperforms existing state-of-the-art methods but also mines effective hidden factors for predicting stock returns.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#21How to Re-enable PDE Loss for Physical Systems Modeling Under Partial Observation[PDF12][Copy][Kimi8][REL]",
    "authors": [
      "Authors:\n                Haodong Feng",
      "Yue Wang",
      "Dixia Fan"
    ],
    "affiliations": [],
    "summary": "In science and engineering, machine learning techniques are increasingly successful in physical systems modeling (predicting future states of physical systems). Effectively integrating PDE loss as a constraint of system transition can improve the model's prediction by overcoming generalization issues due to data scarcity, especially when data acquisition is costly. However, in many real-world scenarios, due to sensor limitations, the data we can obtain is often only partial observation, making the calculation of PDE loss seem to be infeasible, as the PDE loss heavily relies on high-resolution states. We carefully study this problem and propose a novel framework named Re-enable PDE Loss under Partial Observation (RPLPO). The key idea is that although enabling PDE loss to constrain system transition solely is infeasible, we can re-enable PDE loss by reconstructing the learnable high-resolution state and constraining system transition simultaneously. Specifically, RPLPO combines an encoding module for reconstructing learnable high-resolution states with a transition module for predicting future states. The two modules are jointly trained by data and PDE loss. We conduct experiments in various physical systems to demonstrate that RPLPO has significant improvement in generalization, even when observation is sparse, irregular, noisy, and PDE is inaccurate.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#22APIRL: Deep Reinforcement Learning for REST API Fuzzing[PDF4][Copy][Kimi6][REL]",
    "authors": [
      "Authors:\n                Myles Foley",
      "Sergio Maffeis"
    ],
    "affiliations": [],
    "summary": "REST APIs have become key components of web services. However, they often contain logic flaws resulting in server side errors or security vulnerabilities. HTTP requests are used as test cases to find and mitigate such issues. Existing methods to modify requests, including those using deep learning, suffer from limited performance and precision, relying on undirected search or making limited usage of the contextual information. In this paper we propose APIRL, a fully automated deep reinforcement learning tool for testing REST APIs. A key novelty of our approach is the use of feedback from a transformer module pre-trained on JSON-structured data, akin to that used in API responses. This allows APIRL to learn the subtleties relating to test outcomes, and generalise to unseen API endpoints. We show APIRL can find significantly more bugs than the state-of-the-art in real world REST APIs while minimising the number of required test cases. We also study how reward functions, and other key design choices, affect learnt policies with a thorough ablation study.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#23A Theoretical Framework for an Efficient Normalizing Flow-Based Solution to the Electronic Schrödinger Equation[PDF7][Copy][Kimi6][REL]",
    "authors": [
      "Authors:\n                Daniel Freedman",
      "Eyal Rozenberg",
      "Alex Bronstein"
    ],
    "affiliations": [],
    "summary": "A central problem in quantum mechanics involves solving the Electronic Schrödinger Equation for a molecule or material. The Variational Monte Carlo approach to this problem approximates a particular variational objective via sampling, and then optimizes this approximated objective over a chosen parameterized family of wavefunctions, known as the ansatz. Recently neural networks have been used as the ansatz, with accompanying success. However, sampling from such wavefunctions has required the use of a Markov Chain Monte Carlo approach, which is inherently inefficient. In this work, we propose a solution to this problem via an ansatz which is cheap to sample from, yet satisfies the requisite quantum mechanical properties. We prove that a normalizing flow using the following two essential ingredients satisfies our requirements: (a) a base distribution which is constructed from Determinantal Point Processes; (b) flow layers which are equivariant to a particular subgroup of the permutation group. We then show how to construct both continuous and discrete normalizing flows which satisfy the requisite equivariance. We further demonstrate the manner in which the non-smooth nature (``cusps'') of the wavefunction may be captured, and how the framework may be generalized to provide induction across multiple molecules. The resulting theoretical framework entails an efficient approach to solving the Electronic Schrödinger Equation.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#24EWMoE: An Effective Model for Global Weather Forecasting with Mixture-of-Experts[PDF16][Copy][Kimi7][REL]",
    "authors": [
      "Authors:\n                Lihao Gan",
      "Xin Man",
      "Chenghong Zhang",
      "Jie Shao"
    ],
    "affiliations": [],
    "summary": "Weather forecasting is a crucial task for meteorologic research, with direct social and economic impacts. Recently, data-driven weather forecasting models based on deep learning have shown great potential, achieving superior performance compared with traditional numerical weather prediction methods. However, these models often require massive training data and computational resources. In this paper, we propose EWMoE, an effective model for accurate global weather forecasting, which requires significantly less training data and computational resources. Our model incorporates three key components to enhance prediction accuracy: 3D absolute position embedding, a core Mixture-of-Experts (MoE) layer, and two specific loss functions. We conduct our evaluation on the ERA5 dataset using only two years of training data. Extensive experiments demonstrate that EWMoE outperforms current models such as FourCastNet and ClimaX at all forecast time, achieving competitive performance compared with the state-of-the-art models Pangu-Weather and GraphCast in evaluation metrics such as Anomaly Correlation Coefficient (ACC) and Root Mean Square Error (RMSE). Additionally, ablation studies indicate that applying the MoE architecture to weather forecasting offers significant advantages in improving accuracy and resource efficiency.",
    "link": null,
    "published_date": null,
    "conference": "AAAI",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#2Layer by Layer: Uncovering Hidden Representations in Language Models[PDF221][Copy][Kimi184][REL]",
    "authors": [
      "Authors:\n                Oscar Skean",
      "Md Rifat Arefin",
      "Dan Zhao",
      "Niket Patel",
      "Jalal Naghiyev",
      "Yann LeCun",
      "Ravid Shwartz-Ziv"
    ],
    "affiliations": [],
    "summary": "From extracting features to generating text, the outputs of large language models (LLMs) typically rely on their final layers, following the conventional wisdom that earlier layers capture only low-level cues. However, our analysis shows that intermediate layers can encode even richer representations, often improving performance on a wide range of downstream tasks. To explain and quantify these hidden-layer properties, we propose a unified framework of representation quality metrics based on information theory, geometry, and invariance to input perturbations. Our framework highlights how each model layer balances information compression and signal preservation, revealing why mid-depth embeddings can exceed the last layer’s performance. Through extensive experiments on 32 text-embedding tasks across various architectures (transformers, state-space models) and domains (language, vision), we demonstrate that intermediate layers consistently provide stronger features, challenging the standard view on final-layer embeddings and opening new directions on using mid-layer representations for more robust and accurate representations.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#8The Value of Prediction in Identifying the Worst-Off[PDF28][Copy][Kimi45][REL]",
    "authors": [
      "Authors:\n                Unai Fischer Abaigar",
      "Christoph Kern",
      "Juan Perdomo"
    ],
    "affiliations": [],
    "summary": "Machine learning is increasingly used in government programs to identify and support the most vulnerable individuals, prioritizing assistance for those at greatest risk over optimizing aggregate outcomes. This paper examines the welfare impacts of prediction in equity-driven contexts, and how they compare to other policy levers, such as expanding bureaucratic capacity. Through mathematical models and a real-world case study on long-term unemployment amongst German residents, we develop a comprehensive understanding of the relative effectiveness of prediction in surfacing the worst-off. Our findings provide clear analytical frameworks and practical, data-driven tools that empower policymakers to make principled decisions when designing these systems.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#9Normalizing Flows are Capable Generative Models[PDF69][Copy][Kimi68][REL]",
    "authors": [
      "Authors:\n                Shuangfei Zhai",
      "Ruixiang Zhang",
      "Preetum Nakkiran",
      "David Berthelot",
      "Jiatao Gu",
      "Huangjie Zheng",
      "Tianrong Chen",
      "Miguel Angel Bautista Martin",
      "Navdeep Jaitly",
      "Joshua M Susskind"
    ],
    "affiliations": [],
    "summary": "Authors:Shuangfei Zhai,Ruixiang Zhang,Preetum Nakkiran,David Berthelot,Jiatao Gu,Huangjie Zheng,Tianrong Chen,Miguel Angel Bautista Martin,Navdeep Jaitly,Joshua M Susskind",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#11Algorithm Development in Neural Networks: Insights from the Streaming Parity Task[PDF17][Copy][Kimi35][REL]",
    "authors": [
      "Authors:\n                Loek van Rossem",
      "Andrew Saxe"
    ],
    "affiliations": [],
    "summary": "Even when massively overparameterized, deep neural networks show a remarkable ability to generalize. Research on this phenomenon has focused on generalization within distribution, via smooth interpolation. Yet in some settings neural networks also learn to extrapolate to data far beyond the bounds of the original training set, sometimes even allowing for infinite generalization, implying that an algorithm capable of solving the task has been learned. Here we undertake a case study of the learning dynamics of recurrent neural networks trained on the streaming parity task in order to develop an effective theory of algorithm development. The streaming parity task is a simple but nonlinear task defined on sequences up to arbitrary length. We show that, with sufficient finite training experience, RNNs exhibit a phase transition to perfect infinite generalization. Using an effective theory for the representational dynamics, we find an implicit representational merger effect which can be interpreted as the construction of a finite automaton that reproduces the task. Overall, our results disclose one mechanism by which neural networks can generalize infinitely from finite training experience.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#13rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking[PDF81][Copy][Kimi72][REL]",
    "authors": [
      "Authors:\n                Xinyu Guan",
      "Li Lyna Zhang",
      "Yifei Liu",
      "Ning Shang",
      "Youran Sun",
      "Yi Zhu",
      "Fan Yang",
      "Mao Yang"
    ],
    "affiliations": [],
    "summary": "We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of OpenAI o1, without distillation from superior models. rStar-Math achieves this by exercising ``deep thinking'' through Monte Carlo Tree Search (MCTS), where a math policy SLM performs test-time search guided by an SLM-based process reward model. rStar-Math introduces three innovations to tackle the challenges in training the two SLMs: (1) a novel code-augmented CoT data synthesis method, which performs extensive MCTS rollouts to generate step-by-step verified reasoning trajectories used to train the policy SLM; (2) a novel process reward model training method that avoids naïve step-level score annotation, yielding a more effective process preference model (PPM); (3) a self-evolution recipe in which the policy SLM and PPM are built from scratch and iteratively evolved to improve reasoning capabilities. Through 4 rounds of self-evolution with millions of synthesized solutions for 747k math problems, rStar-Math boosts SLMs' math reasoning to state-of-the-art levels. On MATH benchmark, it improves Qwen2.5-Math-7B from 58.8% to 90.0%, surpassing o1-preview by +4.5%. On the USA Math Olympiad (AIME), rStar-Math solves an average of 53.3% (8/15) of problems, ranking among the top 20% of the brightest high school math students. Code and data are available at https://github.com/microsoft/rStar.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#14Theoretical Limitations of Ensembles in the Age of Overparameterization[PDF22][Copy][Kimi31][REL]",
    "authors": [
      "Authors:\n                Niclas Dern",
      "John Cunningham",
      "Geoff Pleiss"
    ],
    "affiliations": [],
    "summary": "Classic ensembles generalize better than any single component model. In contrast, recent empirical studies find that modern ensembles of (overparameterized) neural networks may not provide any inherent generalization advantage over single but larger neural networks. This paper clarifies how modern overparameterized ensembles differ from their classic underparameterized counterparts, using ensembles of random feature (RF) regressors as a basis for developing theory. In contrast to the underparameterized regime, where ensembling typically induces regularization and increases generalization, we prove with minimal assumptions that infinite ensembles of overparameterized RF regressors become pointwise equivalent to (single) infinite-width RF regressors, and finite width ensembles rapidly converge to single models with the same parameter budget. These results, which are exact for ridgeless models and approximate for small ridge penalties, imply that overparameterized ensembles and single large models exhibit nearly identical generalization. We further characterize the predictive variance amongst ensemble members, demonstrating that it quantifies the expected effects of increasing capacity rather than capturing any conventional notion of uncertainty. Our results challenge common assumptions about the advantages of ensembles in overparameterized settings, prompting a reconsideration of how well intuitions from underparameterized ensembles transfer to deep ensembles and the overparameterized regime.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#15EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents[PDF36][Copy][Kimi33][REL]",
    "authors": [
      "Authors:\n                Rui Yang",
      "Hanyang(Jeremy) Chen",
      "Junyu Zhang",
      "Mark Zhao",
      "Cheng Qian",
      "Kangrui Wang",
      "Qineng Wang",
      "Teja Koripella",
      "Marziyeh Movahedi",
      "Manling Li",
      "Heng Ji",
      "Huan Zhang",
      "Tong Zhang"
    ],
    "affiliations": [],
    "summary": "Authors:Rui Yang,Hanyang(Jeremy) Chen,Junyu Zhang,Mark Zhao,Cheng Qian,Kangrui Wang,Qineng Wang,Teja Koripella,Marziyeh Movahedi,Manling Li,Heng Ji,Huan Zhang,Tong Zhang",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#16Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions[PDF43][Copy][Kimi42][REL]",
    "authors": [
      "Authors:\n                Jaeyeon Kim",
      "Kulin Shah",
      "Vasilis Kontonis",
      "Sham Kakade",
      "Sitan Chen"
    ],
    "affiliations": [],
    "summary": "In recent years, masked diffusion models (MDMs) have emerged as a promising alternative approach for generative modeling over discrete domains. Compared to autoregressive models (ARMs), MDMs trade off complexity at training time with flexibility at inference time. At training time, they must learn to solve an exponentially large number of infilling problems, but at inference time, they can decode tokens in essentially arbitrary order. In this work we closely examine these two competing effects. On the training front, we theoretically and empirically demonstrate that MDMs indeed train on computationally intractable subproblems compared to their autoregressive counterparts. On the inference front, we show that a suitable strategy for adaptively choosing the token decoding order significantly enhances the capabilities of MDMs, allowing them to sidestep hard subproblems. On logic puzzles like Sudoku, we show that adaptive inference can boost solving accuracy in pretrained MDMs from $<7$\\% to $\\approx 90$\\%, even outperforming ARMs that were explicitly trained via teacher forcing to learn the right order of decoding.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#17CollabLLM: From Passive Responders to Active Collaborators[PDF37][Copy][Kimi50][REL]",
    "authors": [
      "Authors:\n                Shirley Wu",
      "Michel Galley",
      "Baolin Peng",
      "Hao Cheng",
      "Gavin Li",
      "Yao Dou",
      "Weixin Cai",
      "James Zou",
      "Jure Leskovec",
      "Jianfeng Gao"
    ],
    "affiliations": [],
    "summary": "Authors:Shirley Wu,Michel Galley,Baolin Peng,Hao Cheng,Gavin Li,Yao Dou,Weixin Cai,James Zou,Jure Leskovec,Jianfeng Gao",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#18Generative Social Choice: The Next Generation[PDF15][Copy][Kimi29][REL]",
    "authors": [
      "Authors:\n                Niclas Boehmer",
      "Sara Fish",
      "Ariel Procaccia"
    ],
    "affiliations": [],
    "summary": "A key task in certain democratic processes is to produce a concise slate of statements that proportionally represents the full spectrum of user opinions. This task is similar to committee elections, but unlike traditional settings, the candidate set comprises all possible statements of varying lengths, and so it can only be accessed through specific queries. Combining social choice and large language models, prior work has approached this challenge through a framework of generative social choice. We extend the framework in two fundamental ways, providing theoretical guarantees even in the face of approximately optimal queries and a budget limit on the overall length of the slate. Using GPT-4o to implement queries, we showcase our approach on datasets related to city improvement measures and drug reviews, demonstrating its effectiveness in generating representative slates from unstructured user opinions.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#19Hierarchical Refinement: Optimal Transport to Infinity and Beyond[PDF30][Copy][Kimi28][REL]",
    "authors": [
      "Authors:\n                Peter Halmos",
      "Julian Gold",
      "Xinhao Liu",
      "Benjamin Raphael"
    ],
    "affiliations": [],
    "summary": "Optimal transport (OT) has enjoyed great success in machine learning as a principled way to align datasets via a least-cost correspondence, driven in large part by the runtime efficiency of the Sinkhorn algorithm (Cuturi, 2013). However, Sinkhorn has quadratic space complexity in the number of points, limiting scalability to larger datasets. Low-rank OT achieves linear-space complexity, but by definition, cannot compute a one-to-one correspondence between points. When the optimal transport problem is an assignment problem between datasets then an optimal mapping, known as the _Monge map_, is guaranteed to be a bijection. In this setting, we show that the factors of an optimal low-rank coupling co-cluster each point with its image under the Monge map. We leverage this invariant to derive an algorithm, _Hierarchical Refinement_ (`HiRef`), that dynamically constructs a multiscale partition of each dataset using low-rank OT subproblems, culminating in a bijective coupling. Hierarchical Refinement uses linear space and has log-linear runtime, retaining the space advantage of low-rank OT while overcoming its limited resolution. We demonstrate the advantages of Hierarchical Refinement on several datasets, including ones containing over a million points, scaling full-rank OT to problems previously beyond Sinkhorn's reach.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#20SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs[PDF35][Copy][Kimi36][REL]",
    "authors": [
      "Authors:\n                Xin Su",
      "Man Luo",
      "Kris Pan",
      "Tien Pei Chou",
      "Vasudev Lal",
      "Phillip Howard"
    ],
    "affiliations": [],
    "summary": "Multimodal retrieval-augmented generation (RAG) plays a crucial role in domains such as knowledge-based visual question answering (KB-VQA), where models should effectively integrate additional knowledge to generate a response. However, existing vision and language models (VLMs) are not inherently designed for context-augmented generation, limiting their effectiveness in such tasks. While synthetic data generation has recently gained attention for training large VLMs, its application for context-augmented generation remains underexplored. To address this gap, we introduce SKVQA, a large-scale synthetic multimodal dataset containing over 2 million visual question-answer pairs, each associated with external knowledge sources to determine the final answer. Compared to previous datasets, SKVQA exhibits 11× more unique questions, greater domain diversity, and a broader spectrum of image sources. Through human evaluations, we confirm the high quality of the generated question-answer pairs and their contextual relevance. Extensive experiments show that SKVQA serves both as a challenging benchmark for knowledge-based VQA and as an effective training resource for adapting generative multimodal models to context-augmented generation. Our results further indicate that models trained on SKVQA demonstrate enhanced generalization in both context-aware VQA and multimodal RAG settings.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#21In-Context Denoising with One-Layer Transformers: Connections between Attention and Associative Memory Retrieval[PDF40][Copy][Kimi50][REL]",
    "authors": [
      "Authors:\n                Matthew Smart",
      "Alberto Bietti",
      "Anirvan Sengupta"
    ],
    "affiliations": [],
    "summary": "We introduce in-context denoising, a task that refines the connection between attention-based architectures and dense associative memory (DAM) networks, also known as modern Hopfield networks. Using a Bayesian framework, we show theoretically and empirically that certain restricted denoising problems can be solved optimally even by a single-layer transformer. We demonstrate that a trained attention layer processes each denoising prompt by performing a single gradient descent update on a context-aware DAM energy landscape, where context tokens serve as associative memories and the query token acts as an initial state. This one-step update yields better solutions than exact retrieval of either a context token or a spurious local minimum, providing a concrete example of DAM networks extending beyond the standard retrieval paradigm. Overall, this work solidifies the link between associative memory and attention mechanisms first identified by Ramsauer et al., and demonstrates the relevance of associative memory models in the study of in-context learning.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#22Scaling Collapse Reveals Universal Dynamics in Compute-Optimally Trained Neural Networks[PDF18][Copy][Kimi30][REL]",
    "authors": [
      "Authors:\n                Shikai Qiu",
      "Lechao Xiao",
      "Andrew Wilson",
      "Jeffrey Pennington",
      "Atish Agarwala"
    ],
    "affiliations": [],
    "summary": "Understanding neural network training dynamics at scale is an important open problem. Although realistic model architectures, optimizers, and data interact in complex ways that make predictive theory challenging, we show that compute-optimally trained models exhibit remarkably precise collective regularities. Specifically, loss curves from models of varying sizes collapse onto a single universal curve when training compute and loss are normalized to unity at the end of training. With learning rate decay, discrepancies between normalized curves fall below the noise floor of individual models' loss curves across random seeds, yielding an exceptionally tight collapse we term \"supercollapse.\" We observe supercollapse across learning rate schedules, datasets, and architectures, including transformers trained on next-token prediction. This collapse breaks down when hyperparameters are scaled suboptimally, providing a practical indicator of proper scaling. We explain these phenomena by connecting collapse to the power-law structure in typical neural scaling laws, and analyzing a simple but effective model of SGD noise dynamics that accurately captures how learning rate schedules deform loss curves away from power laws while preserving universality, and why learning rate decay suppresses variance to enable supercollapse.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#24Flowing Datasets with Wasserstein over Wasserstein Gradient Flows[PDF18][Copy][Kimi28][REL]",
    "authors": [
      "Authors:\n                Clément Bonet",
      "Christophe Vauthier",
      "Anna Korba"
    ],
    "affiliations": [],
    "summary": "Many applications in machine learning involve data represented as probability distributions. The emergence of such data requires radically novel techniques to design tractable gradient flows on probability distributions over this type of (infinite-dimensional) objects. For instance, being able to flow labeled datasets is a core task for applications ranging from domain adaptation to transfer learning or dataset distillation. In this setting, we propose to represent each class by the associated conditional distribution of features, and to model the dataset as a mixture distribution supported on these classes (which are themselves probability distributions), meaning that labeled datasets can be seen as probability distributions over probability distributions. We endow this space with a metric structure from optimal transport, namely the Wasserstein over Wasserstein (WoW) distance, derive a differential structure on this space, and define WoW gradient flows. The latter enables to design dynamics over this space that decrease a given objective functional. We apply our framework to transfer learning and dataset distillation tasks, leveraging our gradient flow construction as well as novel tractable functionals that take the form of Maximum Mean Discrepancies with Sliced-Wasserstein based kernels between probability distributions.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#25Learning dynamics in linear recurrent neural networks[PDF34][Copy][Kimi26][REL]",
    "authors": [
      "Authors:\n                Alexandra Proca",
      "Clémentine Dominé",
      "Murray Shanahan",
      "Pedro Mediano"
    ],
    "affiliations": [],
    "summary": "Recurrent neural networks (RNNs) are powerful models used widely in both machine learning and neuroscience to learn tasks with temporal dependencies and to model neural dynamics. However, despite significant advancements in the theory of RNNs, there is still limited understanding of their learning process and the impact of the temporal structure of data. Here, we bridge this gap by analyzing the learning dynamics of linear RNNs (LRNNs) analytically, enabled by a novel framework that accounts for task dynamics. Our mathematical result reveals four key properties of LRNNs: (1) Learning of data singular values is ordered by both scale and temporal precedence, such that singular values that are larger and occur later are learned faster. (2) Task dynamics impact solution stability and extrapolation ability. (3) The loss function contains an effective regularization term that incentivizes small weights and mediates a tradeoff between recurrent and feedforward computation. (4) Recurrence encourages feature learning, as shown through a novel derivation of the neural tangent kernel for finite-width LRNNs. As a final proof-of-concept, we apply our theoretical framework to explain the behavior of LRNNs performing sensory integration tasks. Our work provides a first analytical treatment of the relationship between the temporal dependencies in tasks and learning dynamics in LRNNs, building a foundation for understanding how complex dynamic behavior emerges in cognitive models.",
    "link": null,
    "published_date": null,
    "conference": "ICML",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#2GraphNarrator: Generating Textual Explanations for Graph Neural Networks[PDF117][Copy][Kimi105][REL]",
    "authors": [
      "Authors:\n                Bo Pan",
      "Zhen Xiong",
      "Guanchen Wu",
      "Zheng Zhang",
      "Yifei Zhang",
      "Yuntong Hu",
      "Liang Zhao"
    ],
    "affiliations": [],
    "summary": "Graph representation learning has garnered significant attention due to its broad applications in various domains, such as recommendation systems and social network analysis. Despite advancements in graph learning methods, challenges still remain in explainability when graphs are associated with semantic features. In this paper, we present GraphNarrator, the first method designed to generate natural language explanations for Graph Neural Networks. GraphNarrator employs a generative language model that maps input-output pairs to explanations reflecting the model’s decision-making process. To address the lack of ground truth explanations to train the model, we propose first generating pseudo-labels that capture the model’s decisions from saliency-based explanations, then using Expert Iteration to iteratively train the pseudo-label generator based on training objectives on explanation quality. The high-quality pseudo-labels are finally utilized to train an end-to-end explanation generator model. Extensive experiments are conducted to demonstrate the effectiveness of GraphNarrator in producing faithful, concise, and human-preferred natural language explanations.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#4ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming[PDF54][Copy][Kimi48][REL]",
    "authors": [
      "Authors:\n                Xinwei Yang",
      "Zhaofeng Liu",
      "Chen Huang",
      "Jiashuai Zhang",
      "Tong Zhang",
      "Yifan Zhang",
      "Wenqiang Lei"
    ],
    "affiliations": [],
    "summary": "While recent research increasingly emphasizes the value of human-LLM collaboration in competitive programming and proposes numerous empirical methods, a comprehensive understanding remains elusive due to the fragmented nature of existing studies and their use of diverse, application-specific human feedback. Thus, our work serves a three-fold purpose: First, we present the first taxonomy of human feedback consolidating the entire programming process, which promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a novel programming dataset specifically designed for human-LLM collaboration, meticulously annotated to enable large-scale simulated human feedback and facilitate cost-effective real human interaction studies. Third, we introduce ELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM competitive programming. With ELABORATION, we pinpoint strengthes and weaknesses of existing methods, thereby setting the foundation for furture improvement. Our dataset and code will be openly released.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#5The Impossibility of Fair LLMs[PDF63][Copy][Kimi82][REL]",
    "authors": [
      "Authors:\n                Jacy Reese Anthis",
      "Kristian Lum",
      "Michael Ekstrand",
      "Avi Feller",
      "Chenhao Tan"
    ],
    "affiliations": [],
    "summary": "The rise of general-purpose artificial intelligence (AI) systems, particularly large language models (LLMs), has raised pressing moral questions about how to reduce bias and ensure fairness at scale. Researchers have documented a sort of “bias” in the significant correlations between demographics (e.g., race, gender) in LLM prompts and responses, but it remains unclear how LLM fairness could be evaluated with more rigorous definitions, such as group fairness or fair representations. We analyze a variety of technical fairness frameworks and find inherent challenges in each that make the development of a fair LLM intractable. We show that each framework either does not logically extend to the general-purpose AI context or is infeasible in practice, primarily due to the large amounts of unstructured training data and the many potential combinations of human populations, use cases, and sensitive attributes. These inherent challenges would persist for general-purpose AI, including LLMs, even if empirical challenges, such as limited participatory input and limited measurement methods, were overcome. Nonetheless, fairness will remain an important type of model evaluation, and there are still promising research directions, particularly the development of standards for the responsibility of LLM developers, context-specific evaluations, and methods of iterative, participatory, and AI-assisted evaluation that could scale fairness across the diverse contexts of modern human-AI interaction.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#7Bias in Language Models: Beyond Trick Tests and Towards RUTEd Evaluation[PDF59][Copy][Kimi39][REL]",
    "authors": [
      "Authors:\n                Kristian Lum",
      "Jacy Reese Anthis",
      "Kevin Robinson",
      "Chirag Nagpal",
      "Alexander Nicholas D’Amour"
    ],
    "affiliations": [],
    "summary": "Standard bias benchmarks used for large language models (LLMs) measure the association between social attributes in model inputs and single-word model outputs. We test whether these benchmarks are robust to lengthening the model outputs via a more realistic user prompt, in the commonly studied domain of gender-occupation bias, as a step towards measuring Realistic Use and Tangible Effects (i.e., RUTEd evaluations). From the current literature, we adapt three standard metrics of next-word prediction (neutrality, skew, and stereotype), and we develop analogous RUTEd evaluations in three contexts of real-world LLM use: children’s bedtime stories, user personas, and English language learning exercises. We find that standard bias metrics have no significant correlation with long-form output metrics. For example, selecting the least biased model based on the standard “trick tests” coincides with selecting the least biased model based on longer output no more than random chance. There may not yet be evidence to justify standard benchmarks as reliable proxies of real-world biases, and we encourage further development of context-specific RUTEd evaluations.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#8Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models[PDF64][Copy][Kimi60][REL]",
    "authors": [
      "Authors:\n                Wenhan Liu",
      "Xinyu Ma",
      "Yutao Zhu",
      "Ziliang Zhao",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Zhicheng Dou"
    ],
    "affiliations": [],
    "summary": "Large Language Models (LLMs) have shown exciting performance in listwise passage ranking. Due to the limited input length, existing methods often adopt the sliding window strategy. Such a strategy, though effective, is inefficient as it involves repetitive and serialized processing, which usually re-evaluates relevant passages multiple times. As a result, it incurs redundant API costs, which are proportional to the number of inference tokens. The development of long-context LLMs enables the full ranking of all passages within a single inference, avoiding redundant API costs. In this paper, we conduct a comprehensive study of long-context LLMs for ranking tasks in terms of efficiency and effectiveness. Surprisingly, our experiments reveal that full ranking with long-context LLMs can deliver superior performance in the supervised fine-tuning setting with a huge efficiency improvement. Furthermore, we identify two limitations of fine-tuning the full ranking model based on existing methods: (1) sliding window strategy fails to produce a full ranking list as a training label, and (2) the language modeling loss cannot emphasize top-ranked passage IDs in the label. To alleviate these issues, we propose a new complete listwise label construction approach and a novel importance-aware learning objective for full ranking. Experiments show the superior performance of our method over baselines.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#11StrucText-Eval: Evaluating Large Language Model’s Reasoning Ability in Structure-Rich Text[PDF40][Copy][Kimi40][REL]",
    "authors": [
      "Authors:\n                Zhouhong Gu",
      "Haoning Ye",
      "Xingzhou Chen",
      "Zeyang Zhou",
      "Hongwei Feng",
      "Yanghua Xiao"
    ],
    "affiliations": [],
    "summary": "The effective utilization of structured data, integral to corporate data strategies, has been challenged by the rise of large language models (LLMs) capable of processing unstructured information. This shift prompts the question: can LLMs interpret structured data directly in its unstructured form? We propose an automatic evaluation data generation method for assessing LLMs’ reasoning capabilities on structure-rich text to explore this. Our approach supports 8 structured languages and 29 tasks, generating data with adjustable complexity through controllable nesting and structural width. We introduce StrucText-Eval, a benchmark containing 5,800 pre-generated and annotated samples designed to evaluate how well LLMs understand and reason through structured text. StrucText-Eval is divided into two suites: a regular Test suite (3,712 samples) and a Test-Hard suite (2,088 samples), the latter emphasizing the gap between human and model performance on more complex tasks. Experimental results show that while open-source LLMs achieve a maximum accuracy of 74.9% on the standard dataset, their performance drops significantly to 45.8% on the harder dataset. In contrast, human participants reach an accuracy of 92.6% on StrucText-Eval-Hard, highlighting LLMs’ current limitations in handling intricate structural information.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#12Literature Meets Data: A Synergistic Approach to Hypothesis Generation[PDF30][Copy][Kimi30][REL]",
    "authors": [
      "Authors:\n                Haokun Liu",
      "Yangqiaoyu Zhou",
      "Mingxuan Li",
      "Chenfei Yuan",
      "Chenhao Tan"
    ],
    "affiliations": [],
    "summary": "AI holds promise for transforming scientific processes, including hypothesis generation. Prior work on hypothesis generation can be broadly categorized into theory-driven and data-driven approaches. While both have proven effective in generating novel and plausible hypotheses, it remains an open question whether they can complement each other. To address this, we develop the first method that combines literature-based insights with data to perform LLM-powered hypothesis generation. We apply our method on five different datasets and demonstrate that integrating literature and data outperforms other baselines (8.97% over few-shot, 15.75% over literature-based alone, and 3.37% over data-driven alone). Additionally, we conduct the first human evaluation to assess the utility of LLM-generated hypotheses in assisting human decision-making on two challenging tasks: deception detection and AI generated content detection. Our results show that human accuracy improves significantly by 7.44% and 14.19% on these tasks, respectively. These findings suggest that integrating literature-based and data-driven approaches provides a comprehensive and nuanced framework for hypothesis generation and could open new avenues for scientific inquiry.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#13GAPO: Learning Preferential Prompt through Generative Adversarial Policy Optimization[PDF80][Copy][Kimi59][REL]",
    "authors": [
      "Authors:\n                Zhouhong Gu",
      "Xingzhou Chen",
      "Xiaoran Shi",
      "Tao Wang",
      "Suhang Zheng",
      "Tianyu Li",
      "Hongwei Feng",
      "Yanghua Xiao"
    ],
    "affiliations": [],
    "summary": "Authors:Zhouhong Gu,Xingzhou Chen,Xiaoran Shi,Tao Wang,Suhang Zheng,Tianyu Li,Hongwei Feng,Yanghua Xiao",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#14Tree-of-Evolution: Tree-Structured Instruction Evolution for Code Generation in Large Language Models[PDF39][Copy][Kimi31][REL]",
    "authors": [
      "Authors:\n                Ziyang Luo",
      "Kaixin Li",
      "Hongzhan Lin",
      "Yuchen Tian",
      "Mohan Kankanhalli",
      "Jing Ma"
    ],
    "affiliations": [],
    "summary": "Data synthesis has become a crucial research area in large language models (LLMs), especially for generating high-quality instruction fine-tuning data to enhance downstream performance. In code generation, a key application of LLMs, manual annotation of code instruction data is costly. Recent methods, such as Code Evol-Instruct and OSS-Instruct, leverage LLMs to synthesize large-scale code instruction data, significantly improving LLM coding capabilities. However, these approaches face limitations due to unidirectional synthesis and randomness-driven generation, which restrict data quality and diversity. To overcome these challenges, we introduce Tree-of-Evolution (ToE), a novel framework that models code instruction synthesis process with a tree structure, exploring multiple evolutionary paths to alleviate the constraints of unidirectional generation. Additionally, we propose optimization-driven evolution, which refines each generation step based on the quality of the previous iteration. Experimental results across five widely-used coding benchmarks—HumanEval, MBPP, EvalPlus, LiveCodeBench, and BigCodeBench—demonstrate that base models fine-tuned on just 75k data synthesized by our method achieve comparable or superior performance to the state-of-the-art open-weight Code LLM, Qwen2.5-Coder-Instruct, which was fine-tuned on millions of samples.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#15Delving into Multilingual Ethical Bias: The MSQAD with Statistical Hypothesis Tests for Large Language Models[PDF14][Copy][Kimi19][REL]",
    "authors": [
      "Authors:\n                Seunguk Yu",
      "Juhwan Choi",
      "YoungBin Kim"
    ],
    "affiliations": [],
    "summary": "Despite the recent strides in large language models, studies have underscored the existence of social biases within these systems. In this paper, we delve into the validation and comparison of the ethical biases of LLMs concerning globally discussed and potentially sensitive topics, hypothesizing that these biases may arise from language-specific distinctions. Introducing the Multilingual Sensitive Questions & Answers Dataset (**MSQAD**), we collected news articles from Human Rights Watch covering 17 topics, and generated socially sensitive questions along with corresponding responses in multiple languages. We scrutinized the biases of these responses across languages and topics, employing two statistical hypothesis tests. The results showed that the null hypotheses were rejected in most cases, indicating biases arising from cross-language differences. It demonstrates that ethical biases in responses are widespread across various languages, and notably, these biases were prevalent even among different LLMs. By making the proposed MSQAD openly available, we aim to facilitate future research endeavors focused on examining cross-language biases in LLMs and their variant models.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#16ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision[PDF23][Copy][Kimi28][REL]",
    "authors": [
      "Authors:\n                Dosung Lee",
      "Wonjun Oh",
      "Boyoung Kim",
      "Minyoung Kim",
      "Joonsuk Park",
      "Paul Hongsuck Seo"
    ],
    "affiliations": [],
    "summary": "Multi-hop question answering (MHQA) involves reasoning across multiple documents to answer complex questions. Dense retrievers typically outperform sparse methods like BM25 by leveraging semantic embeddings in many tasks; however, they require labeled query-document pairs for fine-tuning, which poses a significant challenge in MHQA due to the complexity of the reasoning steps. To overcome this limitation, we introduce Retriever Supervision with Consistency and Relevance (ReSCORE), a novel method for training dense retrievers for MHQA without the need for labeled documents. ReSCORE leverages large language models to measure document-question relevance with answer consistency and utilizes this information to train a retriever within an iterative question-answering framework. Evaluated on three MHQA benchmarks, our extensive experiments demonstrate the effectiveness of ReSCORE, with significant improvements in retrieval performance that consequently lead to state-of-the-art Exact Match and F1 scores for MHQA.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#17FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models[PDF43][Copy][Kimi50][REL]",
    "authors": [
      "Authors:\n                Hongzhan Lin",
      "Yang Deng",
      "Yuxuan Gu",
      "Wenxuan Zhang",
      "Jing Ma",
      "See-Kiong Ng",
      "Tat-Seng Chua"
    ],
    "affiliations": [],
    "summary": "Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMs’ fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMs’ factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#19Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients[PDF20][Copy][Kimi20][REL]",
    "authors": [
      "Authors:\n                Jabin Koo",
      "Minwoo Jang",
      "Jungseul Ok"
    ],
    "affiliations": [],
    "summary": "Federated fine-tuning for Large Language Models (LLMs) has recently gained attention due to the heavy communication overhead of transmitting large model updates. Low Rank Adaptation (LoRA) has been proposed as a solution, yet its application in federated learning is complicated by discordance in aggregation. Existing methods addressing this discordance often suffer from performance degradation at low ranks in heterogeneous data settings. In response, we introduce LoRA-A^2 (Low Rank Adaptation with Alternating freeze and Adaptive rank selection), which demonstrates robustness in challenging settings with low ranks and high data heterogeneity. Our experimental findings reveal that LoRA-A^2 maintains performance even under extreme heterogeneity and low rank conditions, achieving up to a 99.8% reduction in uploaded parameters compared to full fine-tuning without compromising performance. This adaptive mechanism boosts robustness and communication efficiency in federated fine-tuning, enabling the practical deployment of LLMs in resource-constrained environments.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#20LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs[PDF20][Copy][Kimi21][REL]",
    "authors": [
      "Authors:\n                Kaibo Liu",
      "Zhenpeng Chen",
      "Yiyang Liu",
      "Jie M. Zhang",
      "Mark Harman",
      "Yudong Han",
      "Yun Ma",
      "Yihong Dong",
      "Ge Li",
      "Gang Huang"
    ],
    "affiliations": [],
    "summary": "Authors:Kaibo Liu,Zhenpeng Chen,Yiyang Liu,Jie M. Zhang,Mark Harman,Yudong Han,Yun Ma,Yihong Dong,Ge Li,Gang Huang",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#21Capture the Key in Reasoning to Enhance CoT Distillation Generalization[PDF55][Copy][Kimi53][REL]",
    "authors": [
      "Authors:\n                Chengwei Dai",
      "Kun Li",
      "Wei Zhou",
      "Songlin Hu"
    ],
    "affiliations": [],
    "summary": "As Large Language Models (LLMs) scale up and gain powerful Chain-of-Thoughts (CoTs) reasoning abilities, practical resource constraints drive efforts to distill these capabilities into more compact Smaller Language Models (SLMs). We find that CoTs consist mainly of simple reasoning forms, with a small proportion (4.7%) of key reasoning steps that truly impact conclusions. However, previous distillation methods typically involve supervised fine-tuning student SLMs only on correct CoTs data produced by teacher LLMs, resulting in students struggling to learn the key, instead imitating the teacher’s reasoning forms and making errors or omissions in reasoning. To address these issues, drawing an analogy to human learning, where analyzing mistakes according to correct solutions often reveals the crucial steps leading to successes or failures, we propose mistakE-Driven key reasonIng step distillaTion (EDIT), a novel method that further aids SLMs learning key reasoning steps rather than mere simple fine-tuning. Firstly, to expose the crucial steps in CoTs, we carefully design specific prompts to generate dual CoTs data with similar reasoning paths but divergent conclusions. Then, we apply the minimum edit distance algorithm on the dual CoTs data to locate these key steps and optimize the likelihood on these tokens. Extensive experiments and analysis validate the effectiveness of EDIT across both in-domain(IND) and out-of-domain(OOD) benchmark reasoning datasets.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#22How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond[PDF21][Copy][Kimi23][REL]",
    "authors": [
      "Authors:\n                Chen Huang",
      "Yang Deng",
      "Wenqiang Lei",
      "Jiancheng Lv",
      "Tat-Seng Chua",
      "Jimmy Huang"
    ],
    "affiliations": [],
    "summary": "With the advancement of large language models (LLMs), intelligent models have evolved from mere tools to autonomous agents with their own goals and strategies for cooperating with humans. This evolution has birthed a novel paradigm in NLP, i.e., human-model cooperation, that has yielded remarkable progress in numerous NLP tasks in recent years. In this paper, we take the first step to present a thorough review of human-model cooperation, exploring its principles, formalizations, and open challenges. In particular, we introduce a new taxonomy that provides a unified perspective to summarize existing approaches. Also, we discuss potential frontier areas and their corresponding challenges. We regard our work as an entry point, paving the way for more breakthrough research in this regard.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#24UniICL: An Efficient ICL Framework Unifying Compression, Selection, and Generation[PDF29][Copy][Kimi30][REL]",
    "authors": [
      "Authors:\n                Jun Gao",
      "Qi Lv",
      "Zili Wang",
      "Tianxiang Wu",
      "Ziqiang Cao",
      "Wenjie Li"
    ],
    "affiliations": [],
    "summary": "In-context learning (ICL) enhances the reasoning abilities of Large Language Models (LLMs) by prepending a few demonstrations. It motivates researchers to introduce more examples to provide additional contextual information for the generation. However, existing methods show a significant limitation due to the problem of excessive growth in context length which causes a large hardware burden. Additionally, shallow-relevant examples selected by out-off-shelf tools hinder LLMs from capturing useful contextual information for generation. In this paper, to approach these limitations, we propose UniICL, a novel Unified ICL framework that unifies demonstration compression, demonstration selection, and final response generation. Furthermore, to avoid repeated compression of the same demonstration and boost inference efficiency, we design a tailored compression strategy that allows UniICL caching compression results into Demonstration Bank(DB). Extensive out-of-domain evaluations prove the advantages of UniICL in both effectiveness and efficiency.",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#25BelarusianGLUE: Towards a Natural Language Understanding Benchmark for Belarusian[PDF16][Copy][Kimi11][REL]",
    "authors": [
      "Authors:\n                Maksim Aparovich",
      "Volha Harytskaya",
      "Vladislav Poritski",
      "Oksana Volchek",
      "Pavel Smrz"
    ],
    "affiliations": [],
    "summary": "In the epoch of multilingual large language models (LLMs), it is still challenging to evaluate the models’ understanding of lower-resourced languages, which motivates further development of expert-crafted natural language understanding benchmarks. We introduce BelarusianGLUE — a natural language understanding benchmark for Belarusian, an East Slavic language, with ≈15K instances in five tasks: sentiment analysis, linguistic acceptability, word in context, Winograd schema challenge, textual entailment. A systematic evaluation of BERT models and LLMs against this novel benchmark reveals that both types of models approach human-level performance on easier tasks, such as sentiment analysis, but there is a significant gap in performance between machine and human on a harder task — Winograd schema challenge. We find the optimal choice of model type to be task-specific: e.g. BERT models underperform on textual entailment task but are competitive for linguistic acceptability. We release the datasets (https://hf.co/datasets/maaxap/BelarusianGLUE) and evaluation code (https://github.com/maaxap/BelarusianGLUE).",
    "link": null,
    "published_date": null,
    "conference": "ACL",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#1Towards Automated Error Discovery: A Study in Conversational AI[PDF35][Copy][Kimi53][REL]",
    "authors": [
      "Authors:\n                Dominic Petrak",
      "Thy Thy Tran",
      "Iryna Gurevych"
    ],
    "affiliations": [],
    "summary": "Although LLM-based conversational agents demonstrate strong fluency and coherence, they still produce undesirable behaviors (errors) that are challenging to prevent from reaching users during deployment. Recent research leverages large language models (LLMs) to detect errors and guide response-generation models toward improvement. However, current LLMs struggle to identify errors not explicitly specified in their instructions, such as those arising from updates to the response-generation model or shifts in user behavior. In this work, we introduce Automated Error Discovery, a framework for detecting and defining errors in conversational AI, and propose SEEED (Soft Clustering Extended Encoder-Based Error Detection), as an encoder-based approach to its implementation. We enhance the Soft Nearest Neighbor Loss by amplifying distance weighting for negative samples and introduce Label-Based Sample Ranking to select highly contrastive examples for better representation learning. SEEED outperforms adapted baselines—including GPT-4o and Phi-4—across multiple error-annotated dialogue datasets, improving the accuracy for detecting unknown errors by up to 8 points and demonstrating strong generalization to unknown intent detection.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#2Break the Checkbox: Challenging Closed-Style Evaluations of Cultural Alignment in LLMs[PDF8][Copy][Kimi18][REL]",
    "authors": [
      "Authors:\n                Mohsinul Kabir",
      "Ajwad Abrar",
      "Sophia Ananiadou"
    ],
    "affiliations": [],
    "summary": "A large number of studies rely on closed-style multiple-choice surveys to evaluate cultural alignment in Large Language Models (LLMs). In this work, we challenge this constrained evaluation paradigm and explore more realistic, unconstrained approaches. Using the World Values Survey (WVS) and Hofstede Cultural Dimensions as case studies, we demonstrate that LLMs exhibit stronger cultural alignment in less constrained settings, where responses are not forced. Additionally, we show that even minor changes, such as reordering survey choices, lead to inconsistent outputs, exposing the limitations of closed-style evaluations. Our findings advocate for more robust and flexible evaluation frameworks that focus on specific cultural proxies, encouraging more nuanced and accurate assessments of cultural alignment in LLMs.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#3Biased Tales: Cultural and Topic Bias in Generating Children’s Stories[PDF8][Copy][Kimi12][REL]",
    "authors": [
      "Authors:\n                Donya Rooein",
      "Vilém Zouhar",
      "Debora Nozza",
      "Dirk Hovy"
    ],
    "affiliations": [],
    "summary": "Stories play a pivotal role in human communication, shaping beliefs and morals, particularly in children. As parents increasingly rely on large language models (LLMs) to craft bedtime stories, the presence of cultural and gender stereotypes in these narratives raises significant concerns. To address this issue, we present Biased Tales, a comprehensive dataset designed to analyze how biases influence protagonists’ attributes and story elements in LLM-generated stories. Our analysis uncovers striking disparities. When the protagonist is described as a girl (as compared to a boy), appearance-related attributes increase by 55.26%. Stories featuring non-Western children disproportionately emphasize cultural heritage, tradition, and family themes far more than those for Western children. Our findings highlight the role of sociocultural bias in making creative AI use more equitable and diverse.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#4Large Language Models as Realistic Microservice Trace Generators[PDF2][Copy][Kimi16][REL]",
    "authors": [
      "Authors:\n                Donghyun Kim",
      "Sriram Ravula",
      "Taemin Ha",
      "Alex Dimakis",
      "Daehyeok Kim",
      "Aditya Akella"
    ],
    "affiliations": [],
    "summary": "Workload traces are essential to understand complex computer systems’ behavior and manage processing and memory resources. Since real-world traces are hard to obtain, synthetic trace generation is a promising alternative. This paper proposes a first-of-a-kind approach that relies on training a large language model (LLM) to generate synthetic workload traces, specifically microservice call graphs. To capture complex and arbitrary hierarchical structures and implicit constraints in such traces, we propose to train LLMs to generate recursively, making call graph generation a sequence of more manageable steps. To further enforce learning constraints on the traces and generate uncommon situations, we apply additional instruction tuning steps to align our model with the desired trace features. With this method, we train TraceLLM, an LLM for microservice trace generation, and demonstrate that it produces diverse, realistic traces under varied conditions, outperforming existing approaches in both accuracy and validity. The synthetically generated traces can effectively replace real data to optimize important microservice management tasks. Additionally, TraceLLM adapts to downstream trace-related tasks, such as predicting key trace features and infilling missing data.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#6QFrCoLA: a Quebec-French Corpus of Linguistic Acceptability Judgments[PDF2][Copy][Kimi3][REL]",
    "authors": [
      "Authors:\n                David Beauchemin",
      "Richard Khoury"
    ],
    "affiliations": [],
    "summary": "Large and Transformer-based language models perform outstandingly in various downstream tasks. However, there is limited understanding regarding how these models internalize linguistic knowledge, so various linguistic benchmarks have recently been proposed to facilitate syntactic evaluation of language models across languages. This paper introduces QFrCoLA (Quebec-French Corpus of Linguistic Acceptability Judgments), a normative binary acceptability judgments dataset comprising 25,153 in-domain and 2,675 out-of-domain sentences. Our study leverages the QFrCoLA dataset and seven other linguistic binary acceptability judgment corpora to benchmark seven language models. The results demonstrate that, on average, fine-tuned Transformer-based LM are strong baselines for most languages and that zero-shot binary classification large language models perform poorly on the task. However, for the QFrCoLA benchmark, on average, a fine-tuned Transformer-based LM outperformed other methods tested. It also shows that pre-trained cross-lingual LLMs selected for our experimentation do not seem to have acquired linguistic judgment capabilities during their pre-training for Quebec French. Finally, our experiment results on QFrCoLA show that our dataset, built from examples that illustrate linguistic norms rather than speakers’ feelings, is similar to linguistic acceptability judgment; it is a challenging dataset that can benchmark LM on their linguistic judgment capabilities.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#7Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?[PDF3][Copy][Kimi12][REL]",
    "authors": [
      "Authors:\n                Siqi Shen",
      "Mehar Singh",
      "Lajanugen Logeswaran",
      "Moontae Lee",
      "Honglak Lee",
      "Rada Mihalcea"
    ],
    "affiliations": [],
    "summary": "The value orientation of Large Language Models (LLMs) has been extensively studied, as it can shape user experiences across demographic groups.However, two key challenges remain: (1) the lack of systematic comparison across value probing strategies, despite the Multiple Choice Question (MCQ) setting being vulnerable to perturbations, and (2) the uncertainty over whether probed values capture in-context information or predict models’ real-world actions.In this paper, we systematically compare three widely used value probing methods: token likelihood, sequence perplexity, and text generation.Our results show that all three methods exhibit large variances under non-semantic perturbations in prompts and option formats, with sequence perplexity being the most robust overall.We further introduce two tasks to assess expressiveness: demographic prompting, testing whether probed values adapt to cultural context; and value–action agreement, testing the alignment of probed values with value-based actions.We find that demographic context has little effect on the text generation method, and probed values only weakly correlate with action preferences across all methods.Our work highlights the instability and the limited expressive power of current value probing methods, calling for more reliable LLM value representations.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#8A Systematic Analysis of Base Model Choice for Reward Modeling[PDF8][Copy][Kimi8][REL]",
    "authors": [
      "Authors:\n                Kian Ahrabian",
      "Pegah Jandaghi",
      "Negar Mokhberian",
      "Sai Praneeth Karimireddy",
      "Jay Pujara"
    ],
    "affiliations": [],
    "summary": "Reinforcement learning from human feedback (RLHF) and, at its core, reward modeling have become a crucial part of training powerful large language models (LLMs). One commonly overlooked factor in training high-quality reward models (RMs) is the effect of the base model, which is becoming more challenging to choose given the rapidly growing pool of LLMs. In this work, we present a systematic analysis of the effect of base model selection on reward modeling performance. Our results show that the performance can be improved by up to 14% compared to the most common (i.e., default) choice. Moreover, we showcase the strong statistical relation between some existing benchmarks and downstream performances. We also demonstrate that the results from a small set of benchmarks could be combined to boost the model selection (+18% on average in the top 5-10). Lastly, we illustrate the impact of different post-training steps on the final performance and explore using estimated data distributions to reduce performance prediction error.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#9Comparing Specialised Small and General Large Language Models on Text Classification: 100 Labelled Samples to Achieve Break-Even Performance[PDF8][Copy][Kimi12][REL]",
    "authors": [
      "Authors:\n                Branislav Pecher",
      "Ivan Srba",
      "Maria Bielikova"
    ],
    "affiliations": [],
    "summary": "When solving NLP tasks with limited labelled data, researchers typically either use a general large language model without further update, or use a small number of labelled samples to tune a specialised smaller model. In this work, we answer an important question – how many labelled samples are required for the specialised small models to outperform general large models, while taking the performance variance into consideration. By observing the behaviour of fine-tuning, instruction-tuning, prompting and in-context learning on 8 language models, we identify such performance break-even points across 8 representative text classification tasks of varying characteristics. We show that the specialised models often need only few samples (on average 100) to be on par or better than the general ones. At the same time, the number of required labels strongly depends on the dataset or task characteristics, with fine-tuning on binary datasets requiring significantly more samples. When performance variance is taken into consideration, the number of required labels increases on average by 100 - 200%. Finally, larger models do not consistently lead to better performance and lower variance, with 4-bit quantisation having negligible impact.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#10Is the Top Still Spinning? Evaluating Subjectivity in Narrative Understanding[PDF1][Copy][Kimi8][REL]",
    "authors": [
      "Authors:\n                Melanie Subbiah",
      "Akankshya Mishra",
      "Grace Kim",
      "Liyan Tang",
      "Greg Durrett",
      "Kathleen McKeown"
    ],
    "affiliations": [],
    "summary": "Determining faithfulness of a claim to a source document is an important problem across many domains. This task is generally treated as a binary judgment of whether the claim is supported or unsupported in relation to the source. In many cases, though, whether a claim is supported can be ambiguous. For instance, it may depend on making inferences from given evidence, and different people can reasonably interpret the claim as either supported or unsupported based on their agreement with those inferences. Forcing binary labels upon such claims lowers the reliability of evaluation. In this work, we reframe the task to manage the subjectivity involved with factuality judgments of ambiguous claims. We introduce LLM-generated edits of summaries as a method of providing a nuanced evaluation of claims: how much does a summary need to be edited to be unambiguous? Whether a claim gets rewritten and how much it changes can be used as an automatic evaluation metric, the Ambiguity Rewrite Metric (ARM), with a much richer feedback signal than a binary judgment of faithfulness. We focus on the area of narrative summarization as it is particularly rife with ambiguity and subjective interpretation. We show that ARM produces a 21% absolute improvement in annotator agreement on claim faithfulness, indicating that subjectivity is reduced.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#11MathTutorBench: A Benchmark for Measuring Open-ended Pedagogical Capabilities of LLM Tutors[PDF1][Copy][Kimi4][REL]",
    "authors": [
      "Authors:\n                Jakub Macina",
      "Nico Daheim",
      "Ido Hakimi",
      "Manu Kapur",
      "Iryna Gurevych",
      "Mrinmaya Sachan"
    ],
    "affiliations": [],
    "summary": "Evaluating the pedagogical capabilities of AI-based tutoring models is critical for making guided progress in the field. Yet, we lack a reliable, easy-to-use, and simple-to-run evaluation that reflects the pedagogical abilities of models. To fill this gap, we present MathTutorBench, an open-source benchmark for holistic tutoring model evaluation. MathTutorBench contains a collection of datasets and metrics that broadly cover tutor abilities as defined by learning sciences research in dialog-based teaching. To score the pedagogical quality of open-ended teacher responses, we train a reward model and show it can discriminate expert from novice teacher responses with high accuracy. We evaluate a wide set of closed- and open-weight models on MathTutorBench and find that subject expertise, indicated by solving ability, does not immediately translate to good teaching. Rather, pedagogy and subject expertise appear to form a trade-off that is navigated by the degree of tutoring specialization of the model. Furthermore, tutoring appears to become more challenging in longer dialogs, where simpler questioning strategies begin to fail. We release the benchmark, code, and leaderboard openly to enable rapid benchmarking of future models.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#12Preemptive Detection and Correction of Misaligned Actions in LLM Agents[PDF6][Copy][Kimi8][REL]",
    "authors": [
      "Authors:\n                Haishuo Fang",
      "Xiaodan Zhu",
      "Iryna Gurevych"
    ],
    "affiliations": [],
    "summary": "Deploying LLM-based agents in real-life applications often faces a critical challenge: the misalignment between agents’ behavior and user intent. Such misalignment may lead agents to unintentionally execute some critical actions that carry negative outcomes (e.g., accidentally triggering a buy-now in web shopping), resulting in undesirable or even irreversible consequences. Although addressing these issues is crucial, the preemptive detection and correction of misaligned actions remains relatively underexplored. To fill this gap, we introduce InferAct, a novel approach that leverages the belief reasoning ability of LLMs, grounded in Theory-of-Mind, to detect misaligned actions. Once the misalignment is detected, InferAct alerts users for timely correction, preventing adverse outcomes and enhancing the reliability of LLM agents’ decision-making processes. Experiments on three widely used tasks demonstrate InferAct achieves up to 20% improvements on Marco-F1 against baselines in misaligned action detection. An in-depth evaluation of misalignment correction further highlights InferAct‘s effectiveness in improving agent alignment.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#13Fingerprinting LLMs through Survey Item Factor Correlation: A Case Study on Humor Style Questionnaire[PDF2][Copy][Kimi7][REL]",
    "authors": [
      "Author:\n                Simon Münker"
    ],
    "affiliations": [],
    "summary": "LLMs increasingly engage with psychological instruments, yet how they represent constructs internally remains poorly understood. We introduce a novel approach to “fingerprinting” LLMs through their factor correlation patterns on standardized psychological assessments to deepen the understanding of LLMs constructs representation. Using the Humor Style Questionnaire as a case study, we analyze how six LLMs represent and correlate humor-related constructs to survey participants. Our results show that they exhibit little similarity to human response patterns. In contrast, participants’ subsamples demonstrate remarkably high internal consistency. Exploratory graph analysis further confirms that no LLM successfully recovers the four constructs of the Humor Style Questionnaire. These findings suggest that despite advances in natural language capabilities, current LLMs represent psychological constructs in fundamentally different ways than humans, questioning the validity of application as human simulacra.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#14Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval[PDF2][Copy][Kimi6][REL]",
    "authors": [
      "Authors:\n                Tianlu Zheng",
      "Yifan Zhang",
      "Xiang An",
      "Ziyong Feng",
      "Kaicheng Yang",
      "Qichuan Ding"
    ],
    "affiliations": [],
    "summary": "Although Contrastive Language-Image Pre-training (CLIP) exhibits strong performance across diverse vision tasks, its application to person representation learning faces two critical challenges: (i) the scarcity of large-scale annotated vision-language data focused on person-centric images, and (ii) the inherent limitations of global contrastive learning, which struggles to maintain discriminative local features crucial for fine-grained matching while remaining vulnerable to noisy text tokens. This work advances CLIP for person representation learning through synergistic improvements in data curation and model architecture. First, we develop a noise-resistant data construction pipeline that leverages the in-context learning capabilities of MLLMs to automatically filter and caption web-sourced images. This yields WebPerson, a large-scale dataset of 5M high-quality person-centric image-text pairs. Second, we introduce the GA-DMS (Gradient-Attention Guided Dual-Masking Synergetic) framework, which improves cross-modal alignment by adaptively masking noisy textual tokens based on the gradient-attention similarity score. Additionally, we incorporate masked token prediction objectives that compel the model to predict informative text tokens, enhancing fine-grained semantic representation learning. Extensive experiments show that GA-DMS achieves state-of-the-art performance across multiple benchmarks. The data and pre-trained models are released at https://github.com/Multimodal-Representation-Learning-MRL/GA-DMS.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#15From Problem-Solving to Teaching Problem-Solving: Aligning LLMs with Pedagogy using Reinforcement Learning[PDF5][Copy][Kimi6][REL]",
    "authors": [
      "Authors:\n                David Dinucu-Jianu",
      "Jakub Macina",
      "Nico Daheim",
      "Ido Hakimi",
      "Iryna Gurevych",
      "Mrinmaya Sachan"
    ],
    "affiliations": [],
    "summary": "Large language models (LLMs) can transform education, but their optimization for direct question-answering often undermines effective pedagogy which requires strategically withholding answers. To mitigate this, we propose an online reinforcement learning (RL)-based alignment framework that can quickly adapt LLMs into effective tutors using simulated student-tutor interactions by emphasizing pedagogical quality and guided problem-solving over simply giving away answers. We use our method to train a 7B parameter tutor model without human annotations which reaches similar performance to larger proprietary models like LearnLM. We introduce a controllable reward weighting to balance pedagogical support and student solving accuracy, allowing us to trace the Pareto frontier between these two objectives. Our models better preserve reasoning capabilities than single-turn SFT baselines and can optionally enhance interpretability through thinking tags that expose the model’s instructional planning.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#17Permutative Preference Alignment from Listwise Ranking of Human Judgments[PDF3][Copy][Kimi4][REL]",
    "authors": [
      "Authors:\n                Yang Zhao",
      "Yixin Wang",
      "Mingzhang Yin"
    ],
    "affiliations": [],
    "summary": "Aligning Large Language Models (LLMs) with human preferences is crucial in ensuring desirable and controllable model behaviors. Current methods, such as Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO), rely on the Bradley-Terry (B-T) model to maximize the likelihood of pairwise choices. However, when multiple responses are available, the B-T model fails to guarantee an accurate list ranking of the responses. To address this issue, we propose Permutative Preference Alignment (PPA), a novel offline listwise approach that incorporates the Normalized Discounted Cumulative Gain (NDCG)—a widely-used ranking metric—as an alternative training objective for LLM alignment. We develop an end-to-end alignment algorithm by approximating NDCG with a differentiable surrogate loss. Experiments demonstrate that PPA outperforms existing pairwise and listwise methods on evaluation sets and general benchmarks such as AlpacaEval. Furthermore, we show that NDCG-based approaches improve ranking accuracy more effectively than B-T-based methods and provide a theoretical explanation for this improvement.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#18ToneCraft: Cantonese Lyrics Generation with Harmony of Tones and Pitches[PDF4][Copy][Kimi5][REL]",
    "authors": [
      "Authors:\n                Junyu Cheng",
      "Chang Pan",
      "Shuangyin Li"
    ],
    "affiliations": [],
    "summary": "Lyrics generation has garnered increasing attention within the artificial intelligence community. Our task focuses on generating harmonious Cantonese lyrics. Unlike other languages, Cantonese has a unique system of nine contours and six tones, making it essential to satisfy the harmony rules that ensure the alignment between the melody and the tonal contours of the lyrics when composing lyrics. Current research has not yet addressed the challenge of generating lyrics that adhere to Cantonese harmony rules. To tackle this issue, we propose ToneCraft, a novel framework for generating Cantonese lyrics that ensures tonal and melodic harmony. It enables LLMs to generate lyrics with a fixed character count while aligning with tonal and melodic structures. We present an algorithm that combines character-level control, melodic guidance, and a task-specific loss to achieve tonal harmony without compromising generation flexibility and quality. By incorporating domain-specific expertise, we leverage pure lyric datasets to train our model, eliminating the need for aligned data. Both objective evaluations and subjective assessments show that our generated lyrics align with melodic contours significantly better than existing methods. All code and data are available at: https://github.com/purepasser-by/ToneCraft.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#19SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition[PDF4][Copy][Kimi5][REL]",
    "authors": [
      "Authors:\n                Zechen Li",
      "Shohreh Deldari",
      "Linyao Chen",
      "Hao Xue",
      "Flora D. Salim"
    ],
    "affiliations": [],
    "summary": "We introduce SensorLLM, a two-stage framework that enables Large Language Models (LLMs) to perform human activity recognition (HAR) from sensor time-series data. Despite their strong reasoning and generalization capabilities, LLMs remain underutilized for motion sensor data due to the lack of semantic context in time-series, computational constraints, and challenges in processing numerical inputs. SensorLLM addresses these limitations through a Sensor-Language Alignment stage, where the model aligns sensor inputs with trend descriptions. Special tokens are introduced to mark channel boundaries. This alignment enables LLMs to capture numerical variations, channel-specific features, and data of varying durations, without requiring human annotations. In the subsequent Task-Aware Tuning stage, we refine the model for HAR classification, achieving performance that matches or surpasses state-of-the-art methods. Our results demonstrate that SensorLLM evolves into an effective sensor learner, reasoner, and classifier through human-intuitive Sensor-Language Alignment, generalizing across diverse HAR datasets. We believe this work establishes a foundation for future research on time-series and text alignment, paving the way for foundation models in sensor data analysis. Our codes are available at https://github.com/zechenli03/SensorLLM.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#20MixLoRA-DSI: Dynamically Expandable Mixture-of-LoRA Experts for Rehearsal-Free Generative Retrieval over Dynamic Corpora[PDF1][Copy][Kimi3][REL]",
    "authors": [
      "Authors:\n                Tuan-Luc Huynh",
      "Thuy-Trang Vu",
      "Weiqing Wang",
      "Trung Le",
      "Dragan Gasevic",
      "Yuan-Fang Li",
      "Thanh-Toan Do"
    ],
    "affiliations": [],
    "summary": "Continually updating model-based indexes in generative retrieval with new documents remains challenging, as full retraining is computationally expensive and impractical under resource constraints. We propose MixLoRA-DSI, a novel framework that combines an expandable mixture of Low-Rank Adaptation experts with a layer-wise out-of-distribution (OOD)-driven expansion strategy. Instead of allocating new experts for each new corpus, our proposed expansion strategy enables sublinear parameter growth by selectively introducing new experts only when significant number of OOD documents are detected. Experiments on NQ320k and MS MARCO Passage demonstrate that MixLoRA-DSI outperforms full-model update baselines, with minimal parameter overhead and substantially lower training costs.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#22DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments[PDF12][Copy][Kimi14][REL]",
    "authors": [
      "Authors:\n                Yuxiang Zheng",
      "Dayuan Fu",
      "Xiangkun Hu",
      "Xiaojie Cai",
      "Lyumanshan Ye",
      "Pengrui Lu",
      "Pengfei Liu"
    ],
    "affiliations": [],
    "summary": "Large Language Models (LLMs) with web search capabilities show significant potential for deep research, yet current methods—brittle prompt engineering or RAG-based reinforcement learning in controlled environments—fail to capture real-world complexities. In this paper, we introduce DeepResearcher, the first comprehensive framework for end-to-end training of LLM-based deep research agents through scaling reinforcement learning (RL) in real-world environments with authentic web search interactions. Unlike RAG approaches reliant on fixed corpora, DeepResearcher trains agents to navigate the noisy, dynamic open web. We implement a specialized multi-agent architecture where browsing agents extract relevant information from various webpage structures and overcoming significant technical challenges. Extensive experiments on open-domain research tasks demonstrate that DeepResearcher achieves substantial improvements of up to 28.9 points over prompt engineering-based baselines and up to 7.2 points over RAG-based RL agents. Our qualitative analysis reveals emergent cognitive behaviors from end-to-end RL training, such as planning, cross-validation, self-reflection for research redirection, and maintain honesty when unable to find definitive answers. Our results highlight that end-to-end training in real-world web environments is fundamental for developing robust research capabilities aligned with real-world applications. The source codefor DeepResearcher is released at: https://github.com/GAIR-NLP/DeepResearcher.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#23Mixture of Length and Pruning Experts for Knowledge Graphs Reasoning[PDF6][Copy][Kimi7][REL]",
    "authors": [
      "Authors:\n                Enjun Du",
      "Siyi Liu",
      "Yongqi Zhang"
    ],
    "affiliations": [],
    "summary": "Knowledge Graph (KG) reasoning, which aims to infer new facts from structured knowledge repositories, plays a vital role in Natural Language Processing (NLP) systems. Its effectiveness critically depends on constructing informative and contextually relevant reasoning paths. However, existing graph neural networks (GNNs) often adopt rigid, query-agnostic path-exploration strategies, limiting their ability to adapt to diverse linguistic contexts and semantic nuances. To address these limitations, we propose MoKGR, a mixture-of-experts framework that personalizes path exploration through two complementary components: (1) a mixture of length experts that adaptively selects and weights candidate path lengths according to query complexity, providing query-specific reasoning depth; and (2) a mixture of pruning experts that evaluates candidate paths from a complementary perspective, retaining the most informative paths for each query. Through comprehensive experiments on diverse benchmark, MoKGR demonstrates superior performance in both transductive and inductive settings, validating the effectiveness of personalized path exploration in KGs reasoning.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#24MPRF: Interpretable Stance Detection through Multi-Path Reasoning Framework[PDF4][Copy][Kimi5][REL]",
    "authors": [
      "Authors:\n                ZhaoDan Zhang",
      "Jin Zhang",
      "Hui Xu",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "affiliations": [],
    "summary": "Stance detection, a critical task in Natural Language Processing (NLP), aims to identify the attitude expressed in text toward specific targets. Despite advancements in Large Language Models (LLMs), challenges such as limited interpretability and handling nuanced content persist. To address these issues, we propose the Multi-Path Reasoning Framework (MPRF), a novel framework that generates, evaluates, and integrates multiple reasoning paths to improve accuracy, robustness, and transparency in stance detection. Unlike prior work that relies on single-path reasoning or static explanations, MPRF introduces a structured end-to-end pipeline: it first generates diverse reasoning paths through predefined perspectives, then dynamically evaluates and optimizes each path using LLM-based scoring, and finally fuses the results via weighted aggregation to produce interpretable and reliable predictions. Extensive experiments on the SEM16, VAST, and PStance datasets demonstrate that MPRF outperforms existing models. Ablation studies further validate the critical role of MPRF’s components, highlighting its effectiveness in enhancing interpretability and handling complex stance detection tasks.",
    "link": null,
    "published_date": null,
    "conference": "EMNLP",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#2Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding[PDF513][Copy][Kimi271][REL]",
    "authors": [
      "Authors:\n                Feilong Tang",
      "Chengzhi Liu",
      "Zhongxing Xu",
      "Ming Hu",
      "Zile Huang",
      "Haochen Xue",
      "Ziyang Chen",
      "Zelin Peng",
      "Zhiwei Yang",
      "Sijin Zhou",
      "Wenxue Li",
      "Yulong Li",
      "Wenxuan Song",
      "Shiyan Su",
      "Wei Feng",
      "Jionglong Su",
      "Mingquan Lin",
      "Yifan Peng",
      "Xuelian Cheng",
      "Imran Razzak",
      "Zongyuan Ge"
    ],
    "affiliations": [],
    "summary": "Authors:Feilong Tang,Chengzhi Liu,Zhongxing Xu,Ming Hu,Zile Huang,Haochen Xue,Ziyang Chen,Zelin Peng,Zhiwei Yang,Sijin Zhou,Wenxue Li,Yulong Li,Wenxuan Song,Shiyan Su,Wei Feng,Jionglong Su,Mingquan Lin,Yifan Peng,Xuelian Cheng,Imran Razzak,Zongyuan Ge",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#3UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming[PDF183][Copy][Kimi121][REL]",
    "authors": [
      "Authors:\n                Hao Lin",
      "Ke Wu",
      "Jie Li",
      "Jun Li",
      "Wu-Jun Li"
    ],
    "affiliations": [],
    "summary": "Distributed learning is commonly used for training deep learning models, especially large models. In distributed learning, manual parallelism (MP) methods demand considerable human effort and have limited flexibility. Hence, automatic parallelism (AP) methods have recently been proposed for automating the parallel strategy optimization process. Existing AP methods suffer from sub-optimal solutions because they do not jointly optimize the two categories of parallel strategies (i.e., inter-layer parallelism and intra-layer parallelism). In this paper, we propose a novel AP method called UniAP, which unifies inter- and intra-layer automatic parallelism by mixed integer quadratic programming. To the best of our knowledge, UniAP is the first parallel method that can jointly optimize the two categories of parallel strategies to find an optimal solution. Experimental results show that UniAP outperforms state-of-the-art methods by up to 3.80$\\times$ in throughput and reduces strategy optimization time by up to 107$\\times$ across five Transformer-based models.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#5VGGT: Visual Geometry Grounded Transformer[PDF329][Copy][Kimi181][REL]",
    "authors": [
      "Authors:\n                Jianyuan Wang",
      "Minghao Chen",
      "Nikita Karaev",
      "Andrea Vedaldi",
      "Christian Rupprecht",
      "David Novotny"
    ],
    "affiliations": [],
    "summary": "We present VGGN, a feed-forward neural network that infers directly all key 3D attributes of a scene, such as camera poses, point maps, depth maps, and 3D point tracks, from few or hundreds of its views. Unlike recent alternatives, VGGN does not need to use visual geometry optimization techniques to refine the results in post-processing, obtaining all quantities of interest directly. This approach is simple and more efficient, reconstructing hundreds of images in seconds. We train VGGN on a large number of publicly available datasets with 3D annotations and demonstrate its ability to achieve state-of-the-art results in multiple 3D tasks, including camera pose estimation, multi-view depth estimation, dense point cloud reconstruction, and 3D point tracking. This is a step forward in 3D computer vision, where models have been typically constrained to and specialized for single tasks. We extensively evaluate our method on unseen datasets to demonstrate its superior performance. We will release the code and trained model.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#6Reconstructing Humans with a Biomechanically Accurate Skeleton[PDF236][Copy][Kimi100][REL]",
    "authors": [
      "Authors:\n                Yan Xia",
      "Xiaowei Zhou",
      "Etienne Vouga",
      "Qixing Huang",
      "Georgios Pavlakos"
    ],
    "affiliations": [],
    "summary": "In this paper, we introduce a method for reconstructing humans in 3D from a single image using a biomechanically accurate skeleton model. To achieve this, we train a transformer that takes an image as input and estimates the parameters of the model. Due to the lack of training data for this task, we build a pipeline to generate pseudo ground truth data and implement a training procedure that iteratively refines these pseudo labels for improved accuracy. Compared to state-of-the-art methods in 3D human pose estimation, our model achieves competitive performance on standard benchmarks, while it significantly outperforms them in settings with extreme 3D poses and viewpoints. This result highlights the benefits of using a biomechanical skeleton with realistic degrees of freedom for robust pose estimation. Additionally, we show that previous models frequently violate joint angle limits, leading to unnatural rotations. In contrast, our approach leverages the biomechanically plausible degrees of freedom leading to more realistic joint rotation estimates. We validate our approach across multiple human pose estimation benchmarks. We will make all code, models and data publicly available upon publication.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#7CraftsMan3D: High-fidelity Mesh Generation with 3D Native Diffusion and Interactive Geometry Refiner[PDF192][Copy][Kimi78][REL]",
    "authors": [
      "Authors:\n                Weiyu Li",
      "Jiarui Liu",
      "Hongyu Yan",
      "Rui Chen",
      "Yixun Liang",
      "Xuelin Chen",
      "Ping Tan",
      "Xiaoxiao Long"
    ],
    "affiliations": [],
    "summary": "We present a novel generative 3D modeling system, coined CraftsMan, which can generate high-fidelity 3D geometries with highly varied shapes, regular mesh topologies, and detailed surfaces, and, notably, allows for refining the geometry in an interactive manner. Despite the significant advancements in 3D generation, existing methods still struggle with lengthy optimization processes, self-occlusion, irregular mesh topologies, and difficulties in accommodating user edits, consequently impeding their widespread adoption and implementation in 3D modeling softwares. Our work is inspired by the craftsman, who usually roughs out the holistic figure of the work first and elaborates the surface details subsequently. Specifically, we first introduce a robust data preprocessing pipeline that utilizes visibility check and winding mumber to maximize the use of existing 3D data. Leveraging this data, we employ a 3D-native DiT model that directly models the distribution of 3D data in latent space, generating coarse geometries with regular mesh topology in seconds. Subsequently, a normal-based geometry refiner enhances local surface details, which can be applied automatically or interactively with user input. Extensive experiments demonstrate that our method achieves high efficacy in producing superior quality 3D assets compared to existing methods.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#8DNF: Unconditional 4D Generation with Dictionary-based Neural Fields[PDF164][Copy][Kimi72][REL]",
    "authors": [
      "Authors:\n                Xinyi Zhang",
      "Naiqi Li",
      "Angela Dai"
    ],
    "affiliations": [],
    "summary": "While remarkable success has been achived through diffusion-based 3D generative models for shapes, 4D generative modeling remains challenging due to the complexity of object deformations over time. We propose DNF, a new 4D representation for unconditional generative modeling that efficiently models deformable shapes with disentangled shape and motion while capturing high-fidelity details in the deforming objects. To achieve this, we propose a dictionary learning approach to disentangle 4D motion from shape as neural fields.Both shape and motion are represented as learned latent spaces, where each deformable shape is represented by its shape and motion global latent codes, shape-specific coefficient vectors, and shared dictionary information. This captures both shape-specific detail and global shared information in the learned dictionary. Our dictionary-based representation well balances fidelity, contiguity and compression -- combined with a transformer-based diffusion model, our method is able to generate effective, high-fidelity 4D animations.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#11DesignDiffusion: High-Quality Text-to-Design Image Generation with Diffusion Models[PDF311][Copy][Kimi109][REL]",
    "authors": [
      "Authors:\n                Zhendong Wang",
      "Jianmin Bao",
      "Shuyang Gu",
      "Dong Chen",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "affiliations": [],
    "summary": "In this paper, we present DesignDiffusion, a simple yet effective framework for the novel task of synthesizing design images from textual descriptions. A primary challenge lies in generating accurate and style-consistent textual and visual content. Existing works in a related task of visual text generation often focus on generating text within given specific regions, which limits the creativity of generation models, resulting in style or color inconsistencies between textual and visual elements if applied to design image generation. To address this issue, we propose an end-to-end, one-stage diffusion-based framework that avoids intricate components like position and layout modeling. Specifically, the proposed framework directly synthesizes textual and visual design elements from user prompts. It utilizes a distinctive character embedding derived from the visual text to enhance the input prompt, along with a character localization loss for enhanced supervision during text generation. Furthermore, we employ a self-play Direct Preference Optimization fine-tuning strategy to improve the quality and accuracy of the synthesized visual text. Extensive experiments demonstrate that DesignDiffusion achieves state-of-the-art performance in design image generation.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#12Learning Audio-guided Video Representation with Gated Attention for Video-Text Retrieval[PDF160][Copy][Kimi68][REL]",
    "authors": [
      "Authors:\n                Boseung Jeong",
      "Jicheol Park",
      "Sungyeon Kim",
      "Suha Kwak"
    ],
    "affiliations": [],
    "summary": "Video-text retrieval, the task of retrieving videos based on a textual query or vice versa, is of paramount importance for video understanding and multimodal information retrieval. Recent methods in this area rely primarily on visual and textual features and often ignore audio, although it helps enhance overall comprehension of video content.Moreover, traditional models that incorporate audio blindly utilize the audio input regardless of whether it is useful or not, resulting in suboptimal video representation. To address these limitations, we propose a novel video-text retrieval framework, Audio-guided VIdeo representation learning with GATEd attention (AVIGATE), that effectively leverages audio cues through a gated attention mechanism that selectively filters out uninformative audio signals.In addition, we propose an adaptive margin-based contrastive loss to deal with the inherently unclear positive-negative relationship between video and text, which facilitates learning better video-text alignment.Our extensive experiments demonstrate that AVIGATE achieves state-of-the-art performance on all the public benchmarks.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#15FoundationStereo: Zero-Shot Stereo Matching[PDF142][Copy][Kimi91][REL]",
    "authors": [
      "Authors:\n                Bowen Wen",
      "Matthew Trepte",
      "Joseph Aribido",
      "Jan Kautz",
      "Orazio Gallo",
      "Stan Birchfield"
    ],
    "affiliations": [],
    "summary": "Tremendous progress has been made in deep stereo matching to excel on benchmark datasets through per-domain fine-tuning. However, achieving strong zero-shot generalization — a hallmark of foundation models in other computer vision tasks — remains challenging for stereo matching. We introduce StereoAnything, a foundation model for stereo depth estimation designed to achieve strong zero-shot generalization. To this end, we first construct a large-scale (1M stereo pairs) synthetic training dataset featuring large diversity and high photorealism, followed by an automatic self-curation pipeline to remove ambiguous samples. We then design a number of network architecture components to enhance scalability, including a side-tuning feature backbone that adapts rich monocular priors from vision foundation models to mitigate the sim-to-real gap, and long-range context reasoning for effective cost volume filtering. Together, these components lead to strong robustness and accuracy across domains, establishing a new standard in zero-shot stereo depth estimation.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#17Language-Guided Image Tokenization for Generation[PDF218][Copy][Kimi89][REL]",
    "authors": [
      "Authors:\n                Kaiwen Zha",
      "Lijun Yu",
      "Alireza Fathi",
      "David A. Ross",
      "Cordelia Schmid",
      "Dina Katabi",
      "Xiuye Gu"
    ],
    "affiliations": [],
    "summary": "Image tokenization, the process of transforming raw image pixels into a compact low-dimensional latent representation, has proven crucial for scalable and efficient image generation. However, mainstream image tokenization methods generally have limited compression rates, making high-resolution image generation computationally expensive. To address this challenge, we propose to leverage language for efficient image tokenization, and we call our method Text-Conditioned Image Tokenization (TexTok). TexTok is a simple yet effective tokenization framework that leverages language to provide high-level semantics. By conditioning the tokenization process on descriptive text captions, TexTok allows the tokenization process to focusing on encoding fine-grained visual details into latent tokens, leading to enhanced reconstruction quality and higher compression rates. Compared to the conventional tokenizer without text conditioning, TexTok achieves average reconstruction FID improvements of 29.2\\% and 48.1\\% on ImageNet 256$\\times$256 and 512$\\times$512 benchmarks respectively, across varying number of tokens. These tokenization improvements consistently translate to 16.3\\% and 34.3\\% average improvements in generation FID. By simply replacing the tokenizer in Diffusion Transformer (DiT) with TexTok, our system can achieve 93.5$\\times$ inference speedup while still outperforming the original DiT using only 32 tokens on ImageNet-512. TexTok with a vanilla DiT generator achieves state-of-the-art FID scores of 1.46 and 1.62 on ImageNet-256 and -512 respectively. Furthermore, we demonstrate TexTok's superiority on the text-to-image generation task, effectively utilizing the off-the-shelf text captions in tokenization.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#18Generative Multimodal Pretraining with Discrete Diffusion Timestep Tokens[PDF176][Copy][Kimi78][REL]",
    "authors": [
      "Authors:\n                Kaihang Pan",
      "Wang Lin",
      "Zhongqi Yue",
      "Tenglong Ao",
      "Liyu Jia",
      "Wei Zhao",
      "Juncheng Li",
      "Siliang Tang",
      "Hanwang Zhang"
    ],
    "affiliations": [],
    "summary": "Authors:Kaihang Pan,Wang Lin,Zhongqi Yue,Tenglong Ao,Liyu Jia,Wei Zhao,Juncheng Li,Siliang Tang,Hanwang Zhang",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#20Reanimating Images using Neural Representations of Dynamic Stimuli[PDF99][Copy][Kimi44][REL]",
    "authors": [
      "Authors:\n                Jacob Yeung",
      "Andrew F. Luo",
      "Gabriel Sarch",
      "Margaret M. Henderson",
      "Deva Ramanan",
      "Michael J. Tarr"
    ],
    "affiliations": [],
    "summary": "While computer vision models have made incredible strides in static image recognition, they still do not match human performance in tasks that require the understanding of complex, dynamic motion. This is notably true for real-world scenarios where embodied agents face complex and motion-rich environments. Our approach leverages state-of-the-art video diffusion models to decouple static image representation from motion generation, enabling us to utilize fMRI brain activity for a deeper understanding of human responses to dynamic visual stimuli. Conversely, we also demonstrate that information about the brain's representation of motion can enhance the prediction of optical flow in artificial systems. Our novel approach leads to four main findings: (1) Visual motion, represented as fine-grained, object-level resolution optical flow, can be decoded from brain activity generated by participants viewing video stimuli; (2) Video encoders outperform image-based models in predicting video-driven brain activity; (3) Brain-decoded motion signals enable realistic video reanimation based only on the initial frame of the video; and (4) We extend prior work to achieve full video decoding from video-driven brain activity. This framework advances our understanding of how the brain represents spatial and temporal information in dynamic visual scenes. Our findings demonstrate the potential of combining brain imaging with video diffusion models for developing more robust and biologically-inspired computer vision systems.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#21Towards Universal Dataset Distillation via Task-Driven Diffusion[PDF123][Copy][Kimi48][REL]",
    "authors": [
      "Authors:\n                Ding Qi",
      "Jian Li",
      "Junyao Gao",
      "Shuguang Dou",
      "Ying Tai",
      "Jianlong Hu",
      "Bo Zhao",
      "Yabiao Wang",
      "Chengjie Wang",
      "Cairong Zhao"
    ],
    "affiliations": [],
    "summary": "Authors:Ding Qi,Jian Li,Junyao Gao,Shuguang Dou,Ying Tai,Jianlong Hu,Bo Zhao,Yabiao Wang,Chengjie Wang,Cairong Zhao",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#22Identifying and Mitigating Position Bias of Multi-image Vision-Language Models[PDF148][Copy][Kimi57][REL]",
    "authors": [
      "Authors:\n                Xinyu Tian",
      "Shu Zou",
      "Zhaoyuan Yang",
      "Jing Zhang"
    ],
    "affiliations": [],
    "summary": "The evolution of Large Vision-Language Models (LVLMs) has progressed from single-image understanding to multi-image reasoning. Despite this advancement, our findings indicate that LVLMs struggle to robustly utilize information across multiple images, with predictions significantly affected by the alteration of image positions. To further explore this issue, we introduce Position-wise Question Answering (PQA), a meticulously designed task to quantify reasoning capabilities at each position. Our analysis reveals a pronounced position bias in LVLMs: open-source models excel in reasoning with images positioned later but underperform with those in the middle or at the beginning, while proprietary models like GPT-4o show improved comprehension for images at the beginning and end but struggle with those in the middle. Motivated by these insights, we propose SoFt Attention (SoFA), a simple, training-free approach that mitigates this bias by employing linear interpolation between inter-image causal attention and bidirectional counterparts. Experimental results demonstrate that SoFA effectively reduces position bias and significantly enhances the reasoning performance of existing LVLMs.",
    "link": null,
    "published_date": null,
    "conference": "CVPR",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#1Token Activation Map to Visually Explain Multimodal LLMs[PDF98][Copy][Kimi88][REL]",
    "authors": [
      "Authors:\n                Yi Li",
      "Hualiang Wang",
      "Xinpeng Ding",
      "Haonan Wang",
      "Xiaomeng Li"
    ],
    "affiliations": [],
    "summary": "Multimodal large language models (MLLMs) are broadly empowering various fields. Despite their advancements, the explainability of MLLMs remains less explored, hindering deeper understanding, model credibility, and effective visualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that produce a single output, MLLMs generate sequences of tokens progressively, where each generated token depends on the previous context. Therefore, earlier context tokens can introduce redundant activations that interfere with the explanation of later tokens beyond their original information. Existing studies often overlook this issue, but our observations reveal that these redundant correlations can significantly hurt the reliability of explanations. To address this, we propose an estimated causal inference method to mitigate the interference of context to achieve high-quality MLLM explanation, with a novel rank Gaussian filter to further reduce activation noises. We term this method Token Activation Map (TAM) to highlight the consideration of interactions between tokens. TAM also indicates that it excels at explaining multiple tokens of MLLM, which is different from the Class Activation Map (CAM) for a single prediction. Our TAM method significantly outperforms existing SoTA methods, showcasing high-quality visualization results that can be utilized for various scenarios, such as object localization, failure case analysis, video visualization, MLLMs visual comparison, and model understanding (e.g., color, shape, action, location, visual reasoning, multi-turn conversation, etc). The code is available at github.com/xmed-lab/TAM.",
    "link": null,
    "published_date": null,
    "conference": "ICCV",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#2NullSwap: Proactive Identity Cloaking Against Deepfake Face Swapping[PDF25][Copy][Kimi27][REL]",
    "authors": [
      "Authors:\n                Tianyi Wang",
      "Shuaicheng Niu",
      "Harry Cheng",
      "Xiao Zhang",
      "Yinglong Wang"
    ],
    "affiliations": [],
    "summary": "Suffering from performance bottlenecks in passively detecting high-quality Deepfake images due to the advancement of generative models, proactive perturbations offer a promising approach to disabling Deepfake manipulations by inserting signals into benign images. However, existing proactive perturbation approaches remain unsatisfactory in several aspects: 1) visual degradation due to direct element-wise addition; 2) limited effectiveness against face swapping manipulation; 3) unavoidable reliance on white- and grey-box settings to involve generative models during training. In this study, we analyze the essence of Deepfake face swapping and argue the necessity of protecting source identities rather than target images, and we propose NullSwap, a novel proactive defense approach that cloaks source image identities and nullifies face swapping under a pure black-box scenario. We design an Identity Extraction module to obtain facial identity features from the source image, while a Perturbation Block is then devised to generate identity-guided perturbations accordingly. Meanwhile, a Feature Block extracts shallow-level image features, which are then fused with the perturbation in the Cloaking Block for image reconstruction. Furthermore, to ensure adaptability across different identity extractors in face swapping algorithms, we propose Dynamic Loss Weighting to adaptively balance identity losses. Experiments demonstrate the outstanding ability of our approach to fool various identity recognition models, outperforming state-of-the-art proactive perturbations in preventing face swapping models from generating images with correct source identities.",
    "link": null,
    "published_date": null,
    "conference": "ICCV",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#6LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering[PDF33][Copy][Kimi21][REL]",
    "authors": [
      "Authors:\n                Xiaohang Zhan",
      "Dingming Liu"
    ],
    "affiliations": [],
    "summary": "We propose a novel training-free image generation algorithm that precisely controls the occlusion relationships between objects in an image. Existing image generation methods typically rely on prompts to influence occlusion, which often lack precision. While layout-to-image methods provide control over object locations, they fail to address occlusion relationships explicitly. Given a pre-trained image diffusion model, our method leverages volume rendering principles to \"render\" the scene in latent space, guided by occlusion relationships and the estimated transmittance of objects. This approach does not require retraining or fine-tuning the image diffusion model, yet it enables accurate occlusion control due to its physics-grounded foundation. In extensive experiments, our method significantly outperforms existing approaches in terms of occlusion accuracy. Furthermore, we demonstrate that by adjusting the opacities of objects or concepts during rendering, our method can achieve a variety of effects, such as altering the transparency of objects, the density of mass (e.g., forests), the concentration of particles (e.g., rain, fog), the intensity of light, and the strength of lens effects, etc.",
    "link": null,
    "published_date": null,
    "conference": "ICCV",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#8LoftUp: Learning a Coordinate-Based Feature Upsampler for Vision Foundation Models[PDF23][Copy][Kimi12][REL]",
    "authors": [
      "Authors:\n                Haiwen Huang",
      "Anpei Chen",
      "Volodymyr Havrylov",
      "Andreas Geiger",
      "Dan Zhang"
    ],
    "affiliations": [],
    "summary": "Vision foundation models (VFMs) such as DINOv2 and CLIP have achieved impressive results on various downstream tasks, but their limited feature resolution hampers performance in applications requiring pixel-level understanding. Feature upsampling offers a promising direction to address this challenge. In this work, we identify two critical factors for enhancing feature upsampling: the upsampler architecture and the training objective. For the upsampler architecture, we introduce a coordinate-based cross-attention transformer that integrates the high-resolution images with coordinates and low-resolution VFM features to generate sharp, high-quality features. For the training objective, we propose constructing high-resolution pseudo-groundtruth features by leveraging class-agnostic masks and self-distillation. Our approach effectively captures fine-grained details and adapts flexibly to various input and feature resolutions. Through experiments, we demonstrate that our approach significantly outperforms existing feature upsampling techniques across various downstream tasks. Our code is released at https://github.com/andrehuang/loftup.",
    "link": null,
    "published_date": null,
    "conference": "ICCV",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#9LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing[PDF18][Copy][Kimi10][REL]",
    "authors": [
      "Authors:\n                Federico Girella",
      "Davide Talon",
      "Ziyue Liu",
      "Zanxi Ruan",
      "Yiming Wang",
      "Marco Cristani"
    ],
    "affiliations": [],
    "summary": "Fashion design is a complex creative process that blends visual and textual expressions. Designers convey ideas through sketches, which define spatial structure and design elements, and textual descriptions, capturing material, texture, and stylistic details. In this paper, we present LOcalized Text and Sketch for fashion image generation (LOTS), an approach for compositional sketch-text based generation of complete fashion outlooks. LOTS leverages a global description with paired localized sketch + text information for conditioning and introduces a novel step-based merging strategy for diffusion adaptation. First, a Modularized Pair-Centric representation encodes sketches and text into a shared latent space while preserving independent localized features; then, a Diffusion Pair Guidance phase integrates both local and global conditioning via attention-based guidance within the diffusion model's multi-step denoising process. To validate our method, we build on Fashionpedia to release Sketchy, the first fashion dataset where multiple text-sketch pairs are provided per image. Quantitative results show LOTS achieves state-of-the-art image generation performance on both global and localized metrics, while qualitative examples and a human evaluation study highlight its unprecedented level of design customization.",
    "link": null,
    "published_date": null,
    "conference": "ICCV",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#14TrajectoryCrafter: Redirecting Camera Trajectory for Monocular Videos via Diffusion Models[PDF22][Copy][Kimi11][REL]",
    "authors": [
      "Authors:\n                Mark Yu",
      "Wenbo Hu",
      "Jinbo Xing",
      "Ying Shan"
    ],
    "affiliations": [],
    "summary": "We present TrajectoryCrafter, a novel approach to redirect camera trajectories for monocular videos. By disentangling deterministic view transformations from stochastic content generation, our method achieves precise control over user-specified camera trajectories. We propose a novel dual-stream conditional video diffusion model that concurrently integrates point cloud renders and source videos as conditions, ensuring accurate view transformations and coherent 4D content generation. Instead of leveraging scarce multi-view videos, we curate a hybrid training dataset combining web-scale monocular videos with static multi-view datasets, by our innovative double-reprojection strategy, significantly fostering robust generalization across diverse scenes. Extensive evaluations on multi-view and large-scale monocular videos demonstrate the superior performance of our method. Code and pre-trained model will be released.",
    "link": null,
    "published_date": null,
    "conference": "ICCV",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#15FlowEdit: Inversion-Free Text-Based Editing Using Pre-Trained Flow Models[PDF19][Copy][Kimi10][REL]",
    "authors": [
      "Authors:\n                Vladimir Kulikov",
      "Matan Kleiner",
      "Inbar Huberman-Spiegelglas",
      "Tomer Michaeli"
    ],
    "affiliations": [],
    "summary": "Editing real images using a pre-trained text-to-image (T2I) diffusion/flow model often involves inverting the image into its corresponding noise map. However, inversion by itself is typically insufficient for obtaining satisfactory results, and therefore many methods additionally intervene in the sampling process. Such methods achieve improved results but are not seamlessly transferable between model architectures. Here, we introduce FlowEdit, a text-based editing method for pre-trained T2I flow models, which is inversion-free, optimization-free and model agnostic. Our method constructs an ODE that directly maps between the source and target distributions (corresponding to the source and target text prompts) and achieves a lower transport cost than the inversion approach. This leads to state-of-the-art results, as we illustrate with Stable Diffusion 3 and FLUX.",
    "link": null,
    "published_date": null,
    "conference": "ICCV",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#17Dynamic Typography: Bringing Text to Life via Video Diffusion Prior[PDF21][Copy][Kimi9][REL]",
    "authors": [
      "Authors:\n                Zichen Liu",
      "Yihao Meng",
      "Hao Ouyang",
      "Yue Yu",
      "Bolin Zhao",
      "Daniel Cohen-Or",
      "Huamin Qu"
    ],
    "affiliations": [],
    "summary": "Text animation serves as an expressive medium, transforming static communication into dynamic experiences by infusing words with motion to evoke emotions, emphasize meanings, and construct compelling narratives. Crafting animations that are semantically aware poses significant challenges, demanding expertise in graphic design and animation. We present an automated text animation scheme, termed \"Dynamic Typography\", which deforms letters to convey semantic meaning and infuses them with vibrant movements based on user prompts. The animation is represented by a canonical field that aggregates the semantic content in a canonical shape and a deformation field that applies per-frame motion to deform the canonical shape. Two fields are jointly optimized by the priors from a large pretrained text-to-video diffusion model using score-distillation loss with designed regularization, encouraging the video coherence with the intended textual concept while maintaining legibility and structural integrity throughout the animation process. We demonstrate the generalizability of our approach across various text-to-video models and highlight the superiority of our methodology over baselines. Through quantitative and qualitative evaluations, we demonstrate the effectiveness of our framework in generating coherent text animations that faithfully interpret user prompts while maintaining readability.",
    "link": null,
    "published_date": null,
    "conference": "ICCV",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#21Moto: Latent Motion Token as the Bridging Language for Learning Robot Manipulation from Videos[PDF13][Copy][Kimi7][REL]",
    "authors": [
      "Authors:\n                Yi Chen",
      "Yuying Ge",
      "Weiliang Tang",
      "Yizhuo Li",
      "Yixiao Ge",
      "Mingyu Ding",
      "Ying Shan",
      "Xihui Liu"
    ],
    "affiliations": [],
    "summary": "Recent developments in Large Language Models (LLMs) pre-trained on extensive corpora have shown significant success in various natural language processing (NLP) tasks with minimal fine-tuning. This success offers new promise for robotics, which has long been constrained by the high cost of action-labeled data. We ask: given the abundant video data containing interaction-related knowledge available as a rich \"corpus\", can a similar generative pre-training approach be effectively applied to enhance robot learning? The key challenge is to identify an effective representation for autoregressive pre-training that benefits robot manipulation tasks.Inspired by the way humans learn new skills through observing dynamic environments, we propose that effective robotic learning should emphasize motion-related knowledge, which is closely tied to low-level actions and is hardware-agnostic, facilitating the transfer of learned motions to actual robot actions. To this end, we introduce Moto, which converts video content into latent Motion Token sequences by a Latent Motion Tokenizer, learning a bridging \"language\" of motion from videos in an unsupervised manner. We pre-train Moto-GPT through motion token autoregression, enabling it to capture diverse visual motion knowledge. After pre-training, Moto-GPT demonstrates the promising ability to produce semantically interpretable motion tokens, predict plausible motion trajectories, and assess trajectory rationality through output likelihood.To transfer learned motion priors to real robot actions, we implement a co-fine-tuning strategy that seamlessly bridges latent motion token prediction and real robot control. Extensive experiments show that the fine-tuned Moto-GPT exhibits superior robustness and efficiency on robot manipulation benchmarks, underscoring its effectiveness in transferring knowledge from video data to downstream visual manipulation tasks.",
    "link": null,
    "published_date": null,
    "conference": "ICCV",
    "source": "paperscool"
  },
  {
    "id": null,
    "title": "#25HairCUP: Hair Compositional Universal Prior for 3D Gaussian Avatars[PDF10][Copy][Kimi10][REL]",
    "authors": [
      "Authors:\n                Byungjun Kim",
      "Shunsuke Saito",
      "Giljoo Nam",
      "Tomas Simon",
      "Jason Saragih",
      "Hanbyul Joo",
      "Junxuan Li"
    ],
    "affiliations": [],
    "summary": "We present a universal prior model for 3D head avatars with explicit hair compositionality. Existing approaches to build generalizable priors for 3D head avatars often adopt a holistic modeling approach, treating the face and hair as an inseparable entity. This overlooks the inherent compositionality of the human head, making it difficult for the model to naturally disentangle face and hair representations, especially when the dataset is limited. Furthermore, such holistic models struggle to support applications like 3D face and hairstyle swapping in a flexible and controllable manner. To address these challenges, we introduce a prior model that explicitly accounts for the compositionality of face and hair, learning their latent spaces separately. A key enabler of this approach is our synthetic hairless data creation pipeline, which removes hair from studio-captured datasets using estimated hairless geometry and texture derived from a diffusion prior. By leveraging a paired dataset of original and synthetic hairless captures, we train disentangled prior models for face and hair, incorporating compositionality as an inductive bias to facilitate effective separation. Our model's inherent compositionality enables seamless transfer of face and hair components between avatars while preserving identity. Additionally, we demonstrate that our model can be fine-tuned in a data-efficient manner using monocular captures to create high-fidelity, hair-compositional 3D head avatars for unseen subjects. These capabilities highlight the practical applicability of our approach in real-world scenarios, paving the way for flexible and expressive 3D avatar generation.",
    "link": null,
    "published_date": null,
    "conference": "ICCV",
    "source": "paperscool"
  },
  {
    "id": "2601.16214",
    "title": "CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback",
    "authors": [
      "Wenhang Ge",
      "Guibao Shen",
      "Jiawei Feng",
      "Luozhou Wang",
      "Hao Lu",
      "Xingye Tian",
      "Xin Tao",
      "Ying-Cong Chen"
    ],
    "affiliations": [],
    "summary": "Recent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \\href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}.",
    "link": "http://arxiv.org/abs/2601.16214v1",
    "published_date": "2026-01-22T18:59:56",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16208",
    "title": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders",
    "authors": [
      "Shengbang Tong",
      "Boyang Zheng",
      "Ziteng Wang",
      "Bingda Tang",
      "Nanye Ma",
      "Ellis Brown",
      "Jihan Yang",
      "Rob Fergus",
      "Yann LeCun",
      "Saining Xie"
    ],
    "affiliations": [],
    "summary": "Representation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models.",
    "link": "http://arxiv.org/abs/2601.16208v1",
    "published_date": "2026-01-22T18:58:16",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16206",
    "title": "LLM-in-Sandbox Elicits General Agentic Intelligence",
    "authors": [
      "Daixuan Cheng",
      "Shaohan Huang",
      "Yuxian Gu",
      "Huatong Song",
      "Guoxin Chen",
      "Li Dong",
      "Wayne Xin Zhao",
      "Ji-Rong Wen",
      "Furu Wei"
    ],
    "affiliations": [],
    "summary": "We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.",
    "link": "http://arxiv.org/abs/2601.16206v1",
    "published_date": "2026-01-22T18:57:09",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16205",
    "title": "Counterfactual Training: Teaching Models Plausible and Actionable Explanations",
    "authors": [
      "Patrick Altmeyer",
      "Aleksander Buszydlik",
      "Arie van Deursen",
      "Cynthia C. S. Liem"
    ],
    "affiliations": [],
    "summary": "We propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and additionally exhibit improved adversarial robustness.",
    "link": "http://arxiv.org/abs/2601.16205v1",
    "published_date": "2026-01-22T18:56:14",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16200",
    "title": "Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing",
    "authors": [
      "Song Xia",
      "Meiwen Ding",
      "Chenqi Kong",
      "Wenhan Yang",
      "Xudong Jiang"
    ],
    "affiliations": [],
    "summary": "Multimodal large language models (MLLMs) exhibit strong capabilities across diverse applications, yet remain vulnerable to adversarial perturbations that distort their feature representations and induce erroneous predictions. To address this vulnerability, we propose the Feature-space Smoothing (FS) and theoretically prove that FS offers certified robustness on the feature representations of MLLMs. Specifically, FS transforms any feature encoder into a smoothed variant that is guaranteed to maintain a certified lower bound on the feature cosine similarity between clean and adversarial representations under $\\ell_2$-bounded attacks. Moreover, we indicate that the value of this Feature Cosine Similarity Bound (FCSB) derived from FS can be improved by enlarging the defined Gaussian robustness score on the vanilla encoder. Building upon this, we introduce the Purifier and Smoothness Mapper (PSM), a plug-and-play module that improves the Gaussian robustness score of MLLMs and thus enhances their certified robustness under FS, without requiring any retraining on MLLMs. We demonstrate that the FS with PSM not only provides a strong theoretical robustness guarantee but also exhibits superior empirical performance compared to adversarial training. Extensive experiments across diverse MLLMs and downstream tasks indicate the effectiveness of the FS-PSM, reducing the Attack Success Rate (ASR) of various white-box attacks from nearly 90\\% to about 1\\%.",
    "link": "http://arxiv.org/abs/2601.16200v1",
    "published_date": "2026-01-22T18:52:21",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16199",
    "title": "PAL*M: Property Attestation for Large Generative Models",
    "authors": [
      "Prach Chantasantitam",
      "Adam Ilyas Caulfield",
      "Vasisht Duddu",
      "Lachlan J. Gunn",
      "N. Asokan"
    ],
    "affiliations": [],
    "summary": "Machine learning property attestations allow provers (e.g., model providers or owners) to attest properties of their models/datasets to verifiers (e.g., regulators, customers), enabling accountability towards regulations and policies. But, current approaches do not support generative models or large datasets. We present PAL*M, a property attestation framework for large generative models, illustrated using large language models. PAL*M defines properties across training and inference, leverages confidential virtual machines with security-aware GPUs for coverage of CPU-GPU operations, and proposes using incremental multiset hashing over memory-mapped datasets to efficiently track their integrity. We implement PAL*M on Intel TDX and NVIDIA H100, showing it is efficient, scalable, versatile, and secure.",
    "link": "http://arxiv.org/abs/2601.16199v1",
    "published_date": "2026-01-22T18:51:13",
    "categories": [
      "cs.CR"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16192",
    "title": "360Anything: Geometry-Free Lifting of Images and Videos to 360°",
    "authors": [
      "Ziyi Wu",
      "Daniel Watson",
      "Andrea Tagliasacchi",
      "David J. Fleet",
      "Marcus A. Brubaker",
      "Saurabh Saxena"
    ],
    "affiliations": [],
    "summary": "Lifting perspective images and videos to 360° panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360° generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything's deep geometric understanding and broader utility in computer vision tasks. Additional results are available at https://360anything.github.io/.",
    "link": "http://arxiv.org/abs/2601.16192v1",
    "published_date": "2026-01-22T18:45:59",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16175",
    "title": "Learning to Discover at Test Time",
    "authors": [
      "Mert Yuksekgonul",
      "Daniel Koceja",
      "Xinhao Li",
      "Federico Bianchi",
      "Jed McCaleb",
      "Xiaolong Wang",
      "Jan Kautz",
      "Yejin Choi",
      "James Zou",
      "Carlos Guestrin",
      "Yu Sun"
    ],
    "affiliations": [],
    "summary": "How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.",
    "link": "http://arxiv.org/abs/2601.16175v1",
    "published_date": "2026-01-22T18:24:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16174",
    "title": "Beyond Predictive Uncertainty: Reliable Representation Learning with Structural Constraints",
    "authors": [
      "Yiyao Yang"
    ],
    "affiliations": [],
    "summary": "Uncertainty estimation in machine learning has traditionally focused on the prediction stage, aiming to quantify confidence in model outputs while treating learned representations as deterministic and reliable by default. In this work, we challenge this implicit assumption and argue that reliability should be regarded as a first-class property of learned representations themselves. We propose a principled framework for reliable representation learning that explicitly models representation-level uncertainty and leverages structural constraints as inductive biases to regularize the space of feasible representations. Our approach introduces uncertainty-aware regularization directly in the representation space, encouraging representations that are not only predictive but also stable, well-calibrated, and robust to noise and structural perturbations. Structural constraints, such as sparsity, relational structure, or feature-group dependencies, are incorporated to define meaningful geometry and reduce spurious variability in learned representations, without assuming fully correct or noise-free structure. Importantly, the proposed framework is independent of specific model architectures and can be integrated with a wide range of representation learning methods.",
    "link": "http://arxiv.org/abs/2601.16174v1",
    "published_date": "2026-01-22T18:19:52",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16172",
    "title": "Structured Hints for Sample-Efficient Lean Theorem Proving",
    "authors": [
      "Zachary Burton"
    ],
    "affiliations": [],
    "summary": "State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention -- a fixed prompt schedule over 15 common tactic skeletons -- on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maximum generation length (1024 tokens). Our results suggest that even capable RL-trained provers underutilize structural priors available in the tactic language, and that simple inference-time guidance remains a cheap, complementary boost.",
    "link": "http://arxiv.org/abs/2601.16172v1",
    "published_date": "2026-01-22T18:16:46",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16163",
    "title": "Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning",
    "authors": [
      "Moo Jin Kim",
      "Yihuai Gao",
      "Tsung-Yi Lin",
      "Yen-Chen Lin",
      "Yunhao Ge",
      "Grace Lam",
      "Percy Liang",
      "Shuran Song",
      "Ming-Yu Liu",
      "Chelsea Finn",
      "Jinwei Gu"
    ],
    "affiliations": [],
    "summary": "Recent video generation models demonstrate remarkable ability to capture complex physical interactions and scene evolution over time. To leverage their spatiotemporal priors, robotics works have adapted video models for policy learning but introduce complexity by requiring multiple stages of post-training and new architectural components for action generation. In this work, we introduce Cosmos Policy, a simple approach for adapting a large pretrained video model (Cosmos-Predict2) into an effective robot policy through a single stage of post-training on the robot demonstration data collected on the target platform, with no architectural modifications. Cosmos Policy learns to directly generate robot actions encoded as latent frames within the video model's latent diffusion process, harnessing the model's pretrained priors and core learning algorithm to capture complex action distributions. Additionally, Cosmos Policy generates future state images and values (expected cumulative rewards), which are similarly encoded as latent frames, enabling test-time planning of action trajectories with higher likelihood of success. In our evaluations, Cosmos Policy achieves state-of-the-art performance on the LIBERO and RoboCasa simulation benchmarks (98.5% and 67.1% average success rates, respectively) and the highest average score in challenging real-world bimanual manipulation tasks, outperforming strong diffusion policies trained from scratch, video model-based policies, and state-of-the-art vision-language-action models fine-tuned on the same robot demonstrations. Furthermore, given policy rollout data, Cosmos Policy can learn from experience to refine its world model and value function and leverage model-based planning to achieve even higher success rates in challenging tasks. We release code, models, and training data at https://research.nvidia.com/labs/dir/cosmos-policy/",
    "link": "http://arxiv.org/abs/2601.16163v1",
    "published_date": "2026-01-22T18:09:30",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16160",
    "title": "CONTEX-T: Contextual Privacy Exploitation via Transformer Spectral Analysis for IoT Device Fingerprinting",
    "authors": [
      "Nazmul Islam",
      "Mohammad Zulkernine"
    ],
    "affiliations": [],
    "summary": "The rapid expansion of internet of things (IoT) devices have created a pervasive ecosystem where encrypted wireless communications serve as the primary privacy and security protection mechanism. While encryption effectively protects message content, packet metadata and statistics inadvertently expose device identities and user contexts. Various studies have exploited raw packet statistics and their visual representations for device fingerprinting and identification. However, these approaches remain confined to the spatial domain with limited feature representation. Therefore, this paper presents CONTEX-T, a novel framework that exploits contextual privacy vulnerabilities using spectral representation of encrypted wireless traffic for IoT device characterization. The experiments show that spectral analysis provides new and rich feature representation for covert reconnaissance attacks, revealing a complex and expanding threat landscape that would require robust countermeasures for IoT security management. CONTEXT-T first transforms raw packet length sequences into time-frequency spectral representations and then utilizes transformer-based spectral analysis for the device identification. We systematically evaluated multiple spectral representation techniques and transformer-based models across encrypted traffic samples from various IoT devices. CONTEXT-T effectively exploited privacy vulnerabilities and achieved device classification accuracy exceeding 99% across all devices while remaining completely passive and undetectable.",
    "link": "http://arxiv.org/abs/2601.16160v1",
    "published_date": "2026-01-22T18:03:34",
    "categories": [
      "cs.CR"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16158",
    "title": "Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems",
    "authors": [
      "Prakash Dhungana",
      "Sayed Ahmad Salehi"
    ],
    "affiliations": [],
    "summary": "Keyword Spotting (KWS) systems with small footprint models deployed on edge devices face significant accuracy and robustness challenges due to domain shifts caused by varying noise and recording conditions. To address this, we propose a comprehensive framework for continual learning designed to adapt to new domains while maintaining computational efficiency. The proposed pipeline integrates a dual-input Convolutional Neural Network, utilizing both Mel Frequency Cepstral Coefficients (MFCC) and Mel-spectrogram features, supported by a multi-stage denoising process, involving discrete wavelet transform and spectral subtraction techniques, plus model and prototype update blocks. Unlike prior methods that restrict updates to specific layers, our approach updates the complete quantized model, made possible due to compact model architecture. A subset of input samples are selected during runtime using class prototypes and confidence-driven filtering, which are then pseudo-labeled and combined with rehearsal buffer for incremental model retraining. Experimental results on noisy test dataset demonstrate the framework's effectiveness, achieving 99.63\\% accuracy on clean data and maintaining robust performance (exceeding 94\\% accuracy) across diverse noisy environments, even at -10 dB Signal-to-Noise Ratio. The proposed framework work confirms that integrating efficient denoising with prototype-based continual learning enables KWS models to operate autonomously and robustly in resource-constrained, dynamic environments.",
    "link": "http://arxiv.org/abs/2601.16158v1",
    "published_date": "2026-01-22T17:59:31",
    "categories": [
      "cs.SD",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16155",
    "title": "HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval",
    "authors": [
      "Zequn Xie",
      "Xin Liu",
      "Boyun Zhang",
      "Yuxiao Lin",
      "Sihang Cai",
      "Tao Jin"
    ],
    "affiliations": [],
    "summary": "The success of CLIP has driven substantial progress in text-video retrieval. However, current methods often suffer from \"blind\" feature interaction, where the model struggles to discern key visual information from background noise due to the sparsity of textual queries. To bridge this gap, we draw inspiration from human cognitive behavior and propose the Human Vision-Driven (HVD) model. Our framework establishes a coarse-to-fine alignment mechanism comprising two key components: the Frame Features Selection Module (FFSM) and the Patch Features Compression Module (PFCM). FFSM mimics the human macro-perception ability by selecting key frames to eliminate temporal redundancy. Subsequently, PFCM simulates micro-perception by aggregating patch features into salient visual entities through an advanced attention mechanism, enabling precise entity-level matching. Extensive experiments on five benchmarks demonstrate that HVD not only captures human-like visual focus but also achieves state-of-the-art performance.",
    "link": "http://arxiv.org/abs/2601.16155v1",
    "published_date": "2026-01-22T17:57:42",
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16150",
    "title": "Pay (Cross) Attention to the Melody: Curriculum Masking for Single-Encoder Melodic Harmonization",
    "authors": [
      "Maximos Kaliakatsos-Papakostas",
      "Dimos Makris",
      "Konstantinos Soiledis",
      "Konstantinos-Theodoros Tsamis",
      "Vassilis Katsouros",
      "Emilios Cambouropoulos"
    ],
    "affiliations": [],
    "summary": "Melodic harmonization, the task of generating harmonic accompaniments for a given melody, remains a central challenge in computational music generation. Recent single encoder transformer approaches have framed harmonization as a masked sequence modeling problem, but existing training curricula inspired by discrete diffusion often result in weak (cross) attention between melody and harmony. This leads to limited exploitation of melodic cues, particularly in out-of-domain contexts. In this work, we introduce a training curriculum, FF (full-to-full), which keeps all harmony tokens masked for several training steps before progressively unmasking entire sequences during training to strengthen melody-harmony interactions. We systematically evaluate this approach against prior curricula across multiple experimental axes, including temporal quantization (quarter vs. sixteenth note), bar-level vs. time-signature conditioning, melody representation (full range vs. pitch class), and inference-time unmasking strategies. Models are trained on the HookTheory dataset and evaluated both in-domain and on a curated collection of jazz standards, using a comprehensive set of metrics that assess chord progression structure, harmony-melody alignment, and rhythmic coherence. Results demonstrate that the proposed FF curriculum consistently outperforms baselines in nearly all metrics, with particularly strong gains in out-of-domain evaluations where harmonic adaptability to novel melodic queues is crucial. We further find that quarter-note quantization, intertwining of bar tokens, and pitch-class melody representations are advantageous in the FF setting. Our findings highlight the importance of training curricula in enabling effective melody conditioning and suggest that full-to-full unmasking offers a robust strategy for single encoder harmonization.",
    "link": "http://arxiv.org/abs/2601.16150v1",
    "published_date": "2026-01-22T17:46:31",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16148",
    "title": "ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion",
    "authors": [
      "Remy Sabathier",
      "David Novotny",
      "Niloy J. Mitra",
      "Tom Monnier"
    ],
    "affiliations": [],
    "summary": "Generating animated 3D objects is at the heart of many applications, yet most advanced works are typically difficult to apply in practice because of their limited setup, their long runtime, or their limited quality. We introduce ActionMesh, a generative model that predicts production-ready 3D meshes \"in action\" in a feed-forward manner. Drawing inspiration from early video models, our key insight is to modify existing 3D diffusion models to include a temporal axis, resulting in a framework we dubbed \"temporal 3D diffusion\". Specifically, we first adapt the 3D diffusion stage to generate a sequence of synchronized latents representing time-varying and independent 3D shapes. Second, we design a temporal 3D autoencoder that translates a sequence of independent shapes into the corresponding deformations of a pre-defined reference shape, allowing us to build an animation. Combining these two components, ActionMesh generates animated 3D meshes from different inputs like a monocular video, a text description, or even a 3D mesh with a text prompt describing its animation. Besides, compared to previous approaches, our method is fast and produces results that are rig-free and topology consistent, hence enabling rapid iteration and seamless applications like texturing and retargeting. We evaluate our model on standard video-to-4D benchmarks (Consistent4D, Objaverse) and report state-of-the-art performances on both geometric accuracy and temporal consistency, demonstrating that our model can deliver animated 3D meshes with unprecedented speed and quality.",
    "link": "http://arxiv.org/abs/2601.16148v1",
    "published_date": "2026-01-22T17:41:13",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16140",
    "title": "Learning to Watermark in the Latent Space of Generative Models",
    "authors": [
      "Sylvestre-Alvise Rebuffi",
      "Tuan Tran",
      "Valeriu Lacatusu",
      "Pierre Fernandez",
      "Tomáš Souček",
      "Nikola Jovanović",
      "Tom Sander",
      "Hady Elsahar",
      "Alexandre Mourachko"
    ],
    "affiliations": [],
    "summary": "Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.",
    "link": "http://arxiv.org/abs/2601.16140v1",
    "published_date": "2026-01-22T17:34:30",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16139",
    "title": "On the Intrinsic Dimensions of Data in Kernel Learning",
    "authors": [
      "Rustem Takhanov"
    ],
    "affiliations": [],
    "summary": "The manifold hypothesis suggests that the generalization performance of machine learning methods improves significantly when the intrinsic dimension of the input distribution's support is low. In the context of KRR, we investigate two alternative notions of intrinsic dimension. The first, denoted $d_ρ$, is the upper Minkowski dimension defined with respect to the canonical metric induced by a kernel function $K$ on a domain $Ω$. The second, denoted $d_K$, is the effective dimension, derived from the decay rate of Kolmogorov $n$-widths associated with $K$ on $Ω$. Given a probability measure $μ$ on $Ω$, we analyze the relationship between these $n$-widths and eigenvalues of the integral operator $φ\\to \\int_ΩK(\\cdot,x)φ(x)dμ(x)$. We show that, for a fixed domain $Ω$, the Kolmogorov $n$-widths characterize the worst-case eigenvalue decay across all probability measures $μ$ supported on $Ω$. These eigenvalues are central to understanding the generalization behavior of constrained KRR, enabling us to derive an excess error bound of order $O(n^{-\\frac{2+d_K}{2+2d_K} + ε})$ for any $ε> 0$, when the training set size $n$ is large. We also propose an algorithm that estimates upper bounds on the $n$-widths using only a finite sample from $μ$. For distributions close to uniform, we prove that $ε$-accurate upper bounds on all $n$-widths can be computed with high probability using at most $O\\left(ε^{-d_ρ}\\log\\frac{1}ε\\right)$ samples, with fewer required for small $n$. Finally, we compute the effective dimension $d_K$ for various fractal sets and present additional numerical experiments. Our results show that, for kernels such as the Laplace kernel, the effective dimension $d_K$ can be significantly smaller than the Minkowski dimension $d_ρ$, even though $d_K = d_ρ$ provably holds on regular domains.",
    "link": "http://arxiv.org/abs/2601.16139v1",
    "published_date": "2026-01-22T17:32:24",
    "categories": [
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16138",
    "title": "Automatic Classification of Arabic Literature into Historical Eras",
    "authors": [
      "Zainab Alhathloul",
      "Irfan Ahmad"
    ],
    "affiliations": [],
    "summary": "The Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.",
    "link": "http://arxiv.org/abs/2601.16138v1",
    "published_date": "2026-01-22T17:32:19",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16134",
    "title": "LLM Prompt Evaluation for Educational Applications",
    "authors": [
      "Langdon Holmes",
      "Adam Coscia",
      "Scott Crossley",
      "Joon Suh Choi",
      "Wesley Morris"
    ],
    "affiliations": [],
    "summary": "As large language models (LLMs) become increasingly common in educational applications, there is a growing need for evidence-based methods to design and evaluate LLM prompts that produce personalized and pedagogically aligned out-puts. This study presents a generalizable, systematic approach for evaluating prompts, demonstrated through an analysis of LLM-generated follow-up questions in a structured dialogue activity. Six prompt templates were designed and tested. The templates incorporated established prompt engineering patterns, with each prompt emphasizing distinct pedagogical strategies. The prompt templates were compared through a tournament-style evaluation framework that can be adapted for other educational applications. The tournament employed the Glicko2 rating system with eight judges evaluating question pairs across three dimensions: format, dialogue support, and appropriateness for learners. Data was sourced from 120 authentic user interactions across three distinct educational deployments. Results showed that a single prompt related to strategic reading out-performed other templates with win probabilities ranging from 81% to 100% in pairwise comparisons. This prompt combined persona and context manager pat-terns and was designed to support metacognitive learning strategies such as self-directed learning. The methodology showcases how educational technology re- searchers can systematically evaluate and improve prompt designs, moving beyond ad-hoc prompt engineering toward evidence-based prompt development for educational applications.",
    "link": "http://arxiv.org/abs/2601.16134v1",
    "published_date": "2026-01-22T17:31:25",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16130",
    "title": "Replicating Human Motivated Reasoning Studies with LLMs",
    "authors": [
      "Neeley Pate",
      "Adiba Mahbub Proma",
      "Hangfeng He",
      "James N. Druckman",
      "Daniel Molden",
      "Gourab Ghoshal",
      "Ehsan Hoque"
    ],
    "affiliations": [],
    "summary": "Motivated reasoning -- the idea that individuals processing information may be motivated to reach a certain conclusion, whether it be accurate or predetermined -- has been well-explored as a human phenomenon. However, it is unclear whether base LLMs mimic these motivational changes. Replicating 4 prior political motivated reasoning studies, we find that base LLM behavior does not align with expected human behavior. Furthermore, base LLM behavior across models shares some similarities, such as smaller standard deviations and inaccurate argument strength assessments. We emphasize the importance of these findings for researchers using LLMs to automate tasks such as survey data collection and argument assessment.",
    "link": "http://arxiv.org/abs/2601.16130v1",
    "published_date": "2026-01-22T17:29:07",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16127",
    "title": "Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging",
    "authors": [
      "Alphaeus Dmonte",
      "Vidhi Gupta",
      "Daniel J Perry",
      "Mark Arehart"
    ],
    "affiliations": [],
    "summary": "Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.",
    "link": "http://arxiv.org/abs/2601.16127v1",
    "published_date": "2026-01-22T17:28:24",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16107",
    "title": "Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets",
    "authors": [
      "Adithya Sineesh",
      "Akshita Kamsali"
    ],
    "affiliations": [],
    "summary": "Deep learning classifiers for Raman spectroscopy are increasingly reported to outperform classical chemometric approaches. However their evaluations are often conducted in isolation or compared against traditional machine learning methods or trivially adapted vision-based architectures that were not originally proposed for Raman spectroscopy. As a result, direct comparisons between existing deep learning models developed specifically for Raman spectral analysis on shared open-source datasets remain scarce. To the best of our knowledge, this study presents one of the first systematic benchmarks comparing three or more published Raman-specific deep learning classifiers across multiple open-source Raman datasets. We evaluate five representative deep learning architectures under a unified training and hyperparameter tuning protocol across three open-source Raman datasets selected to support standard evaluation, fine-tuning, and explicit distribution-shift testing. We report classification accuracies and macro-averaged F1 scores to provide a fair and reproducible comparison of deep learning models for Raman spectra based classification.",
    "link": "http://arxiv.org/abs/2601.16107v1",
    "published_date": "2026-01-22T16:54:53",
    "categories": [
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16098",
    "title": "Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification",
    "authors": [
      "Zack Dewis",
      "Yimin Zhu",
      "Zhengsen Xu",
      "Mabel Heffring",
      "Saeid Taleghanidoozdoozan",
      "Quinn Ledingham",
      "Lincoln Linlin Xu"
    ],
    "affiliations": [],
    "summary": "Although Mamba models greatly improve Hyperspectral Image (HSI) classification, they have critical challenges in terms defining efficient and adaptive token sequences for improve performance. This paper therefore presents CSSMamba (Clustering-guided Spatial-Spectral Mamba) framework to better address the challenges, with the following contributions. First, to achieve efficient and adaptive token sequences for improved Mamba performance, we integrate the clustering mechanism into a spatial Mamba architecture, leading to a cluster-guided spatial Mamba module (CSpaMamba) that reduces the Mamba sequence length and improves Mamba feature learning capability. Second, to improve the learning of both spatial and spectral information, we integrate the CSpaMamba module with a spectral mamba module (SpeMamba), leading to a complete clustering-guided spatial-spectral Mamba framework. Third, to further improve feature learning capability, we introduce an Attention-Driven Token Selection mechanism to optimize Mamba token sequencing. Last, to seamlessly integrate clustering into the Mamba model in a coherent manner, we design a Learnable Clustering Module that learns the cluster memberships in an adaptive manner. Experiments on the Pavia University, Indian Pines, and Liao-Ning 01 datasets demonstrate that CSSMamba achieves higher accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods.",
    "link": "http://arxiv.org/abs/2601.16098v1",
    "published_date": "2026-01-22T16:47:07",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16097",
    "title": "Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating",
    "authors": [
      "Makbule Gulcin Ozsoy"
    ],
    "affiliations": [],
    "summary": "Large Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75\\% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.",
    "link": "http://arxiv.org/abs/2601.16097v1",
    "published_date": "2026-01-22T16:46:57",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16093",
    "title": "SAMTok: Representing Any Mask with Two Words",
    "authors": [
      "Yikang Zhou",
      "Tao Zhang",
      "Dengxian Gong",
      "Yuanzheng Wu",
      "Ye Tian",
      "Haochen Wang",
      "Haobo Yuan",
      "Jiacong Wang",
      "Lu Qi",
      "Hao Fei",
      "Anran Wang",
      "Zhuochen Wang",
      "Yujing Wang",
      "Cheng Chen",
      "Shunping Ji",
      "Xiangtai Li"
    ],
    "affiliations": [],
    "summary": "Pixel-wise capabilities are essential for building interactive intelligent systems. However, pixel-wise multi-modal LLMs (MLLMs) remain difficult to scale due to complex region-level encoders, specialized segmentation decoders, and incompatible training objectives. To address these challenges, we present SAMTok, a discrete mask tokenizer that converts any region mask into two special tokens and reconstructs the mask using these tokens with high fidelity. By treating masks as new language tokens, SAMTok enables base MLLMs (such as the QwenVL series) to learn pixel-wise capabilities through standard next-token prediction and simple reinforcement learning, without architectural modifications and specialized loss design. SAMTok builds on SAM2 and is trained on 209M diverse masks using a mask encoder and residual vector quantizer to produce discrete, compact, and information-rich tokens. With 5M SAMTok-formatted mask understanding and generation data samples, QwenVL-SAMTok attains state-of-the-art or comparable results on region captioning, region VQA, grounded conversation, referring segmentation, scene graph parsing, and multi-round interactive segmentation. We further introduce a textual answer-matching reward that enables efficient reinforcement learning for mask generation, delivering substantial improvements on GRES and GCG benchmarks. Our results demonstrate a scalable and straightforward paradigm for equipping MLLMs with strong pixel-wise capabilities. Our code and models are available.",
    "link": "http://arxiv.org/abs/2601.16093v1",
    "published_date": "2026-01-22T16:44:09",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16087",
    "title": "Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics",
    "authors": [
      "Sukesh Subaharan"
    ],
    "affiliations": [],
    "summary": "Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored. This work investigates whether imposing dynamical structure on an external affective state can induce temporal coherence and controlled recovery in multi-turn dialogue. We introduce an agent-level affective subsystem that maintains a continuous Valence-Arousal-Dominance (VAD) state external to the language model and governed by first- and second-order update rules. Instantaneous affective signals are extracted using a fixed, memoryless estimator and integrated over time via exponential smoothing or momentum-based dynamics. The resulting affective state is injected back into generation without modifying model parameters. Using a fixed 25-turn dialogue protocol, we compare stateless, first-order, and second-order affective dynamics. Stateless agents fail to exhibit coherent trajectories or recovery, while state persistence enables delayed responses and reliable recovery. Second-order dynamics introduce affective inertia and hysteresis that increase with momentum, revealing a trade-off between stability and responsiveness.",
    "link": "http://arxiv.org/abs/2601.16087v1",
    "published_date": "2026-01-22T16:34:05",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16079",
    "title": "Masked Modeling for Human Motion Recovery Under Occlusions",
    "authors": [
      "Zhiyin Qian",
      "Siwei Zhang",
      "Bharat Lal Bhatnagar",
      "Federica Bogo",
      "Siyu Tang"
    ],
    "affiliations": [],
    "summary": "Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings.Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU.",
    "link": "http://arxiv.org/abs/2601.16079v1",
    "published_date": "2026-01-22T16:22:20",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16074",
    "title": "Explainable AI to Improve Machine Learning Reliability for Industrial Cyber-Physical Systems",
    "authors": [
      "Annemarie Jutte",
      "Uraz Odyurt"
    ],
    "affiliations": [],
    "summary": "Industrial Cyber-Physical Systems (CPS) are sensitive infrastructure from both safety and economics perspectives, making their reliability critically important. Machine Learning (ML), specifically deep learning, is increasingly integrated in industrial CPS, but the inherent complexity of ML models results in non-transparent operation. Rigorous evaluation is needed to prevent models from exhibiting unexpected behaviour on future, unseen data. Explainable AI (XAI) can be used to uncover model reasoning, allowing a more extensive analysis of behaviour. We apply XAI to to improve predictive performance of ML models intended for industrial CPS. We analyse the effects of components from time-series data decomposition on model predictions using SHAP values. Through this method, we observe evidence on the lack of sufficient contextual information during model training. By increasing the window size of data instances, informed by the XAI findings, we are able to improve model performance.",
    "link": "http://arxiv.org/abs/2601.16074v1",
    "published_date": "2026-01-22T16:18:22",
    "categories": [
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16070",
    "title": "On damage of interpolation to adversarial robustness in regression",
    "authors": [
      "Jingfu Peng",
      "Yuhong Yang"
    ],
    "affiliations": [],
    "summary": "Deep neural networks (DNNs) typically involve a large number of parameters and are trained to achieve zero or near-zero training error. Despite such interpolation, they often exhibit strong generalization performance on unseen data, a phenomenon that has motivated extensive theoretical investigations. Comforting results show that interpolation indeed may not affect the minimax rate of convergence under the squared error loss. In the mean time, DNNs are well known to be highly vulnerable to adversarial perturbations in future inputs. A natural question then arises: Can interpolation also escape from suboptimal performance under a future $X$-attack? In this paper, we investigate the adversarial robustness of interpolating estimators in a framework of nonparametric regression. A finding is that interpolating estimators must be suboptimal even under a subtle future $X$-attack, and achieving perfect fitting can substantially damage their robustness. An interesting phenomenon in the high interpolation regime, which we term the curse of simple size, is also revealed and discussed. Numerical experiments support our theoretical findings.",
    "link": "http://arxiv.org/abs/2601.16070v1",
    "published_date": "2026-01-22T16:09:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16065",
    "title": "DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models",
    "authors": [
      "Chenyang Li",
      "Jieyuan Liu",
      "Bin Li",
      "Bo Gao",
      "Yilin Yuan",
      "Yangfan He",
      "Yuchen Li",
      "Jingqun Tang"
    ],
    "affiliations": [],
    "summary": "Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.",
    "link": "http://arxiv.org/abs/2601.16065v1",
    "published_date": "2026-01-22T16:02:56",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16064",
    "title": "Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation",
    "authors": [
      "Shams Nafisa Ali",
      "Taufiq Hasan"
    ],
    "affiliations": [],
    "summary": "Deep learning has substantially advanced medical image segmentation, yet achieving robust generalization across diverse imaging modalities and anatomical structures remains a major challenge. A key contributor to this limitation lies in how existing architectures, ranging from CNNs to Transformers and their hybrids, primarily encode spatial information while overlooking frequency-domain representations that capture rich structural and textural cues. Although few recent studies have begun exploring spectral information at the feature level, supervision-level integration of frequency cues-crucial for fine-grained object localization-remains largely untapped. To this end, we propose Phi-SegNet, a CNN-based architecture that incorporates phase-aware information at both architectural and optimization levels. The network integrates Bi-Feature Mask Former (BFMF) modules that blend neighboring encoder features to reduce semantic gaps, and Reverse Fourier Attention (RFA) blocks that refine decoder outputs using phase-regularized features. A dedicated phase-aware loss aligns these features with structural priors, forming a closed feedback loop that emphasizes boundary precision. Evaluated on five public datasets spanning X-ray, US, histopathology, MRI, and colonoscopy, Phi-SegNet consistently achieved state-of-the-art performance, with an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model. In cross-dataset generalization scenarios involving unseen datasets from the known domain, Phi-SegNet also exhibits robust and superior performance, highlighting its adaptability and modality-agnostic design. These findings demonstrate the potential of leveraging spectral priors in both feature representation and supervision, paving the way for generalized segmentation frameworks that excel in fine-grained object localization.",
    "link": "http://arxiv.org/abs/2601.16064v1",
    "published_date": "2026-01-22T16:00:41",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16060",
    "title": "ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation",
    "authors": [
      "Yuan Lin",
      "Murong Xu",
      "Marc Hölle",
      "Chinmay Prabhakar",
      "Andreas Maier",
      "Vasileios Belagiannis",
      "Bjoern Menze",
      "Suprosanna Shit"
    ],
    "affiliations": [],
    "summary": "Widely adopted medical image segmentation methods, although efficient, are primarily deterministic and remain poorly amenable to natural language prompts. Thus, they lack the capability to estimate multiple proposals, human interaction, and cross-modality adaptation. Recently, text-to-image diffusion models have shown potential to bridge the gap. However, training them from scratch requires a large dataset-a limitation for medical image segmentation. Furthermore, they are often limited to binary segmentation and cannot be conditioned on a natural language prompt. To this end, we propose a novel framework called ProGiDiff that leverages existing image generation models for medical image segmentation purposes. Specifically, we propose a ControlNet-style conditioning mechanism with a custom encoder, suitable for image conditioning, to steer a pre-trained diffusion model to output segmentation masks. It naturally extends to a multi-class setting simply by prompting the target organ. Our experiment on organ segmentation from CT images demonstrates strong performance compared to previous methods and could greatly benefit from an expert-in-the-loop setting to leverage multiple proposals. Importantly, we demonstrate that the learned conditioning mechanism can be easily transferred through low-rank, few-shot adaptation to segment MR images.",
    "link": "http://arxiv.org/abs/2601.16060v1",
    "published_date": "2026-01-22T15:56:21",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16056",
    "title": "Designing faster mixed integer linear programming algorithm via learning the optimal path",
    "authors": [
      "Ruizhi Liu",
      "Liming Xu",
      "Xulin Huang",
      "Jingyan Sui",
      "Shizhe Ding",
      "Boyang Xia",
      "Chungong Yu",
      "Dongbo Bu"
    ],
    "affiliations": [],
    "summary": "Designing faster algorithms for solving Mixed-Integer Linear Programming (MILP) problems is highly desired across numerous practical domains, as a vast array of complex real-world challenges can be effectively modeled as MILP formulations. Solving these problems typically employs the branch-and-bound algorithm, the core of which can be conceived as searching for a path of nodes (or sub-problems) that contains the optimal solution to the original MILP problem. Traditional approaches to finding this path rely heavily on hand-crafted, intuition-based heuristic strategies, which often suffer from unstable and unpredictable performance across different MILP problem instances. To address this limitation, we introduce DeepBound, a deep learning-based node selection algorithm that automates the learning of such human intuition from data. The core of DeepBound lies in learning to prioritize nodes containing the optimal solution, thereby improving solving efficiency. DeepBound introduces a multi-level feature fusion network to capture the node representations. To tackle the inherent node imbalance in branch-and-bound trees, DeepBound employs a pairwise training paradigm that enhances the model's ability to discriminate between nodes. Extensive experiments on three NP-hard MILP benchmarks demonstrate that DeepBound achieves superior solving efficiency over conventional heuristic rules and existing learning-based approaches, obtaining optimal feasible solutions with significantly reduced computation time. Moreover, DeepBound demonstrates strong generalization capability on large and complex instances. The analysis of its learned features reveals that the method can automatically discover more flexible and robust feature selection, which may effectively improve and potentially replace human-designed heuristic rules.",
    "link": "http://arxiv.org/abs/2601.16056v1",
    "published_date": "2026-01-22T15:41:22",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16045",
    "title": "AgriPINN: A Process-Informed Neural Network for Interpretable and Scalable Crop Biomass Prediction Under Water Stress",
    "authors": [
      "Yue Shi",
      "Liangxiu Han",
      "Xin Zhang",
      "Tam Sobeih",
      "Thomas Gaiser",
      "Nguyen Huu Thuy",
      "Dominik Behrend",
      "Amit Kumar Srivastava",
      "Krishnagopal Halder",
      "Frank Ewert"
    ],
    "affiliations": [],
    "summary": "Accurate prediction of crop above-ground biomass (AGB) under water stress is critical for monitoring crop productivity, guiding irrigation, and supporting climate-resilient agriculture. Data-driven models scale well but often lack interpretability and degrade under distribution shift, whereas process-based crop models (e.g. DSSAT, APSIM, LINTUL5) require extensive calibration and are difficult to deploy over large spatial domains. To address these limitations, we propose AgriPINN, a process-informed neural network that integrates a biophysical crop-growth differential equation as a differentiable constraint within a deep learning backbone. This design encourages physiologically consistent biomass dynamics under water-stress conditions while preserving model scalability for spatially distributed AGB prediction. AgriPINN recovers latent physiological variables, including leaf area index (LAI), absorbed photosynthetically active radiation (PAR), radiation use efficiency (RUE), and water-stress factors, without requiring direct supervision. We pretrain AgriPINN on 60 years of historical data across 397 regions in Germany and fine-tune it on three years of field experiments under controlled water treatments. Results show that AgriPINN consistently outperforms state-of-the-art deep-learning baselines (ConvLSTM-ViT, SLTF, CNN-Transformer) and the process-based LINTUL5 model in terms of accuracy (RMSE reductions up to $43\\%$) and computational efficiency. By combining the scalability of deep learning with the biophysical rigor of process-based modeling, AgriPINN provides a robust and interpretable framework for spatio-temporal AGB prediction, offering practical value for planning of irrigation infrastructure, yield forecasting, and climate-adaptation planning.",
    "link": "http://arxiv.org/abs/2601.16045v1",
    "published_date": "2026-01-22T15:20:00",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16038",
    "title": "Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval",
    "authors": [
      "Olga Bunkova",
      "Lorenzo Di Fruscia",
      "Sophia Rupprecht",
      "Artur M. Schweidtmann",
      "Marcel J. T. Reinders",
      "Jana M. Weber"
    ],
    "affiliations": [],
    "summary": "Large Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval.",
    "link": "http://arxiv.org/abs/2601.16038v1",
    "published_date": "2026-01-22T15:11:02",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16034",
    "title": "Universal Refusal Circuits Across LLMs: Cross-Model Transfer via Trajectory Replay and Concept-Basis Reconstruction",
    "authors": [
      "Tony Cristofano"
    ],
    "affiliations": [],
    "summary": "Refusal behavior in aligned LLMs is often viewed as model-specific, yet we hypothesize it stems from a universal, low-dimensional semantic circuit shared across models. To test this, we introduce Trajectory Replay via Concept-Basis Reconstruction, a framework that transfers refusal interventions from donor to target models, spanning diverse architectures (e.g., Dense to MoE) and training regimes, without using target-side refusal supervision. By aligning layers via concept fingerprints and reconstructing refusal directions using a shared ``recipe'' of concept atoms, we map the donor's ablation trajectory into the target's semantic space. To preserve capabilities, we introduce a weight-SVD stability guard that projects interventions away from high-variance weight subspaces to prevent collateral damage. Our evaluation across 8 model pairs (including GPT-OSS-20B and GLM-4) confirms that these transferred recipes consistently attenuate refusal while maintaining performance, providing strong evidence for the semantic universality of safety alignment.",
    "link": "http://arxiv.org/abs/2601.16034v1",
    "published_date": "2026-01-22T15:08:28",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16032",
    "title": "Sawtooth Wavefront Reordering: Enhanced CuTile FlashAttention on NVIDIA GB10",
    "authors": [
      "Yifan Zhu",
      "Yekai Pan",
      "Chen Ding"
    ],
    "affiliations": [],
    "summary": "High-performance attention kernels are essential for Large Language Models. This paper presents analysis of CuTile-based Flash Attention memory behavior and a technique to improve its cache performance. In particular, our analysis on the NVIDIA GB10 (Grace Blackwell) identifies the main cause of L2 cache miss. Leveraging this insight, we introduce a new programming technique called Sawtooth Wavefront Reordering that reduces L2 misses. We validate it in both CUDA and CuTile, observing 50\\% or greater reduction in L2 misses and up to 60\\% increase in throughput on GB10.",
    "link": "http://arxiv.org/abs/2601.16032v1",
    "published_date": "2026-01-22T15:05:31",
    "categories": [
      "cs.PF",
      "cs.AI",
      "cs.LG",
      "cs.OS"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16027",
    "title": "Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment",
    "authors": [
      "Yiran Qiao",
      "Xiang Ao",
      "Jing Chen",
      "Yang Liu",
      "Qiwei Zhong",
      "Qing He"
    ],
    "affiliations": [],
    "summary": "The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur across seemingly unrelated streams. To address this, we propose CS-VAR (Cross-Session Evidence-Aware Retrieval-Augmented Detector) for live streaming risk assessment. In CS-VAR, a lightweight, domain-specific model performs fast session-level risk inference, guided during training by a Large Language Model (LLM) that reasons over retrieved cross-session behavioral evidence and transfers its local-to-global insights to the small model. This design enables the small model to recognize recurring patterns across streams, perform structured risk assessment, and maintain efficiency for real-time deployment. Extensive offline experiments on large-scale industrial datasets, combined with online validation, demonstrate the state-of-the-art performance of CS-VAR. Furthermore, CS-VAR provides interpretable, localized signals that effectively empower real-world moderation for live streaming.",
    "link": "http://arxiv.org/abs/2601.16027v1",
    "published_date": "2026-01-22T14:55:51",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16020",
    "title": "Keyframe-Based Feed-Forward Visual Odometry",
    "authors": [
      "Weichen Dai",
      "Wenhan Su",
      "Da Kong",
      "Yuhang Ming",
      "Wanzeng Kong"
    ],
    "affiliations": [],
    "summary": "The emergence of visual foundation models has revolutionized visual odometry~(VO) and SLAM, enabling pose estimation and dense reconstruction within a single feed-forward network. However, unlike traditional pipelines that leverage keyframe methods to enhance efficiency and accuracy, current foundation model based methods, such as VGGT-Long, typically process raw image sequences indiscriminately. This leads to computational redundancy and degraded performance caused by low inter-frame parallax, which provides limited contextual stereo information. Integrating traditional geometric heuristics into these methods is non-trivial, as their performance depends on high-dimensional latent representations rather than explicit geometric metrics. To bridge this gap, we propose a novel keyframe-based feed-forward VO. Instead of relying on hand-crafted rules, our approach employs reinforcement learning to derive an adaptive keyframe policy in a data-driven manner, aligning selection with the intrinsic characteristics of the underlying foundation model. We train our agent on TartanAir dataset and conduct extensive evaluations across several real-world datasets. Experimental results demonstrate that the proposed method achieves consistent and substantial improvements over state-of-the-art feed-forward VO methods.",
    "link": "http://arxiv.org/abs/2601.16020v1",
    "published_date": "2026-01-22T14:45:42",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16007",
    "title": "PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models",
    "authors": [
      "Chak-Wing Mak",
      "Guanyu Zhu",
      "Boyi Zhang",
      "Hongji Li",
      "Xiaowei Chi",
      "Kevin Zhang",
      "Yichen Wu",
      "Yangfan He",
      "Chun-Kai Fan",
      "Wentao Lu",
      "Kuangzhi Ge",
      "Xinyu Fang",
      "Hongyang He",
      "Kuan Lu",
      "Tianxiang Xu",
      "Li Zhang",
      "Yongxin Ni",
      "Youhua Li",
      "Shanghang Zhang"
    ],
    "affiliations": [],
    "summary": "Modern foundational Multimodal Large Language Models (MLLMs) and video world models have advanced significantly in mathematical, common-sense, and visual reasoning, but their grasp of the underlying physics remains underexplored. Existing benchmarks attempting to measure this matter rely on synthetic, Visual Question Answer templates or focus on perceptual video quality that is tangential to measuring how well the video abides by physical laws. To address this fragmentation, we introduce PhysicsMind, a unified benchmark with both real and simulation environments that evaluates law-consistent reasoning and generation over three canonical principles: Center of Mass, Lever Equilibrium, and Newton's First Law. PhysicsMind comprises two main tasks: i) VQA tasks, testing whether models can reason and determine physical quantities and values from images or short videos, and ii) Video Generation(VG) tasks, evaluating if predicted motion trajectories obey the same center-of-mass, torque, and inertial constraints as the ground truth. A broad range of recent models and video generation models is evaluated on PhysicsMind and found to rely on appearance heuristics while often violating basic mechanics. These gaps indicate that current scaling and training are still insufficient for robust physical understanding, underscoring PhysicsMind as a focused testbed for physics-aware multimodal models. Our data will be released upon acceptance.",
    "link": "http://arxiv.org/abs/2601.16007v1",
    "published_date": "2026-01-22T14:33:01",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15995",
    "title": "PUMA: Perception-driven Unified Foothold Prior for Mobility Augmented Quadruped Parkour",
    "authors": [
      "Liang Wang",
      "Kanzhong Yao",
      "Yang Liu",
      "Weikai Qin",
      "Jun Wu",
      "Zhe Sun",
      "Qiuguo Zhu"
    ],
    "affiliations": [],
    "summary": "Parkour tasks for quadrupeds have emerged as a promising benchmark for agile locomotion. While human athletes can effectively perceive environmental characteristics to select appropriate footholds for obstacle traversal, endowing legged robots with similar perceptual reasoning remains a significant challenge. Existing methods often rely on hierarchical controllers that follow pre-computed footholds, thereby constraining the robot's real-time adaptability and the exploratory potential of reinforcement learning. To overcome these challenges, we present PUMA, an end-to-end learning framework that integrates visual perception and foothold priors into a single-stage training process. This approach leverages terrain features to estimate egocentric polar foothold priors, composed of relative distance and heading, guiding the robot in active posture adaptation for parkour tasks. Extensive experiments conducted in simulation and real-world environments across various discrete complex terrains, demonstrate PUMA's exceptional agility and robustness in challenging scenarios.",
    "link": "http://arxiv.org/abs/2601.15995v1",
    "published_date": "2026-01-22T14:16:12",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15977",
    "title": "Predicting Healthcare System Visitation Flow by Integrating Hospital Attributes and Population Socioeconomics with Human Mobility Data",
    "authors": [
      "Binbin Lin",
      "Lei Zou",
      "Hao Tian",
      "Heng Cai",
      "Yifan Yang",
      "Bing Zhou"
    ],
    "affiliations": [],
    "summary": "Healthcare visitation patterns are influenced by a complex interplay of hospital attributes, population socioeconomics, and spatial factors. However, existing research often adopts a fragmented approach, examining these determinants in isolation. This study addresses this gap by integrating hospital capacities, occupancy rates, reputation, and popularity with population SES and spatial mobility patterns to predict visitation flows and analyze influencing factors. Utilizing four years of SafeGraph mobility data and user experience data from Google Maps Reviews, five flow prediction models, Naive Regression, Gradient Boosting, Multilayer Perceptrons (MLPs), Deep Gravity, and Heterogeneous Graph Neural Networks (HGNN),were trained and applied to simulate visitation flows in Houston, Texas, U.S. The Shapley additive explanation (SHAP) analysis and the Partial Dependence Plot (PDP) method were employed to examine the combined impacts of different factors on visitation patterns. The findings reveal that Deep Gravity outperformed other models. Hospital capacities, ICU occupancy rates, ratings, and popularity significantly influence visitation patterns, with their effects varying across different travel distances. Short-distance visits are primarily driven by convenience, whereas long-distance visits are influenced by hospital ratings. White-majority areas exhibited lower sensitivity to hospital ratings for short-distance visits, while Asian populations and those with higher education levels prioritized hospital rating in their visitation decisions. SES further influence these patterns, as areas with higher proportions of Hispanic, Black, under-18, and over-65 populations tend to have more frequent hospital visits, potentially reflecting greater healthcare needs or limited access to alternative medical services.",
    "link": "http://arxiv.org/abs/2601.15977v1",
    "published_date": "2026-01-22T13:56:26",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15968",
    "title": "HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models",
    "authors": [
      "Xin Xie",
      "Jiaxian Guo",
      "Dong Gong"
    ],
    "affiliations": [],
    "summary": "Diffusion models achieve state-of-the-art performance but often fail to generate outputs that align with human preferences and intentions, resulting in images with poor aesthetic quality and semantic inconsistencies. Existing alignment methods present a difficult trade-off: fine-tuning approaches suffer from loss of diversity with reward over-optimization, while test-time scaling methods introduce significant computational overhead and tend to under-optimize. To address these limitations, we propose HyperAlign, a novel framework that trains a hypernetwork for efficient and effective test-time alignment. Instead of modifying latent states, HyperAlign dynamically generates low-rank adaptation weights to modulate the diffusion model's generation operators. This allows the denoising trajectory to be adaptively adjusted based on input latents, timesteps and prompts for reward-conditioned alignment. We introduce multiple variants of HyperAlign that differ in how frequently the hypernetwork is applied, balancing between performance and efficiency. Furthermore, we optimize the hypernetwork using a reward score objective regularized with preference data to reduce reward hacking. We evaluate HyperAlign on multiple extended generative paradigms, including Stable Diffusion and FLUX. It significantly outperforms existing fine-tuning and test-time scaling baselines in enhancing semantic consistency and visual appeal.",
    "link": "http://arxiv.org/abs/2601.15968v1",
    "published_date": "2026-01-22T13:49:47",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15953",
    "title": "Decoupling Return-to-Go for Efficient Decision Transformer",
    "authors": [
      "Yongyi Wang",
      "Hanyu Liu",
      "Lingfeng Li",
      "Bozhou Chen",
      "Ang Li",
      "Qirui Zheng",
      "Xionghui Yang",
      "Wenxin Li"
    ],
    "affiliations": [],
    "summary": "The Decision Transformer (DT) has established a powerful sequence modeling approach to offline reinforcement learning. It conditions its action predictions on Return-to-Go (RTG), using it both to distinguish trajectory quality during training and to guide action generation at inference. In this work, we identify a critical redundancy in this design: feeding the entire sequence of RTGs into the Transformer is theoretically unnecessary, as only the most recent RTG affects action prediction. We show that this redundancy can impair DT's performance through experiments. To resolve this, we propose the Decoupled DT (DDT). DDT simplifies the architecture by processing only observation and action sequences through the Transformer, using the latest RTG to guide the action prediction. This streamlined approach not only improves performance but also reduces computational cost. Our experiments show that DDT significantly outperforms DT and establishes competitive performance against state-of-the-art DT variants across multiple offline RL tasks.",
    "link": "http://arxiv.org/abs/2601.15953v1",
    "published_date": "2026-01-22T13:42:08",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15930",
    "title": "MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging",
    "authors": [
      "Tianjun Wei",
      "Enneng Yang",
      "Yingpeng Du",
      "Huizhong Guo",
      "Jie Zhang",
      "Zhu Sun"
    ],
    "affiliations": [],
    "summary": "Model merging (MM) offers an efficient mechanism for integrating multiple specialized models without access to original training data or costly retraining. While MM has demonstrated success in domains like computer vision, its role in recommender systems (RSs) remains largely unexplored. Recently, Generative Recommendation (GR) has emerged as a new paradigm in RSs, characterized by rapidly growing model scales and substantial computational costs, making MM particularly appealing for cost-sensitive deployment scenarios. In this work, we present the first systematic study of MM in GR through a contextual lens. We focus on a fundamental yet underexplored challenge in real-world: how to merge generative recommenders specialized to different real-world contexts, arising from temporal evolving user behaviors and heterogeneous application domains. To this end, we propose a unified framework MMGRid, a structured contextual grid of GR checkpoints that organizes models trained under diverse contexts induced by temporal evolution and domain diversity. All checkpoints are derived from a shared base LLM but fine-tuned on context-specific data, forming a realistic and controlled model space for systematically analyzing MM across GR paradigms and merging algorithms. Our investigation reveals several key insights. First, training GR models from LLMs can introduce parameter conflicts during merging due to token distribution shifts and objective disparities; such conflicts can be alleviated by disentangling task-aware and context-specific parameter changes via base model replacement. Second, incremental training across contexts induces recency bias, which can be effectively balanced through weighted contextual merging. Notably, we observe that optimal merging weights correlate with context-dependent interaction characteristics, offering practical guidance for weight selection in real-world deployments.",
    "link": "http://arxiv.org/abs/2601.15930v1",
    "published_date": "2026-01-22T13:09:16",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15929",
    "title": "NeuroMamba: Multi-Perspective Feature Interaction with Visual Mamba for Neuron Segmentation",
    "authors": [
      "Liuyun Jiang",
      "Yizhuo Lu",
      "Yanchao Zhang",
      "Jiazheng Liu",
      "Hua Han"
    ],
    "affiliations": [],
    "summary": "Neuron segmentation is the cornerstone of reconstructing comprehensive neuronal connectomes, which is essential for deciphering the functional organization of the brain. The irregular morphology and densely intertwined structures of neurons make this task particularly challenging. Prevailing CNN-based methods often fail to resolve ambiguous boundaries due to the lack of long-range context, whereas Transformer-based methods suffer from boundary imprecision caused by the loss of voxel-level details during patch partitioning. To address these limitations, we propose NeuroMamba, a multi-perspective framework that exploits the linear complexity of Mamba to enable patch-free global modeling and synergizes this with complementary local feature modeling, thereby efficiently capturing long-range dependencies while meticulously preserving fine-grained voxel details. Specifically, we design a channel-gated Boundary Discriminative Feature Extractor (BDFE) to enhance local morphological cues. Complementing this, we introduce the Spatial Continuous Feature Extractor (SCFE), which integrates a resolution-aware scanning mechanism into the Visual Mamba architecture to adaptively model global dependencies across varying data resolutions. Finally, a cross-modulation mechanism synergistically fuses these multi-perspective features. Our method demonstrates state-of-the-art performance across four public EM datasets, validating its exceptional adaptability to both anisotropic and isotropic resolutions. The source code will be made publicly available.",
    "link": "http://arxiv.org/abs/2601.15929v1",
    "published_date": "2026-01-22T13:06:24",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15924",
    "title": "Class Confidence Aware Reweighting for Long Tailed Learning",
    "authors": [
      "Brainard Philemon Jagati",
      "Jitendra Tembhurne",
      "Harsh Goud",
      "Rudra Pratap Singh",
      "Chandrashekhar Meshram"
    ],
    "affiliations": [],
    "summary": "Deep neural network models degrade significantly in the long-tailed data distribution, with the overall training data dominated by a small set of classes in the head, and the tail classes obtaining less training examples. Addressing the imbalance in the classes, attention in the related literature was given mainly to the adjustments carried out in the decision space in terms of either corrections performed at the logit level in order to compensate class-prior bias, with the least attention to the optimization process resulting from the adjustments introduced through the differences in the confidences among the samples. In the current study, we present the design of a class and confidence-aware re-weighting scheme for long-tailed learning. This scheme is purely based upon the loss level and has a complementary nature to the existing methods performing the adjustment of the logits. In the practical implementation stage of the proposed scheme, we use an Ω(p_t, f_c) function. This function enables the modulation of the contribution towards the training task based upon the confidence value of the prediction, as well as the relative frequency of the corresponding class. Our observations in the experiments are corroborated by significant experimental results performed on the CIFAR-100-LT, ImageNet-LT, and iNaturalist2018 datasets under various values of imbalance factors that clearly authenticate the theoretical discussions above.",
    "link": "http://arxiv.org/abs/2601.15924v1",
    "published_date": "2026-01-22T12:58:05",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15915",
    "title": "Progressive Power Homotopy for Non-convex Optimization",
    "authors": [
      "Chen Xu"
    ],
    "affiliations": [],
    "summary": "We propose a novel first-order method for non-convex optimization of the form $\\max_{\\bm{w}\\in\\mathbb{R}^d}\\mathbb{E}_{\\bm{x}\\sim\\mathcal{D}}[f_{\\bm{w}}(\\bm{x})]$, termed Progressive Power Homotopy (Prog-PowerHP). The method applies stochastic gradient ascent to a surrogate objective obtained by first performing a power transformation and then Gaussian smoothing, $F_{N,σ}(\\bmμ):=\\mathbb{E}_{\\bm{w}\\sim\\mathcal{N}(\\bmμ,σ^2I_d),\\bm{x}\\sim\\mathcal{D}}[e^{Nf_w(\\bm{x})}]$, while progressively increasing the power parameter $N$ and decreasing the smoothing scale $σ$ along the optimization trajectory. We prove that, under mild regularity conditions, Prog-PowerHP converges to a small neighborhood of the global optimum with an iteration complexity scaling nearly as $O(d^2\\varepsilon^{-2})$. Empirically, Prog-PowerHP demonstrates clear advantages in phase retrieval when the samples-to-dimension ratio approaches the information-theoretic limit, and in training two-layer neural networks in under-parameterized regimes. These results suggest that Prog-PowerHP is particularly effective for navigating cluttered non-convex landscapes where standard first-order methods struggle.",
    "link": "http://arxiv.org/abs/2601.15915v1",
    "published_date": "2026-01-22T12:44:25",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15914",
    "title": "The Latency Wall: Benchmarking Off-the-Shelf Emotion Recognition for Real-Time Virtual Avatars",
    "authors": [
      "Yarin Benyamin"
    ],
    "affiliations": [],
    "summary": "In the realm of Virtual Reality (VR) and Human-Computer Interaction (HCI), real-time emotion recognition shows promise for supporting individuals with Autism Spectrum Disorder (ASD) in improving social skills. This task requires a strict latency-accuracy trade-off, with motion-to-photon (MTP) latency kept below 140 ms to maintain contingency. However, most off-the-shelf Deep Learning models prioritize accuracy over the strict timing constraints of commodity hardware. As a first step toward accessible VR therapy, we benchmark State-of-the-Art (SOTA) models for Zero-Shot Facial Expression Recognition (FER) on virtual characters using the UIBVFED dataset. We evaluate Medium and Nano variants of YOLO (v8, v11, and v12) for face detection, alongside general-purpose Vision Transformers including CLIP, SigLIP, and ViT-FER.Our results on CPU-only inference demonstrate that while face detection on stylized avatars is robust (100% accuracy), a \"Latency Wall\" exists in the classification stage. The YOLOv11n architecture offers the optimal balance for detection (~54 ms). However, general-purpose Transformers like CLIP and SigLIP fail to achieve viable accuracy (<23%) or speed (>150 ms) for real-time loops. This study highlights the necessity for lightweight, domain-specific architectures to enable accessible, real-time AI in therapeutic settings.",
    "link": "http://arxiv.org/abs/2601.15914v1",
    "published_date": "2026-01-22T12:44:12",
    "categories": [
      "cs.CV",
      "cs.HC"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15912",
    "title": "TeNet: Text-to-Network for Compact Policy Synthesis",
    "authors": [
      "Ariyan Bighashdel",
      "Kevin Sebastian Luck"
    ],
    "affiliations": [],
    "summary": "Robots that follow natural-language instructions often either plan at a high level using hand-designed interfaces or rely on large end-to-end models that are difficult to deploy for real-time control. We propose TeNet (Text-to-Network), a framework for instantiating compact, task-specific robot policies directly from natural language descriptions. TeNet conditions a hypernetwork on text embeddings produced by a pretrained large language model (LLM) to generate a fully executable policy, which then operates solely on low-dimensional state inputs at high control frequencies. By using the language only once at the policy instantiation time, TeNet inherits the general knowledge and paraphrasing robustness of pretrained LLMs while remaining lightweight and efficient at execution time. To improve generalization, we optionally ground language in behavior during training by aligning text embeddings with demonstrated actions, while requiring no demonstrations at inference time. Experiments on MuJoCo and Meta-World benchmarks show that TeNet produces policies that are orders of magnitude smaller than sequence-based baselines, while achieving strong performance in both multi-task and meta-learning settings and supporting high-frequency control. These results show that text-conditioned hypernetworks offer a practical way to build compact, language-driven controllers for ressource-constrained robot control tasks with real-time requirements.",
    "link": "http://arxiv.org/abs/2601.15912v1",
    "published_date": "2026-01-22T12:42:30",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15906",
    "title": "Opening the Black Box: Preliminary Insights into Affective Modeling in Multimodal Foundation Models",
    "authors": [
      "Zhen Zhang",
      "Runhao Zeng",
      "Sicheng Zhao",
      "Xiping Hu"
    ],
    "affiliations": [],
    "summary": "Understanding where and how emotions are represented in large-scale foundation models remains an open problem, particularly in multimodal affective settings. Despite the strong empirical performance of recent affective models, the internal architectural mechanisms that support affective understanding and generation are still poorly understood. In this work, we present a systematic mechanistic study of affective modeling in multimodal foundation models. Across multiple architectures, training strategies, and affective tasks, we analyze how emotion-oriented supervision reshapes internal model parameters. Our results consistently reveal a clear and robust pattern: affective adaptation does not primarily focus on the attention module, but instead localizes to the feed-forward gating projection (\\texttt{gate\\_proj}). Through controlled module transfer, targeted single-module adaptation, and destructive ablation, we further demonstrate that \\texttt{gate\\_proj} is sufficient, efficient, and necessary for affective understanding and generation. Notably, by tuning only approximately 24.5\\% of the parameters tuned by AffectGPT, our approach achieves 96.6\\% of its average performance across eight affective tasks, highlighting substantial parameter efficiency. Together, these findings provide empirical evidence that affective capabilities in foundation models are structurally mediated by feed-forward gating mechanisms and identify \\texttt{gate\\_proj} as a central architectural locus of affective modeling.",
    "link": "http://arxiv.org/abs/2601.15906v1",
    "published_date": "2026-01-22T12:34:20",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15892",
    "title": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model",
    "authors": [
      "Chenghao Fan",
      "Wen Heng",
      "Bo Li",
      "Sichen Liu",
      "Yuxuan Song",
      "Jing Su",
      "Xiaoye Qu",
      "Kai Shen",
      "Wei Wei"
    ],
    "affiliations": [],
    "summary": "Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \\~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.",
    "link": "http://arxiv.org/abs/2601.15892v1",
    "published_date": "2026-01-22T12:13:17",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15879",
    "title": "Evaluating and Achieving Controllable Code Completion in Code LLM",
    "authors": [
      "Jiajun Zhang",
      "Zeyu Cui",
      "Lei Zhang",
      "Jian Yang",
      "Jiaxi Yang",
      "Qiang Liu",
      "Zilei Wang",
      "Binyuan Hui",
      "Liang Wang",
      "Junyang Lin"
    ],
    "affiliations": [],
    "summary": "Code completion has become a central task, gaining significant attention with the rise of large language model (LLM)-based tools in software engineering. Although recent advances have greatly improved LLMs' code completion abilities, evaluation methods have not advanced equally. Most current benchmarks focus solely on functional correctness of code completions based on given context, overlooking models' ability to follow user instructions during completion-a common scenario in LLM-assisted programming. To address this limitation, we present the first instruction-guided code completion benchmark, Controllable Code Completion Benchmark (C3-Bench), comprising 2,195 carefully designed completion tasks. Through comprehensive evaluation of over 40 mainstream LLMs across C3-Bench and conventional benchmarks, we reveal substantial gaps in instruction-following capabilities between open-source and advanced proprietary models during code completion tasks. Moreover, we develop a straightforward data synthesis pipeline that leverages Qwen2.5-Coder to generate high-quality instruction-completion pairs for supervised fine-tuning (SFT). The resulting model, Qwen2.5-Coder-C3, achieves state-of-the-art performance on C3-Bench. Our findings provide valuable insights for enhancing LLMs' code completion and instruction-following capabilities, establishing new directions for future research in code LLMs. To facilitate reproducibility and foster further research in code LLMs, we open-source all code, datasets, and models.",
    "link": "http://arxiv.org/abs/2601.15879v1",
    "published_date": "2026-01-22T11:40:04",
    "categories": [
      "cs.SE",
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15874",
    "title": "SoK: Challenges in Tabular Membership Inference Attacks",
    "authors": [
      "Cristina Pêra",
      "Tânia Carvalho",
      "Maxime Cordy",
      "Luís Antunes"
    ],
    "affiliations": [],
    "summary": "Membership Inference Attacks (MIAs) are currently a dominant approach for evaluating privacy in machine learning applications. Despite their significance in identifying records belonging to the training dataset, several concerns remain unexplored, particularly with regard to tabular data. In this paper, first, we provide an extensive review and analysis of MIAs considering two main learning paradigms: centralized and federated learning. We extend and refine the taxonomy for both. Second, we demonstrate the efficacy of MIAs in tabular data using several attack strategies, also including defenses. Furthermore, in a federated learning scenario, we consider the threat posed by an outsider adversary, which is often neglected. Third, we demonstrate the high vulnerability of single-outs (records with a unique signature) to MIAs. Lastly, we explore how MIAs transfer across model architectures. Our results point towards a general poor performance of these attacks in tabular data which contrasts with previous state-of-the-art. Notably, even attacks with limited attack performance can still successfully expose a large portion of single-outs. Moreover, our findings suggest that using different surrogate models makes MIAs more effective.",
    "link": "http://arxiv.org/abs/2601.15874v1",
    "published_date": "2026-01-22T11:30:11",
    "categories": [
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15872",
    "title": "PF-D2M: A Pose-free Diffusion Model for Universal Dance-to-Music Generation",
    "authors": [
      "Jaekwon Im",
      "Natalia Polouliakh",
      "Taketo Akama"
    ],
    "affiliations": [],
    "summary": "Dance-to-music generation aims to generate music that is aligned with dance movements. Existing approaches typically rely on body motion features extracted from a single human dancer and limited dance-to-music datasets, which restrict their performance and applicability to real-world scenarios involving multiple dancers and non-human dancers. In this paper, we propose PF-D2M, a universal diffusion-based dance-to-music generation model that incorporates visual features extracted from dance videos. PF-D2M is trained with a progressive training strategy that effectively addresses data scarcity and generalization challenges. Both objective and subjective evaluations show that PF-D2M achieves state-of-the-art performance in dance-music alignment and music quality.",
    "link": "http://arxiv.org/abs/2601.15872v1",
    "published_date": "2026-01-22T11:21:54",
    "categories": [
      "cs.SD",
      "cs.CV",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15867",
    "title": "Out-of-Distribution Detection Based on Total Variation Estimation",
    "authors": [
      "Dabiao Ma",
      "Zhiba Su",
      "Jian Yang",
      "Haojun Fei"
    ],
    "affiliations": [],
    "summary": "This paper introduces a novel approach to securing machine learning model deployments against potential distribution shifts in practical applications, the Total Variation Out-of-Distribution (TV-OOD) detection method. Existing methods have produced satisfactory results, but TV-OOD improves upon these by leveraging the Total Variation Network Estimator to calculate each input's contribution to the overall total variation. By defining this as the total variation score, TV-OOD discriminates between in- and out-of-distribution data. The method's efficacy was tested across a range of models and datasets, consistently yielding results in image classification tasks that were either comparable or superior to those achieved by leading-edge out-of-distribution detection techniques across all evaluation metrics.",
    "link": "http://arxiv.org/abs/2601.15867v1",
    "published_date": "2026-01-22T11:15:16",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15865",
    "title": "A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies",
    "authors": [
      "Jingsong Xia",
      "Siqi Wang"
    ],
    "affiliations": [],
    "summary": "Background: Coronary angiography (CAG) is a cornerstone imaging modality for assessing coronary artery disease and guiding interventional treatment decisions. However, in real-world clinical settings, angiographic images are often characterized by complex lesion morphology, severe class imbalance, label uncertainty, and limited computational resources, posing substantial challenges to conventional deep learning approaches in terms of robustness and generalization.Methods: The proposed framework is built upon a pretrained convolutional neural network to construct a lightweight hybrid neural representation. A selective neural plasticity training strategy is introduced to enable efficient parameter adaptation. Furthermore, a brain-inspired attention-modulated loss function, combining Focal Loss with label smoothing, is employed to enhance sensitivity to hard samples and uncertain annotations. Class-imbalance-aware sampling and cosine annealing with warm restarts are adopted to mimic rhythmic regulation and attention allocation mechanisms observed in biological neural systems.Results: Experimental results demonstrate that the proposed lightweight brain-inspired model achieves strong and stable performance in binary coronary angiography classification, yielding competitive accuracy, recall, F1-score, and AUC metrics while maintaining high computational efficiency.Conclusion: This study validates the effectiveness of brain-inspired learning mechanisms in lightweight medical image analysis and provides a biologically plausible and deployable solution for intelligent clinical decision support under limited computational resources.",
    "link": "http://arxiv.org/abs/2601.15865v1",
    "published_date": "2026-01-22T11:14:37",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15859",
    "title": "Uncertainty-guided Generation of Dark-field Radiographs",
    "authors": [
      "Lina Felsner",
      "Henriette Bast",
      "Tina Dorosti",
      "Florian Schaff",
      "Franz Pfeiffer",
      "Daniela Pfeiffer",
      "Julia Schnabel"
    ],
    "affiliations": [],
    "summary": "X-ray dark-field radiography provides complementary diagnostic information to conventional attenuation imaging by visualizing microstructural tissue changes through small-angle scattering. However, the limited availability of such data poses challenges for developing robust deep learning models. In this work, we present the first framework for generating dark-field images directly from standard attenuation chest X-rays using an Uncertainty-Guided Progressive Generative Adversarial Network. The model incorporates both aleatoric and epistemic uncertainty to improve interpretability and reliability. Experiments demonstrate high structural fidelity of the generated images, with consistent improvement of quantitative metrics across stages. Furthermore, out-of-distribution evaluation confirms that the proposed model generalizes well. Our results indicate that uncertainty-guided generative modeling enables realistic dark-field image synthesis and provides a reliable foundation for future clinical applications.",
    "link": "http://arxiv.org/abs/2601.15859v1",
    "published_date": "2026-01-22T11:07:19",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15838",
    "title": "TinySense: Effective CSI Compression for Scalable and Accurate Wi-Fi Sensing",
    "authors": [
      "Toan Gian",
      "Dung T. Tran",
      "Viet Quoc Pham",
      "Francesco Restuccia",
      "Van-Dinh Nguyen"
    ],
    "affiliations": [],
    "summary": "With the growing demand for device-free and privacy-preserving sensing solutions, Wi-Fi sensing has emerged as a promising approach for human pose estimation (HPE). However, existing methods often process vast amounts of channel state information (CSI) data directly, ultimately straining networking resources. This paper introduces TinySense, an efficient compression framework that enhances the scalability of Wi-Fi-based human sensing. Our approach is based on a new vector quantization-based generative adversarial network (VQGAN). Specifically, by leveraging a VQGAN-learned codebook, TinySense significantly reduces CSI data while maintaining the accuracy required for reliable HPE. To optimize compression, we employ the K-means algorithm to dynamically adjust compression bitrates to cluster a large-scale pre-trained codebook into smaller subsets. Furthermore, a Transformer model is incorporated to mitigate bitrate loss, enhancing robustness in unreliable networking conditions. We prototype TinySense on an experimental testbed using Jetson Nano and Raspberry Pi to measure latency and network resource use. Extensive results demonstrate that TinySense significantly outperforms state-of-the-art compression schemes, achieving up to 1.5x higher HPE accuracy score (PCK20) under the same compression rate. It also reduces latency and networking overhead, respectively, by up to 5x and 2.5x. The code repository is available online at here.",
    "link": "http://arxiv.org/abs/2601.15838v1",
    "published_date": "2026-01-22T10:44:40",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15829",
    "title": "Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion",
    "authors": [
      "Yonghao Xu",
      "Pedram Ghamisi",
      "Qihao Weng"
    ],
    "affiliations": [],
    "summary": "Recent years have witnessed the remarkable success of deep learning in remote sensing image interpretation, driven by the availability of large-scale benchmark datasets. However, this reliance on massive training data also brings two major challenges: (1) high storage and computational costs, and (2) the risk of data leakage, especially when sensitive categories are involved. To address these challenges, this study introduces the concept of dataset distillation into the field of remote sensing image interpretation for the first time. Specifically, we train a text-to-image diffusion model to condense a large-scale remote sensing dataset into a compact and representative distilled dataset. To improve the discriminative quality of the synthesized samples, we propose a classifier-driven guidance by injecting a classification consistency loss from a pre-trained model into the diffusion training process. Besides, considering the rich semantic complexity of remote sensing imagery, we further perform latent space clustering on training samples to select representative and diverse prototypes as visual style guidance, while using a visual language model to provide aggregated text descriptions. Experiments on three high-resolution remote sensing scene classification benchmarks show that the proposed method can distill realistic and diverse samples for downstream model training. Code and pre-trained models are available online (https://github.com/YonghaoXu/DPD).",
    "link": "http://arxiv.org/abs/2601.15829v1",
    "published_date": "2026-01-22T10:30:32",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15824",
    "title": "Introducing the Generative Application Firewall (GAF)",
    "authors": [
      "Joan Vendrell Farreny",
      "Martí Jordà Roca",
      "Miquel Cornudella Gaya",
      "Rodrigo Fernández Baón",
      "Víctor García Martínez",
      "Eduard Camacho Sucarrat",
      "Alessandro Pignati"
    ],
    "affiliations": [],
    "summary": "This paper introduces the Generative Application Firewall (GAF), a new architectural layer for securing LLM applications. Existing defenses -- prompt filters, guardrails, and data-masking -- remain fragmented; GAF unifies them into a single enforcement point, much like a WAF coordinates defenses for web traffic, while also covering autonomous agents and their tool interactions.",
    "link": "http://arxiv.org/abs/2601.15824v1",
    "published_date": "2026-01-22T10:19:24",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15816",
    "title": "Virtual Traffic Police: Large Language Model-Augmented Traffic Signal Control for Unforeseen Incidents",
    "authors": [
      "Shiqi Wei",
      "Qiqing Wang",
      "Kaidi Yang"
    ],
    "affiliations": [],
    "summary": "Adaptive traffic signal control (TSC) has demonstrated strong effectiveness in managing dynamic traffic flows. However, conventional methods often struggle when unforeseen traffic incidents occur (e.g., accidents and road maintenance), which typically require labor-intensive and inefficient manual interventions by traffic police officers. Large Language Models (LLMs) appear to be a promising solution thanks to their remarkable reasoning and generalization capabilities. Nevertheless, existing works often propose to replace existing TSC systems with LLM-based systems, which can be (i) unreliable due to the inherent hallucinations of LLMs and (ii) costly due to the need for system replacement. To address the issues of existing works, we propose a hierarchical framework that augments existing TSC systems with LLMs, whereby a virtual traffic police agent at the upper level dynamically fine-tunes selected parameters of signal controllers at the lower level in response to real-time traffic incidents. To enhance domain-specific reliability in response to unforeseen traffic incidents, we devise a self-refined traffic language retrieval system (TLRS), whereby retrieval-augmented generation is employed to draw knowledge from a tailored traffic language database that encompasses traffic conditions and controller operation principles. Moreover, we devise an LLM-based verifier to update the TLRS continuously over the reasoning process. Our results show that LLMs can serve as trustworthy virtual traffic police officers that can adapt conventional TSC methods to unforeseen traffic incidents with significantly improved operational efficiency and reliability.",
    "link": "http://arxiv.org/abs/2601.15816v1",
    "published_date": "2026-01-22T10:04:21",
    "categories": [
      "eess.SY",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15813",
    "title": "Beyond Off-the-Shelf Models: A Lightweight and Accessible Machine Learning Pipeline for Ecologists Working with Image Data",
    "authors": [
      "Clare Chemery",
      "Hendrik Edelhoff",
      "Ludwig Bothmann"
    ],
    "affiliations": [],
    "summary": "We introduce a lightweight experimentation pipeline designed to lower the barrier for applying machine learning (ML) methods for classifying images in ecological research. We enable ecologists to experiment with ML models independently, thus they can move beyond off-the-shelf models and generate insights tailored to local datasets and specific classification tasks and target variables. Our tool combines a simple command-line interface for preprocessing, training, and evaluation with a graphical interface for annotation, error analysis, and model comparison. This design enables ecologists to build and iterate on compact, task-specific classifiers without requiring advanced ML expertise. As a proof of concept, we apply the pipeline to classify red deer (Cervus elaphus) by age and sex from 3392 camera trap images collected in the Veldenstein Forest, Germany. Using 4352 cropped images containing individual deer labeled by experts, we trained and evaluated multiple backbone architectures with a wide variety of parameters and data augmentation strategies. Our best-performing models achieved 90.77% accuracy for age classification and 96.15% for sex classification. These results demonstrate that reliable demographic classification is feasible even with limited data to answer narrow, well-defined ecological problems. More broadly, the framework provides ecologists with an accessible tool for developing ML models tailored to specific research questions, paving the way for broader adoption of ML in wildlife monitoring and demographic analysis.",
    "link": "http://arxiv.org/abs/2601.15813v1",
    "published_date": "2026-01-22T10:01:01",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15812",
    "title": "ErrorMap and ErrorAtlas: Charting the Failure Landscape of Large Language Models",
    "authors": [
      "Shir Ashury-Tahan",
      "Yifan Mai",
      "Elron Bandel",
      "Michal Shmueli-Scheuer",
      "Leshem Choshen"
    ],
    "affiliations": [],
    "summary": "Large Language Models (LLM) benchmarks tell us when models fail, but not why they fail. A wrong answer on a reasoning dataset may stem from formatting issues, calculation errors, or dataset noise rather than weak reasoning. Without disentangling such causes, benchmarks remain incomplete and cannot reliably guide model improvement. We introduce ErrorMap, the first method to chart the sources of LLM failure. It extracts a model's unique \"failure signature\", clarifies what benchmarks measure, and broadens error identification to reduce blind spots. This helps developers debug models, aligns benchmark goals with outcomes, and supports informed model selection. ErrorMap works on any model or dataset with the same logic. Applying our method to 35 datasets and 83 models we generate ErrorAtlas, a taxonomy of model errors, revealing recurring failure patterns. ErrorAtlas highlights error types that are currently underexplored in LLM research, such as omissions of required details in the output and question misinterpretation. By shifting focus from where models succeed to why they fail, ErrorMap and ErrorAtlas enable advanced evaluation - one that exposes hidden weaknesses and directs progress. Unlike success, typically measured by task-level metrics, our approach introduces a deeper evaluation layer that can be applied globally across models and tasks, offering richer insights into model behavior and limitations. We make the taxonomy and code publicly available with plans to periodically update ErrorAtlas as new benchmarks and models emerge.",
    "link": "http://arxiv.org/abs/2601.15812v1",
    "published_date": "2026-01-22T09:52:39",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15810",
    "title": "A Mobile Application for Flower Recognition System Based on Convolutional Neural Networks",
    "authors": [
      "Mustafa Yurdakul",
      "Enes Ayan",
      "Fahrettin Horasan",
      "Sakir Tasdemir"
    ],
    "affiliations": [],
    "summary": "A convolutional neural network (CNN) is a deep learning algorithm that has been specifically designed for computer vision applications. The CNNs proved successful in handling the increasing amount of data in many computer vision problems, where classical machine learning algorithms were insufficient. Flowers have many uses in our daily lives, from decorating to making medicines to detoxifying the environment. Identifying flower types requires expert knowledge. However, accessing experts at any time and in any location may not always be feasible. In this study a mobile application based on CNNs was developed to recognize different types of flowers to provide non-specialists with quick and easy access to information about flower types. The study employed three distinct CNN models, namely MobileNet, DenseNet121, and Xception, to determine the most suitable model for the mobile application. The classification performances of the models were evaluated by training them with seven different optimization algorithms. The DenseNet-121 architecture, which uses the stochastic gradient descent (SGD) optimization algorithm, was the most successful, achieving 95.84 % accuracy, 96.00% precision, recall, and F1-score. This result shows that CNNs can be used for flower classification in mobile applications.",
    "link": "http://arxiv.org/abs/2601.15810v1",
    "published_date": "2026-01-22T09:52:04",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15808",
    "title": "Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification",
    "authors": [
      "Yuxuan Wan",
      "Tianqing Fang",
      "Zaitang Li",
      "Yintong Huo",
      "Wenxuan Wang",
      "Haitao Mi",
      "Dong Yu",
      "Michael R. Lyu"
    ],
    "affiliations": [],
    "summary": "Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.",
    "link": "http://arxiv.org/abs/2601.15808v1",
    "published_date": "2026-01-22T09:47:31",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15801",
    "title": "Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models",
    "authors": [
      "Fengheng Chu",
      "Jiahao Chen",
      "Yuhong Wang",
      "Jun Wang",
      "Zhihui Fu",
      "Shouling Ji",
      "Songze Li"
    ],
    "affiliations": [],
    "summary": "While Large Language Models (LLMs) are aligned to mitigate risks, their safety guardrails remain fragile against jailbreak attacks. This reveals limited understanding of components governing safety. Existing methods rely on local, greedy attribution that assumes independent component contributions. However, they overlook the cooperative interactions between different components in LLMs, such as attention heads, which jointly contribute to safety mechanisms. We propose \\textbf{G}lobal \\textbf{O}ptimization for \\textbf{S}afety \\textbf{V}ector Extraction (GOSV), a framework that identifies safety-critical attention heads through global optimization over all heads simultaneously. We employ two complementary activation repatching strategies: Harmful Patching and Zero Ablation. These strategies identify two spatially distinct sets of safety vectors with consistently low overlap, termed Malicious Injection Vectors and Safety Suppression Vectors, demonstrating that aligned LLMs maintain separate functional pathways for safety purposes. Through systematic analyses, we find that complete safety breakdown occurs when approximately 30\\% of total heads are repatched across all models. Building on these insights, we develop a novel inference-time white-box jailbreak method that exploits the identified safety vectors through activation repatching. Our attack substantially outperforms existing white-box attacks across all test models, providing strong evidence for the effectiveness of the proposed GOSV framework on LLM safety interpretability.",
    "link": "http://arxiv.org/abs/2601.15801v1",
    "published_date": "2026-01-22T09:32:43",
    "categories": [
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15798",
    "title": "VitalDiagnosis: AI-Driven Ecosystem for 24/7 Vital Monitoring and Chronic Disease Management",
    "authors": [
      "Zhikai Xue",
      "Tianqianjin Lin",
      "Pengwei Yan",
      "Ruichun Wang",
      "Yuxin Liu",
      "Zhuoren Jiang",
      "Xiaozhong Liu"
    ],
    "affiliations": [],
    "summary": "Chronic diseases have become the leading cause of death worldwide, a challenge intensified by strained medical resources and an aging population. Individually, patients often struggle to interpret early signs of deterioration or maintain adherence to care plans. In this paper, we introduce VitalDiagnosis, an LLM-driven ecosystem designed to shift chronic disease management from passive monitoring to proactive, interactive engagement. By integrating continuous data from wearable devices with the reasoning capabilities of LLMs, the system addresses both acute health anomalies and routine adherence. It analyzes triggers through context-aware inquiries, produces provisional insights within a collaborative patient-clinician workflow, and offers personalized guidance. This approach aims to promote a more proactive and cooperative care paradigm, with the potential to enhance patient self-management and reduce avoidable clinical workload.",
    "link": "http://arxiv.org/abs/2601.15798v1",
    "published_date": "2026-01-22T09:31:19",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15797",
    "title": "Creativity in the Age of AI: Rethinking the Role of Intentional Agency",
    "authors": [
      "James S. Pearson",
      "Matthew J. Dennis",
      "Marc Cheong"
    ],
    "affiliations": [],
    "summary": "Many theorists of creativity maintain that intentional agency is a necessary condition of creativity. We argue that this requirement, which we call the Intentional Agency Condition (IAC), should be rejected as a general condition of creativity, while retaining its relevance in specific contexts. We show that recent advances in generative AI have rendered the IAC increasingly problematic, both descriptively and functionally. We offer two reasons for abandoning it at the general level. First, we present corpus evidence indicating that authors and journalists are increasingly comfortable ascribing creativity to generative AI, despite its lack of intentional agency. This development places pressure on the linguistic intuitions that have traditionally been taken to support the IAC. Second, drawing on the method of conceptual engineering, we argue that the IAC no longer fulfils its core social function. Rather than facilitating the identification and encouragement of reliable sources of novel and valuable products, it now feeds into biases that distort our assessments of AI-generated outputs. We therefore propose replacing the IAC with a consistency requirement, according to which creativity tracks the reliable generation of novel and valuable products. Nonetheless, we explain why the IAC should be retained in specific local domains.",
    "link": "http://arxiv.org/abs/2601.15797v1",
    "published_date": "2026-01-22T09:31:12",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15793",
    "title": "HumanLLM: Towards Personalized Understanding and Simulation of Human Nature",
    "authors": [
      "Yuxuan Lei",
      "Tianfu Wang",
      "Jianxun Lian",
      "Zhengyu Hu",
      "Defu Lian",
      "Xing Xie"
    ],
    "affiliations": [],
    "summary": "Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior--a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual's decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.",
    "link": "http://arxiv.org/abs/2601.15793v1",
    "published_date": "2026-01-22T09:27:27",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15779",
    "title": "Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation",
    "authors": [
      "Liuyun Jiang",
      "Yanchao Zhang",
      "Jinyue Guo",
      "Yizhuo Lu",
      "Ruining Zhou",
      "Hua Han"
    ],
    "affiliations": [],
    "summary": "Neuron segmentation in electron microscopy (EM) aims to reconstruct the complete neuronal connectome; however, current deep learning-based methods are limited by their reliance on large-scale training data and extensive, time-consuming manual annotations. Traditional methods augment the training set through geometric and photometric transformations; however, the generated samples remain highly correlated with the original images and lack structural diversity. To address this limitation, we propose a diffusion-based data augmentation framework capable of generating diverse and structurally plausible image-label pairs for neuron segmentation. Specifically, the framework employs a resolution-aware conditional diffusion model with multi-scale conditioning and EM resolution priors to enable voxel-level image synthesis from 3D masks. It further incorporates a biology-guided mask remodeling module that produces augmented masks with enhanced structural realism. Together, these components effectively enrich the training set and improve segmentation performance. On the AC3 and AC4 datasets under low-annotation regimes, our method improves the ARAND metric by 32.1% and 30.7%, respectively, when combined with two different post-processing methods. Our code is available at https://github.com/HeadLiuYun/NeuroDiff.",
    "link": "http://arxiv.org/abs/2601.15779v1",
    "published_date": "2026-01-22T09:12:05",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15778",
    "title": "Agentic Confidence Calibration",
    "authors": [
      "Jiaxin Zhang",
      "Caiming Xiong",
      "Chien-Sheng Wu"
    ],
    "affiliations": [],
    "summary": "AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents.",
    "link": "http://arxiv.org/abs/2601.15778v1",
    "published_date": "2026-01-22T09:08:25",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15773",
    "title": "Next Generation Active Learning: Mixture of LLMs in the Loop",
    "authors": [
      "Yuanyuan Qi",
      "Xiaohao Yang",
      "Jueqing Lu",
      "Guoxiang Guo",
      "Joanne Enticott",
      "Gang Liu",
      "Lan Du"
    ],
    "affiliations": [],
    "summary": "With the rapid advancement and strong generalization capabilities of large language models (LLMs), they have been increasingly incorporated into the active learning pipelines as annotators to reduce annotation costs. However, considering the annotation quality, labels generated by LLMs often fall short of real-world applicability. To address this, we propose a novel active learning framework, Mixture of LLMs in the Loop Active Learning, replacing human annotators with labels generated through a Mixture-of-LLMs-based annotation model, aimed at enhancing LLM-based annotation robustness by aggregating the strengths of multiple LLMs. To further mitigate the impact of the noisy labels, we introduce annotation discrepancy and negative learning to identify the unreliable annotations and enhance learning effectiveness. Extensive experiments demonstrate that our framework achieves performance comparable to human annotation and consistently outperforms single-LLM baselines and other LLM-ensemble-based approaches. Moreover, our framework is built on lightweight LLMs, enabling it to operate fully on local machines in real-world applications.",
    "link": "http://arxiv.org/abs/2601.15773v1",
    "published_date": "2026-01-22T09:01:42",
    "categories": [
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15761",
    "title": "Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning",
    "authors": [
      "Xiefeng Wu",
      "Mingyu Hu",
      "Shu Zhang"
    ],
    "affiliations": [],
    "summary": "Deploying reinforcement learning in the real world remains challenging due to sample inefficiency, sparse rewards, and noisy visual observations. Prior work leverages demonstrations and human feedback to improve learning efficiency and robustness. However, offline-to-online methods need large datasets and can be unstable, while VLA-assisted RL relies on large-scale pretraining and fine-tuning. As a result, a low-cost real-world RL method with minimal data requirements has yet to emerge. We introduce \\textbf{SigEnt-SAC}, an off-policy actor-critic method that learns from scratch using a single expert trajectory. Our key design is a sigmoid-bounded entropy term that prevents negative-entropy-driven optimization toward out-of-distribution actions and reduces Q-function oscillations. We benchmark SigEnt-SAC on D4RL tasks against representative baselines. Experiments show that SigEnt-SAC substantially alleviates Q-function oscillations and reaches a 100\\% success rate faster than prior methods. Finally, we validate SigEnt-SAC on four real-world robotic tasks across multiple embodiments, where agents learn from raw images and sparse rewards; results demonstrate that SigEnt-SAC can learn successful policies with only a small number of real-world interactions, suggesting a low-cost and practical pathway for real-world RL deployment.",
    "link": "http://arxiv.org/abs/2601.15761v1",
    "published_date": "2026-01-22T08:51:16",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15759",
    "title": "Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)",
    "authors": [
      "Qi Zeng",
      "Weide Liu",
      "Bo Li",
      "Ryne Didier",
      "P. Ellen Grant",
      "Davood Karimi"
    ],
    "affiliations": [],
    "summary": "This paper presents FeTal-SAM, a novel adaptation of the Segment Anything Model (SAM) tailored for fetal brain MRI segmentation. Traditional deep learning methods often require large annotated datasets for a fixed set of labels, making them inflexible when clinical or research needs change. By integrating atlas-based prompts and foundation-model principles, FeTal-SAM addresses two key limitations in fetal brain MRI segmentation: (1) the need to retrain models for varying label definitions, and (2) the lack of insight into whether segmentations are driven by genuine image contrast or by learned spatial priors. We leverage multi-atlas registration to generate spatially aligned label templates that serve as dense prompts, alongside a bounding-box prompt, for SAM's segmentation decoder. This strategy enables binary segmentation on a per-structure basis, which is subsequently fused to reconstruct the full 3D segmentation volumes. Evaluations on two datasets, the dHCP dataset and an in-house dataset demonstrate FeTal-SAM's robust performance across gestational ages. Notably, it achieves Dice scores comparable to state-of-the-art baselines which were trained for each dataset and label definition for well-contrasted structures like cortical plate and cerebellum, while maintaining the flexibility to segment any user-specified anatomy. Although slightly lower accuracy is observed for subtle, low-contrast structures (e.g., hippocampus, amygdala), our results highlight FeTal-SAM's potential to serve as a general-purpose segmentation model without exhaustive retraining. This method thus constitutes a promising step toward clinically adaptable fetal brain MRI analysis tools.",
    "link": "http://arxiv.org/abs/2601.15759v1",
    "published_date": "2026-01-22T08:49:33",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15757",
    "title": "White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification",
    "authors": [
      "Yimin Zhu",
      "Lincoln Linlin Xu",
      "Zhengsen Xu",
      "Zack Dewis",
      "Mabel Heffring",
      "Saeid Taleghanidoozdoozan",
      "Motasem Alkayid",
      "Quinn Ledingham",
      "Megan Greenwood"
    ],
    "affiliations": [],
    "summary": "In hyperspectral image classification (HSIC), most deep learning models rely on opaque spectral-spatial feature mixing, limiting their interpretability and hindering understanding of internal decision mechanisms. We present physical spectrum-aware white-box mHC, named ES-mHC, a hyper-connection framework that explicitly models interactions among different electromagnetic spectrum groupings (residual stream in mHC) interactions using structured, directional matrices. By separating feature representation from interaction structure, ES-mHC promotes electromagnetic spectrum grouping specialization, reduces redundancy, and exposes internal information flow that can be directly visualized and spatially analyzed. Using hyperspectral image classification as a representative testbed, we demonstrate that the learned hyper-connection matrices exhibit coherent spatial patterns and asymmetric interaction behaviors, providing mechanistic insight into the model internal dynamics. Furthermore, we find that increasing the expansion rate accelerates the emergence of structured interaction patterns. These results suggest that ES-mHC transforms HSIC from a purely black-box prediction task into a structurally transparent, partially white-box learning process.",
    "link": "http://arxiv.org/abs/2601.15757v1",
    "published_date": "2026-01-22T08:48:01",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15755",
    "title": "Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs",
    "authors": [
      "Tristan Williams",
      "Franziska Weeber",
      "Sebastian Padó",
      "Alan Akbik"
    ],
    "affiliations": [],
    "summary": "Large language models are increasingly used to represent human opinions, values, or beliefs, and their steerability towards these ideals is an active area of research. Existing work focuses predominantly on aligning marginal response distributions, treating each survey item independently. While essential, this may overlook deeper latent structures that characterise real populations and underpin cultural values theories. We propose a framework for evaluating the representativeness of aligned models through multivariate correlation patterns in addition to marginal distributions. We show the value of our evaluation scheme by comparing two model steering techniques (persona prompting and demographic fine-tuning) and evaluating them against human responses from the World Values Survey. While the demographically fine-tuned model better approximates marginal response distributions than persona prompting, both techniques fail to fully capture the gold standard correlation patterns. We conclude that representativeness is a distinct aspect of value alignment and an evaluation focused on marginals can mask structural failures, leading to overly optimistic conclusions about model capabilities.",
    "link": "http://arxiv.org/abs/2601.15755v1",
    "published_date": "2026-01-22T08:45:55",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15754",
    "title": "CAFE-GB: Scalable and Stable Feature Selection for Malware Detection via Chunk-wise Aggregated Gradient Boosting",
    "authors": [
      "Ajvad Haneef K",
      "Karan Kuwar Singh",
      "Madhu Kumar S D"
    ],
    "affiliations": [],
    "summary": "High-dimensional malware datasets often exhibit feature redundancy, instability, and scalability limitations, which hinder the effectiveness and interpretability of machine learning-based malware detection systems. Although feature selection is commonly employed to mitigate these issues, many existing approaches lack robustness when applied to large-scale and heterogeneous malware data. To address this gap, this paper proposes CAFE-GB (Chunk-wise Aggregated Feature Estimation using Gradient Boosting), a scalable feature selection framework designed to produce stable and globally consistent feature rankings for high-dimensional malware detection. CAFE-GB partitions training data into overlapping chunks, estimates local feature importance using gradient boosting models, and aggregates these estimates to derive a robust global ranking. Feature budget selection is performed separately through a systematic k-selection and stability analysis to balance detection performance and robustness. The proposed framework is evaluated on two large-scale malware datasets: BODMAS and CIC-AndMal2020, representing large and diverse malware feature spaces. Experimental results show that classifiers trained on CAFE-GB -selected features achieve performance parity with full-feature baselines across multiple metrics, including Accuracy, F1-score, MCC, ROC-AUC, and PR-AUC, while reducing feature dimensionality by more than 95\\%. Paired Wilcoxon signed-rank tests confirm that this reduction does not introduce statistically significant performance degradation. Additional analyses demonstrate low inter-feature redundancy and improved interpretability through SHAP-based explanations. Runtime and memory profiling further indicate reduced downstream classification overhead. Overall, CAFE-GB provides a stable, interpretable, and scalable feature selection strategy for large-scale malware detection.",
    "link": "http://arxiv.org/abs/2601.15754v1",
    "published_date": "2026-01-22T08:43:15",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15751",
    "title": "Tabular Incremental Inference",
    "authors": [
      "Xinda Chen",
      "Xing Zhen",
      "Hanyu Zhang",
      "Weimin Tan",
      "Bo Yan"
    ],
    "affiliations": [],
    "summary": "Tabular data is a fundamental form of data structure. The evolution of table analysis tools reflects humanity's continuous progress in data acquisition, management, and processing. The dynamic changes in table columns arise from technological advancements, changing needs, data integration, etc. However, the standard process of training AI models on tables with fixed columns and then performing inference is not suitable for handling dynamically changed tables. Therefore, new methods are needed for efficiently handling such tables in an unsupervised manner. In this paper, we introduce a new task, Tabular Incremental Inference (TabII), which aims to enable trained models to incorporate new columns during the inference stage, enhancing the practicality of AI models in scenarios where tables are dynamically changed. Furthermore, we demonstrate that this new task can be framed as an optimization problem based on the information bottleneck theory, which emphasizes that the key to an ideal tabular incremental inference approach lies in minimizing mutual information between tabular data and representation while maximizing between representation and task labels. Under this guidance, we design a TabII method with Large Language Model placeholders and Pretrained TabAdapter to provide external knowledge and Incremental Sample Condensation blocks to condense the task-relevant information given by incremental column attributes. Experimental results across eight public datasets show that TabII effectively utilizes incremental attributes, achieving state-of-the-art performance.",
    "link": "http://arxiv.org/abs/2601.15751v1",
    "published_date": "2026-01-22T08:24:31",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15737",
    "title": "PhysProver: Advancing Automatic Theorem Proving for Physics",
    "authors": [
      "Hanning Zhang",
      "Ruida Wang",
      "Rui Pan",
      "Wenyuan Wang",
      "Bingxu Meng",
      "Tong Zhang"
    ],
    "affiliations": [],
    "summary": "The combination of verifiable languages and LLMs has significantly influenced both the mathematical and computer science communities because it provides a rigorous foundation for theorem proving. Recent advancements in the field provide foundation models and sophisticated agentic systems pushing the boundaries of formal mathematical reasoning to approach the natural language capability of LLMs. However, little attention has been given to the formal physics reasoning, which also heavily relies on similar problem-solving and theorem-proving frameworks. To solve this problem, this paper presents, to the best of our knowledge, the first approach to enhance formal theorem proving in the physics domain. We compose a dedicated dataset PhysLeanData for the task. It is composed of theorems sampled from PhysLean and data generated by a conjecture-based formal data generation pipeline. In the training pipeline, we leverage DeepSeek-Prover-V2-7B, a strong open-source mathematical theorem prover, and apply Reinforcement Learning with Verifiable Rewards (RLVR) to train our model PhysProver. Comprehensive experiments demonstrate that, using only $\\sim$5K training samples, PhysProver achieves an overall 2.4\\% improvement in multiple sub-domains. Furthermore, after formal physics training, we observe 1.3\\% gains on the MiniF2F-Test benchmark, which indicates non-trivial generalization beyond physics domains and enhancement for formal math capability as well. The results highlight the effectiveness and efficiency of our approach, which provides a paradigm for extending formal provers outside mathematical domains. To foster further research, we will release both our dataset and model to the community.",
    "link": "http://arxiv.org/abs/2601.15737v1",
    "published_date": "2026-01-22T08:05:32",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15734",
    "title": "Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation",
    "authors": [
      "Shadi Alijani",
      "Fereshteh Aghaee Meibodi",
      "Homayoun Najjaran"
    ],
    "affiliations": [],
    "summary": "The successful adaptation of foundation models to multi-modal medical imaging is a critical yet unresolved challenge. Existing models often struggle to effectively fuse information from multiple sources and adapt to the heterogeneous nature of pathological tissues. To address this, we introduce a novel framework for adapting foundation models to multi-modal medical imaging, featuring two key technical innovations: sub-region-aware modality attention and adaptive prompt engineering. The attention mechanism enables the model to learn the optimal combination of modalities for each tumor sub-region, while the adaptive prompting strategy leverages the inherent capabilities of foundation models to refine segmentation accuracy. We validate our framework on the BraTS 2020 brain tumor segmentation dataset, demonstrating that our approach significantly outperforms baseline methods, particularly in the challenging necrotic core sub-region. Our work provides a principled and effective approach to multi-modal fusion and prompting, paving the way for more accurate and robust foundation model-based solutions in medical imaging.",
    "link": "http://arxiv.org/abs/2601.15734v1",
    "published_date": "2026-01-22T08:03:17",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15731",
    "title": "FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging",
    "authors": [
      "Linyong Zou",
      "Liang Zhang",
      "Xiongfei Wang",
      "Jia-Hong Gao",
      "Yi Sun",
      "Shurong Sheng",
      "Kuntao Xiao",
      "Wanli Yang",
      "Pengfei Teng",
      "Guoming Luan",
      "Zhao Lv",
      "Zikang Xu"
    ],
    "affiliations": [],
    "summary": "An essential technique for diagnosing brain disorders is electrophysiological source imaging (ESI). While model-based optimization and deep learning methods have achieved promising results in this field, the accurate selection and refinement of features remains a central challenge for precise ESI. This paper proposes FAIR-ESI, a novel framework that adaptively refines feature importance across different views, including FFT-based spectral feature refinement, weighted temporal feature refinement, and self-attention-based patch-wise feature refinement. Extensive experiments on two simulation datasets with diverse configurations and two real-world clinical datasets validate our framework's efficacy, highlighting its potential to advance brain disorder diagnosis and offer new insights into brain function.",
    "link": "http://arxiv.org/abs/2601.15731v1",
    "published_date": "2026-01-22T07:57:27",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15729",
    "title": "DualShield: Safe Model Predictive Diffusion via Reachability Analysis for Interactive Autonomous Driving",
    "authors": [
      "Rui Yang",
      "Lei Zheng",
      "Ruoyu Yao",
      "Jun Ma"
    ],
    "affiliations": [],
    "summary": "Diffusion models have emerged as a powerful approach for multimodal motion planning in autonomous driving. However, their practical deployment is typically hindered by the inherent difficulty in enforcing vehicle dynamics and a critical reliance on accurate predictions of other agents, making them prone to safety issues under uncertain interactions. To address these limitations, we introduce DualShield, a planning and control framework that leverages Hamilton-Jacobi (HJ) reachability value functions in a dual capacity. First, the value functions act as proactive guidance, steering the diffusion denoising process towards safe and dynamically feasible regions. Second, they form a reactive safety shield using control barrier-value functions (CBVFs) to modify the executed actions and ensure safety. This dual mechanism preserves the rich exploration capabilities of diffusion models while providing principled safety assurance under uncertain and even adversarial interactions. Simulations in challenging unprotected U-turn scenarios demonstrate that DualShield significantly improves both safety and task efficiency compared to leading methods from different planning paradigms under uncertainty.",
    "link": "http://arxiv.org/abs/2601.15729v1",
    "published_date": "2026-01-22T07:56:36",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15727",
    "title": "Towards Automated Kernel Generation in the Era of LLMs",
    "authors": [
      "Yang Yu",
      "Peiyu Zang",
      "Chi Hsu Tsai",
      "Haiming Wu",
      "Yixin Shen",
      "Jialing Zhang",
      "Haoyu Wang",
      "Zhiyou Xiao",
      "Jingze Shi",
      "Yuyu Luo",
      "Wentao Zhang",
      "Chunlei Men",
      "Guang Liu",
      "Yonghua Lin"
    ],
    "affiliations": [],
    "summary": "The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.",
    "link": "http://arxiv.org/abs/2601.15727v1",
    "published_date": "2026-01-22T07:53:52",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15724",
    "title": "VideoThinker: Building Agentic VideoLLMs with LLM-Guided Tool Reasoning",
    "authors": [
      "Chenglin Li",
      "Qianglong Chen",
      "Feng Han",
      "Yikun Wang",
      "Xingxi Yin",
      "Yan Gong",
      "Ruilin Li",
      "Yin Zhang",
      "Jiaqi Wang"
    ],
    "affiliations": [],
    "summary": "Long-form video understanding remains a fundamental challenge for current Video Large Language Models. Most existing models rely on static reasoning over uniformly sampled frames, which weakens temporal localization and leads to substantial information loss in long videos. Agentic tools such as temporal retrieval, spatial zoom, and temporal zoom offer a natural way to overcome these limitations by enabling adaptive exploration of key moments. However, constructing agentic video understanding data requires models that already possess strong long-form video comprehension, creating a circular dependency. We address this challenge with VideoThinker, an agentic Video Large Language Model trained entirely on synthetic tool interaction trajectories. Our key idea is to convert videos into rich captions and employ a powerful agentic language model to generate multi-step tool use sequences in caption space. These trajectories are subsequently grounded back to video by replacing captions with the corresponding frames, yielding a large-scale interleaved video and tool reasoning dataset without requiring any long-form understanding from the underlying model. Training on this synthetic agentic dataset equips VideoThinker with dynamic reasoning capabilities, adaptive temporal exploration, and multi-step tool use. Remarkably, VideoThinker significantly outperforms both caption-only language model agents and strong video model baselines across long-video benchmarks, demonstrating the effectiveness of tool augmented synthetic data and adaptive retrieval and zoom reasoning for long-form video understanding.",
    "link": "http://arxiv.org/abs/2601.15724v1",
    "published_date": "2026-01-22T07:47:29",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15722",
    "title": "Communication-efficient Federated Graph Classification via Generative Diffusion Modeling",
    "authors": [
      "Xiuling Wang",
      "Xin Huang",
      "Haibo Hu",
      "Jianliang Xu"
    ],
    "affiliations": [],
    "summary": "Graph Neural Networks (GNNs) unlock new ways of learning from graph-structured data, proving highly effective in capturing complex relationships and patterns. Federated GNNs (FGNNs) have emerged as a prominent distributed learning paradigm for training GNNs over decentralized data. However, FGNNs face two significant challenges: high communication overhead from multiple rounds of parameter exchanges and non-IID data characteristics across clients. To address these issues, we introduce CeFGC, a novel FGNN paradigm that facilitates efficient GNN training over non-IID data by limiting communication between the server and clients to three rounds only. The core idea of CeFGC is to leverage generative diffusion models to minimize direct client-server communication. Each client trains a generative diffusion model that captures its local graph distribution and shares this model with the server, which then redistributes it back to all clients. Using these generative models, clients generate synthetic graphs combined with their local graphs to train local GNN models. Finally, clients upload their model weights to the server for aggregation into a global GNN model. We theoretically analyze the I/O complexity of communication volume to show that CeFGC reduces to a constant of three communication rounds only. Extensive experiments on several real graph datasets demonstrate the effectiveness and efficiency of CeFGC against state-of-the-art competitors, reflecting our superior performance on non-IID graphs by aligning local and global model objectives and enriching the training set with diverse graphs.",
    "link": "http://arxiv.org/abs/2601.15722v1",
    "published_date": "2026-01-22T07:46:47",
    "categories": [
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15721",
    "title": "CoNRec: Context-Discerning Negative Recommendation with LLMs",
    "authors": [
      "Xinda Chen",
      "Jiawei Wu",
      "Yishuang Liu",
      "Jialin Zhu",
      "Shuwen Xiao",
      "Junjun Zheng",
      "Xiangheng Kong",
      "Yuning Jiang"
    ],
    "affiliations": [],
    "summary": "Understanding what users like is relatively straightforward; understanding what users dislike, however, remains a challenging and underexplored problem. Research into users' negative preferences has gained increasing importance in modern recommendation systems. Numerous platforms have introduced explicit negative feedback mechanisms and leverage such signals to refine their recommendation models. Beyond traditional business metrics, user experience-driven metrics, such as negative feedback rates, have become critical indicators for evaluating system performance. However, most existing approaches primarily use negative feedback as an auxiliary signal to enhance positive recommendations, paying little attention to directly modeling negative interests, which can be highly valuable in offline applications. Moreover, due to the inherent sparsity of negative feedback data, models often suffer from context understanding biases induced by positive feedback dominance. To address these challenges, we propose the first large language model framework for negative feedback modeling with special designed context-discerning modules. We use semantic ID Representation to replace text-based item descriptions and introduce an item-level alignment task that enhances the LLM's understanding of the semantic context behind negative feedback. Furthermore, we design a Progressive GRPO training paradigm that enables the model to dynamically balance the positive and negative behavioral context utilization. Besides, our investigation further reveals a fundamental misalignment between the conventional next-negative-item prediction objective and users' true negative preferences, which is heavily influenced by the system's recommendation order. To mitigate this, we propose a novel reward function and evaluation metric grounded in multi-day future negative feedback and their collaborative signals.",
    "link": "http://arxiv.org/abs/2601.15721v1",
    "published_date": "2026-01-22T07:46:18",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15716",
    "title": "zkFinGPT: Zero-Knowledge Proofs for Financial Generative Pre-trained Transformers",
    "authors": [
      "Xiao-Yang Liu",
      "Ningjie Li",
      "Keyi Wang",
      "Xiaoli Zhi",
      "Weiqin Tong"
    ],
    "affiliations": [],
    "summary": "Financial Generative Pre-trained Transformers (FinGPT) with multimodal capabilities are now being increasingly adopted in various financial applications. However, due to the intellectual property of model weights and the copyright of training corpus and benchmarking questions, verifying the legitimacy of GPT's model weights and the credibility of model outputs is a pressing challenge. In this paper, we introduce a novel zkFinGPT scheme that applies zero-knowledge proofs (ZKPs) to high-value financial use cases, enabling verification while protecting data privacy. We describe how zkFinGPT will be applied to three financial use cases. Our experiments on two existing packages reveal that zkFinGPT introduces substantial computational overhead that hinders its real-world adoption. E.g., for LLama3-8B model, it generates a commitment file of $7.97$MB using $531$ seconds, and takes $620$ seconds to prove and $2.36$ seconds to verify.",
    "link": "http://arxiv.org/abs/2601.15716v1",
    "published_date": "2026-01-22T07:37:33",
    "categories": [
      "cs.CE",
      "cs.CR"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15715",
    "title": "Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind",
    "authors": [
      "Zhitao He",
      "Zongwei Lyu",
      "Yi R Fung"
    ],
    "affiliations": [],
    "summary": "Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.",
    "link": "http://arxiv.org/abs/2601.15715v1",
    "published_date": "2026-01-22T07:36:48",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15714",
    "title": "Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs",
    "authors": [
      "Ryoma Sato"
    ],
    "affiliations": [],
    "summary": "We propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.",
    "link": "http://arxiv.org/abs/2601.15714v1",
    "published_date": "2026-01-22T07:36:01",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15710",
    "title": "FlexLLM: Composable HLS Library for Flexible Hybrid LLM Accelerator Design",
    "authors": [
      "Jiahao Zhang",
      "Zifan He",
      "Nicholas Fraser",
      "Michaela Blott",
      "Yizhou Sun",
      "Jason Cong"
    ],
    "affiliations": [],
    "summary": "We present FlexLLM, a composable High-Level Synthesis (HLS) library for rapid development of domain-specific LLM accelerators. FlexLLM exposes key architectural degrees of freedom for stage-customized inference, enabling hybrid designs that tailor temporal reuse and spatial dataflow differently for prefill and decode, and provides a comprehensive quantization suite to support accurate low-bit deployment. Using FlexLLM, we build a complete inference system for the Llama-3.2 1B model in under two months with only 1K lines of code. The system includes: (1) a stage-customized accelerator with hardware-efficient quantization (12.68 WikiText-2 PPL) surpassing SpinQuant baseline, and (2) a Hierarchical Memory Transformer (HMT) plug-in for efficient long-context processing. On the AMD U280 FPGA at 16nm, the accelerator achieves 1.29$\\times$ end-to-end speedup, 1.64$\\times$ higher decode throughput, and 3.14$\\times$ better energy efficiency than an NVIDIA A100 GPU (7nm) running BF16 inference; projected results on the V80 FPGA at 7nm reach 4.71$\\times$, 6.55$\\times$, and 4.13$\\times$, respectively. In long-context scenarios, integrating the HMT plug-in reduces prefill latency by 23.23$\\times$ and extends the context window by 64$\\times$, delivering 1.10$\\times$/4.86$\\times$ lower end-to-end latency and 5.21$\\times$/6.27$\\times$ higher energy efficiency on the U280/V80 compared to the A100 baseline. FlexLLM thus bridges algorithmic innovation in LLM inference and high-performance accelerators with minimal manual effort.",
    "link": "http://arxiv.org/abs/2601.15710v1",
    "published_date": "2026-01-22T07:31:51",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15709",
    "title": "AgentSM: Semantic Memory for Agentic Text-to-SQL",
    "authors": [
      "Asim Biswal",
      "Chuan Lei",
      "Xiao Qin",
      "Aodong Li",
      "Balakrishnan Narayanaswamy",
      "Tim Kraska"
    ],
    "affiliations": [],
    "summary": "Recent advances in LLM-based Text-to-SQL have achieved remarkable gains on public benchmarks such as BIRD and Spider. Yet, these systems struggle to scale in realistic enterprise settings with large, complex schemas, diverse SQL dialects, and expensive multi-step reasoning. Emerging agentic approaches show potential for adaptive reasoning but often suffer from inefficiency and instability-repeating interactions with databases, producing inconsistent outputs, and occasionally failing to generate valid answers. To address these challenges, we introduce Agent Semantic Memory (AgentSM), an agentic framework for Text-to-SQL that builds and leverages interpretable semantic memory. Instead of relying on raw scratchpads or vector retrieval, AgentSM captures prior execution traces-or synthesizes curated ones-as structured programs that directly guide future reasoning. This design enables systematic reuse of reasoning paths, which allows agents to scale to larger schemas, more complex questions, and longer trajectories efficiently and reliably. Compared to state-of-the-art systems, AgentSM achieves higher efficiency by reducing average token usage and trajectory length by 25% and 35%, respectively, on the Spider 2.0 benchmark. It also improves execution accuracy, reaching a state-of-the-art accuracy of 44.8% on the Spider 2.0 Lite benchmark.",
    "link": "http://arxiv.org/abs/2601.15709v1",
    "published_date": "2026-01-22T07:31:19",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15708",
    "title": "Persona Switch: Mixing Distinct Perspectives in Decoding Time",
    "authors": [
      "Junseok Kim",
      "Nakyeong Yang",
      "Kyomin Jung"
    ],
    "affiliations": [],
    "summary": "Role-play prompting is known to steer the behavior of language models by injecting a persona into the prompt, improving their zero-shot reasoning capabilities. However, such improvements are inconsistent across different tasks or instances. This inconsistency suggests that zero-shot and role-play prompting may offer complementary strengths rather than one being universally superior. Building on this insight, we propose Persona Switch, a novel decoding method that dynamically combines the benefits of both prompting strategies. Our method proceeds step-by-step, selecting the better output between zero-shot and role-play prompting at each step by comparing their output confidence, as measured by the logit gap. Experiments with widely-used LLMs demonstrate that Persona Switch consistently outperforms competitive baselines, achieving up to 5.13% accuracy improvement. Furthermore, we show that output confidence serves as an informative measure for selecting the more reliable output.",
    "link": "http://arxiv.org/abs/2601.15708v1",
    "published_date": "2026-01-22T07:30:27",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15706",
    "title": "Improving Methodologies for LLM Evaluations Across Global Languages",
    "authors": [
      "Akriti Vij",
      "Benjamin Chua",
      "Darshini Ramiah",
      "En Qi Ng",
      "Mahran Morsidi",
      "Naga Nikshith Gangarapu",
      "Sharmini Johnson",
      "Vanessa Wilfred",
      "Vikneswaran Kumaran",
      "Wan Sie Lee",
      "Wenzhuo Yang",
      "Yongsen Zheng",
      "Bill Black",
      "Boming Xia",
      "Frank Sun",
      "Hao Zhang",
      "Qinghua Lu",
      "Suyu Ma",
      "Yue Liu",
      "Chi-kiu Lo",
      "Fatemeh Azadi",
      "Isar Nejadgholi",
      "Sowmya Vajjala",
      "Agnes Delaborde",
      "Nicolas Rolin",
      "Tom Seimandi",
      "Akiko Murakami",
      "Haruto Ishi",
      "Satoshi Sekine",
      "Takayuki Semitsu",
      "Tasuku Sasaki",
      "Angela Kinuthia",
      "Jean Wangari",
      "Michael Michie",
      "Stephanie Kasaon",
      "Hankyul Baek",
      "Jaewon Noh",
      "Kihyuk Nam",
      "Sang Seo",
      "Sungpil Shin",
      "Taewhi Lee",
      "Yongsu Kim",
      "Daisy Newbold-Harrop",
      "Jessica Wang",
      "Mahmoud Ghanem",
      "Vy Hong"
    ],
    "affiliations": [],
    "summary": "As frontier AI models are deployed globally, it is essential that their behaviour remains safe and reliable across diverse linguistic and cultural contexts. To examine how current model safeguards hold up in such settings, participants from the International Network for Advanced AI Measurement, Evaluation and Science, including representatives from Singapore, Japan, Australia, Canada, the EU, France, Kenya, South Korea and the UK conducted a joint multilingual evaluation exercise. Led by Singapore AISI, two open-weight models were tested across ten languages spanning high and low resourced groups: Cantonese English, Farsi, French, Japanese, Korean, Kiswahili, Malay, Mandarin Chinese and Telugu. Over 6,000 newly translated prompts were evaluated across five harm categories (privacy, non-violent crime, violent crime, intellectual property and jailbreak robustness), using both LLM-as-a-judge and human annotation.\n  The exercise shows how safety behaviours can vary across languages. These include differences in safeguard robustness across languages and harm types and variation in evaluator reliability (LLM-as-judge vs. human review). Further, it also generated methodological insights for improving multilingual safety evaluations, such as the need for culturally contextualised translations, stress-tested evaluator prompts and clearer human annotation guidelines. This work represents an initial step toward a shared framework for multilingual safety testing of advanced AI systems and calls for continued collaboration with the wider research community and industry.",
    "link": "http://arxiv.org/abs/2601.15706v1",
    "published_date": "2026-01-22T07:18:08",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15698",
    "title": "Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs",
    "authors": [
      "Mingyu Yu",
      "Lana Liu",
      "Zhehao Zhao",
      "Wei Wang",
      "Sujuan Qin"
    ],
    "affiliations": [],
    "summary": "The rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a \"reconstruction-then-generation\" strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21\\% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs.",
    "link": "http://arxiv.org/abs/2601.15698v1",
    "published_date": "2026-01-22T06:56:27",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15690",
    "title": "From Passive Metric to Active Signal: The Evolving Role of Uncertainty Quantification in Large Language Models",
    "authors": [
      "Jiaxin Zhang",
      "Wendi Cui",
      "Zhuohang Li",
      "Lifu Huang",
      "Bradley Malin",
      "Caiming Xiong",
      "Chien-Sheng Wu"
    ],
    "affiliations": [],
    "summary": "While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of uncertainty from a passive diagnostic metric to an active control signal guiding real-time model behavior. We demonstrate how uncertainty is leveraged as an active control signal across three frontiers: in \\textbf{advanced reasoning} to optimize computation and trigger self-correction; in \\textbf{autonomous agents} to govern metacognitive decisions about tool use and information seeking; and in \\textbf{reinforcement learning} to mitigate reward hacking and enable self-improvement via intrinsic rewards. By grounding these advancements in emerging theoretical frameworks like Bayesian methods and Conformal Prediction, we provide a unified perspective on this transformative trend. This survey provides a comprehensive overview, critical analysis, and practical design patterns, arguing that mastering the new trend of uncertainty is essential for building the next generation of scalable, reliable, and trustworthy AI.",
    "link": "http://arxiv.org/abs/2601.15690v1",
    "published_date": "2026-01-22T06:21:31",
    "categories": [
      "cs.AI",
      "stat.AP"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15688",
    "title": "Performance-guided Reinforced Active Learning for Object Detection",
    "authors": [
      "Zhixuan Liang",
      "Xingyu Zeng",
      "Rui Zhao",
      "Ping Luo"
    ],
    "affiliations": [],
    "summary": "Active learning (AL) strategies aim to train high-performance models with minimal labeling efforts, only selecting the most informative instances for annotation. Current approaches to evaluating data informativeness predominantly focus on the data's distribution or intrinsic information content and do not directly correlate with downstream task performance, such as mean average precision (mAP) in object detection. Thus, we propose Performance-guided (i.e. mAP-guided) Reinforced Active Learning for Object Detection (MGRAL), a novel approach that leverages the concept of expected model output changes as informativeness. To address the combinatorial explosion challenge of batch sample selection and the non-differentiable correlation between model performance and selected batches, MGRAL skillfully employs a reinforcement learning-based sampling agent that optimizes selection using policy gradient with mAP improvement as reward. Moreover, to reduce the computational overhead of mAP estimation with unlabeled samples, MGRAL utilizes an unsupervised way with fast look-up tables, ensuring feasible deployment. We evaluate MGRAL's active learning performance on detection tasks over PASCAL VOC and COCO benchmarks. Our approach demonstrates the highest AL curve with convincing visualizations, establishing a new paradigm in reinforcement learning-driven active object detection.",
    "link": "http://arxiv.org/abs/2601.15688v1",
    "published_date": "2026-01-22T06:17:08",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15687",
    "title": "FARM: Field-Aware Resolution Model for Intelligent Trigger-Action Automation",
    "authors": [
      "Khusrav Badalov",
      "Young Yoon"
    ],
    "affiliations": [],
    "summary": "Trigger-Action Programming (TAP) platforms such as IFTTT and Zapier enable Web of Things (WoT) automation by composing event-driven rules across heterogeneous services. A TAP applet links a trigger to an action and must bind trigger outputs (ingredients) to action inputs (fields) to be executable. Prior work largely treats TAP as service-level prediction from natural language, which often yields non-executable applets that still require manual configuration. We study the function-level configuration problem: generating complete applets with correct ingredient-to-field bindings. We propose FARM (Field-Aware Resolution Model), a two-stage architecture for automated applet generation with full configuration. Stage 1 trains contrastive dual encoders with selective layer freezing over schema-enriched representations, retrieving candidates from 1,724 trigger functions and 1,287 action functions (2.2M possible trigger-action pairs). Stage 2 performs selection and configuration using an LLM-based multi-agent pipeline. It includes intent analysis, trigger selection, action selection via cross-schema scoring, and configuration verification. Agents coordinate through shared state and agreement-based selection. FARM achieves 81% joint accuracy on Gold (62% Noisy, 70% One-shot) at the function level, where both trigger and action functions must match the ground truth. For comparison with service-level baselines, we map functions to their parent services and evaluate at the service level. FARM reaches 81% joint accuracy and improves over TARGE by 23 percentage points. FARM also generates ingredient-to-field bindings, producing executable automation configurations.",
    "link": "http://arxiv.org/abs/2601.15687v1",
    "published_date": "2026-01-22T06:12:18",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15686",
    "title": "Beyond Hard Writes and Rigid Preservation: Soft Recursive Least-Squares for Lifelong LLM Editing",
    "authors": [
      "Xinyu Wang",
      "Sicheng Lyu",
      "Yu Gu",
      "Jerry Huang",
      "Peng Lu",
      "Yufei Cui",
      "Xiao-Wen Chang"
    ],
    "affiliations": [],
    "summary": "Model editing updates a pre-trained LLM with new facts or rules without re-training, while preserving unrelated behavior. In real deployment, edits arrive as long streams, and existing editors often face a plasticity-stability dilemma: locate-then-edit \"hard writes\" can accumulate interference over time, while null-space-style \"hard preservation\" preserves only what is explicitly constrained, so past edits can be overwritten and unconstrained behaviors may deviate, degrading general capabilities in the many-edits regime. We propose RLSEdit, a recursive least-squares editor for long sequential editing. RLSEdit formulates editing as an online quadratic optimization with soft constraints, minimizing a cumulative key-value fitting objective with two regularizers that control for both deviation from the pre-trained weights and from a designated anchor mapping. The resulting update admits an efficient online recursion via the Woodbury identity, with per-edit cost independent of history length and scaling only with the current edit size. We further provide deviation bounds and an asymptotic characterization of the adherence-preservation trade-off in the many-edits regime. Experiments on multiple model families demonstrate stable scaling to 10K edits, outperforming strong baselines in both edit success and holistic stability -- crucially retaining early edits, and preserving general capabilities on GLUE and held-out reasoning/code benchmarks.",
    "link": "http://arxiv.org/abs/2601.15686v1",
    "published_date": "2026-01-22T06:11:44",
    "categories": [
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15681",
    "title": "Consistency-Regularized GAN for Few-Shot SAR Target Recognition",
    "authors": [
      "Yikui Zhai",
      "Shikuang Liu",
      "Wenlve Zhou",
      "Hongsheng Zhang",
      "Zhiheng Zhou",
      "Xiaolin Tian",
      "C. L. Philip Chen"
    ],
    "affiliations": [],
    "summary": "Few-shot recognition in synthetic aperture radar (SAR) imagery remains a critical bottleneck for real-world applications due to extreme data scarcity. A promising strategy involves synthesizing a large dataset with a generative adversarial network (GAN), pre-training a model via self-supervised learning (SSL), and then fine-tuning on the few labeled samples. However, this approach faces a fundamental paradox: conventional GANs themselves require abundant data for stable training, contradicting the premise of few-shot learning. To resolve this, we propose the consistency-regularized generative adversarial network (Cr-GAN), a novel framework designed to synthesize diverse, high-fidelity samples even when trained under these severe data limitations. Cr-GAN introduces a dual-branch discriminator that decouples adversarial training from representation learning. This architecture enables a channel-wise feature interpolation strategy to create novel latent features, complemented by a dual-domain cycle consistency mechanism that ensures semantic integrity. Our Cr-GAN framework is adaptable to various GAN architectures, and its synthesized data effectively boosts multiple SSL algorithms. Extensive experiments on the MSTAR and SRSDD datasets validate our approach, with Cr-GAN achieving a highly competitive accuracy of 71.21% and 51.64%, respectively, in the 8-shot setting, significantly outperforming leading baselines, while requiring only ~5 of the parameters of state-of-the-art diffusion models. Code is available at: https://github.com/yikuizhai/Cr-GAN.",
    "link": "http://arxiv.org/abs/2601.15681v1",
    "published_date": "2026-01-22T06:02:39",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15678",
    "title": "Connect the Dots: Knowledge Graph-Guided Crawler Attack on Retrieval-Augmented Generation Systems",
    "authors": [
      "Mengyu Yao",
      "Ziqi Zhang",
      "Ning Luo",
      "Shaofei Li",
      "Yifeng Cai",
      "Xiangqun Chen",
      "Yao Guo",
      "Ding Li"
    ],
    "affiliations": [],
    "summary": "Retrieval-augmented generation (RAG) systems integrate document retrieval with large language models and have been widely adopted. However, in privacy-related scenarios, RAG introduces a new privacy risk: adversaries can issue carefully crafted queries to exfiltrate sensitive content from the underlying corpus gradually. Although recent studies have demonstrated multi-turn extraction attacks, they rely on heuristics and fail to perform long-term extraction planning. To address these limitations, we formulate the RAG extraction attack as an adaptive stochastic coverage problem (ASCP). In ASCP, each query is treated as a probabilistic action that aims to maximize conditional marginal gain (CMG), enabling principled long-term planning under uncertainty. However, integrating ASCP with practical RAG attack faces three key challenges: unobservable CMG, intractability in the action space, and feasibility constraints. To overcome these challenges, we maintain a global attacker-side state to guide the attack. Building on this idea, we introduce RAGCRAWLER, which builds a knowledge graph to represent revealed information, uses this global state to estimate CMG, and plans queries in semantic space that target unretrieved regions. In comprehensive experiments across diverse RAG architectures and datasets, our proposed method, RAGCRAWLER, consistently outperforms all baselines. It achieves up to 84.4% corpus coverage within a fixed query budget and deliver an average improvement of 20.7% over the top-performing baseline. It also maintains high semantic fidelity and strong content reconstruction accuracy with low attack cost. Crucially, RAGCRAWLER proves its robustness by maintaining effectiveness against advanced RAG systems employing query rewriting and multi-query retrieval strategies. Our work reveals significant security gaps and highlights the pressing need for stronger safeguards for RAG.",
    "link": "http://arxiv.org/abs/2601.15678v1",
    "published_date": "2026-01-22T05:59:42",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15676",
    "title": "Bridging the Perception Gap: A Lightweight Coarse-to-Fine Architecture for Edge Audio Systems",
    "authors": [
      "Hengfan Zhang",
      "Yueqian Lin",
      "Hai Helen Li",
      "Yiran Chen"
    ],
    "affiliations": [],
    "summary": "Deploying Audio-Language Models (Audio-LLMs) on edge infrastructure exposes a persistent tension between perception depth and computational efficiency. Lightweight local models tend to produce passive perception - generic summaries that miss the subtle evidence required for multi-step audio reasoning - while indiscriminate cloud offloading incurs unacceptable latency, bandwidth cost, and privacy risk. We propose CoFi-Agent (Tool-Augmented Coarse-to-Fine Agent), a hybrid architecture targeting edge servers and gateways. It performs fast local perception and triggers conditional forensic refinement only when uncertainty is detected. CoFi-Agent runs an initial single-pass on a local 7B Audio-LLM, then a cloud controller gates difficult cases and issues lightweight plans for on-device tools such as temporal re-listening and local ASR. On the MMAR benchmark, CoFi-Agent improves accuracy from 27.20% to 53.60%, while achieving a better accuracy-efficiency trade-off than an always-on investigation pipeline. Overall, CoFi-Agent bridges the perception gap via tool-enabled, conditional edge-cloud collaboration under practical system constraints.",
    "link": "http://arxiv.org/abs/2601.15676v1",
    "published_date": "2026-01-22T05:57:25",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15674",
    "title": "What Patients Really Ask: Exploring the Effect of False Assumptions in Patient Information Seeking",
    "authors": [
      "Raymond Xiong",
      "Furong Jia",
      "Lionel Wong",
      "Monica Agrawal"
    ],
    "affiliations": [],
    "summary": "Patients are increasingly using large language models (LLMs) to seek answers to their healthcare-related questions. However, benchmarking efforts in LLMs for question answering often focus on medical exam questions, which differ significantly in style and content from the questions patients actually raise in real life. To bridge this gap, we sourced data from Google's People Also Ask feature by querying the top 200 prescribed medications in the United States, curating a dataset of medical questions people commonly ask. A considerable portion of the collected questions contains incorrect assumptions and dangerous intentions. We demonstrate that the emergence of these corrupted questions is not uniformly random and depends heavily on the degree of incorrectness in the history of questions that led to their appearance. Current LLMs that perform strongly on other benchmarks struggle to identify incorrect assumptions in everyday questions.",
    "link": "http://arxiv.org/abs/2601.15674v1",
    "published_date": "2026-01-22T05:56:14",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15673",
    "title": "Enhancing guidance for missing data in diffusion-based sequential recommendation",
    "authors": [
      "Qilong Yan",
      "Yifei Xing",
      "Dugang Liu",
      "Jingpu Duan",
      "Jian Yin"
    ],
    "affiliations": [],
    "summary": "Contemporary sequential recommendation methods are becoming more complex, shifting from classification to a diffusion-guided generative paradigm. However, the quality of guidance in the form of user information is often compromised by missing data in the observed sequences, leading to suboptimal generation quality. Existing methods address this by removing locally similar items, but overlook ``critical turning points'' in user interest, which are crucial for accurately predicting subsequent user intent. To address this, we propose a novel Counterfactual Attention Regulation Diffusion model (CARD), which focuses on amplifying the signal from key interest-turning-point items while concurrently identifying and suppressing noise within the user sequence. CARD consists of (1) a Dual-side Thompson Sampling method to identify sequences undergoing significant interest shift, and (2) a counterfactual attention mechanism for these sequences to quantify the importance of each item. In this manner, CARD provides the diffusion model with a high-quality guidance signal composed of dynamically re-weighted interaction vectors to enable effective generation. Experiments show our method works well on real-world data without being computationally expensive. Our code is available at https://github.com/yanqilong3321/CARD.",
    "link": "http://arxiv.org/abs/2601.15673v1",
    "published_date": "2026-01-22T05:55:21",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15669",
    "title": "Dualformer: Time-Frequency Dual Domain Learning for Long-term Time Series Forecasting",
    "authors": [
      "Jingjing Bai",
      "Yoshinobu Kawahara"
    ],
    "affiliations": [],
    "summary": "Transformer-based models, despite their promise for long-term time series forecasting (LTSF), suffer from an inherent low-pass filtering effect that limits their effectiveness. This issue arises due to undifferentiated propagation of frequency components across layers, causing a progressive attenuation of high-frequency information crucial for capturing fine-grained temporal variations. To address this limitation, we propose Dualformer, a principled dual-domain framework that rethinks frequency modeling from a layer-wise perspective. Dualformer introduces three key components: (1) a dual-branch architecture that concurrently models complementary temporal patterns in both time and frequency domains; (2) a hierarchical frequency sampling module that allocates distinct frequency bands to different layers, preserving high-frequency details in lower layers while modeling low-frequency trends in deeper layers; and (3) a periodicity-aware weighting mechanism that dynamically balances contributions from the dual branches based on the harmonic energy ratio of inputs, supported theoretically by a derived lower bound. This design enables structured frequency modeling and adaptive integration of time-frequency features, effectively preserving high-frequency information and enhancing generalization. Extensive experiments conducted on eight widely used benchmarks demonstrate Dualformer's robustness and superior performance, particularly on heterogeneous or weakly periodic data. Our code is publicly available at https://github.com/Akira-221/Dualformer.",
    "link": "http://arxiv.org/abs/2601.15669v1",
    "published_date": "2026-01-22T05:51:56",
    "categories": [
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15663",
    "title": "TempoNet: Learning Realistic Communication and Timing Patterns for Network Traffic Simulation",
    "authors": [
      "Kristen Moore",
      "Diksha Goel",
      "Cody James Christopher",
      "Zhen Wang",
      "Minjune Kim",
      "Ahmed Ibrahim",
      "Ahmad Mohsin",
      "Seyit Camtepe"
    ],
    "affiliations": [],
    "summary": "Realistic network traffic simulation is critical for evaluating intrusion detection systems, stress-testing network protocols, and constructing high-fidelity environments for cybersecurity training. While attack traffic can often be layered into training environments using red-teaming or replay methods, generating authentic benign background traffic remains a core challenge -- particularly in simulating the complex temporal and communication dynamics of real-world networks. This paper introduces TempoNet, a novel generative model that combines multi-task learning with multi-mark temporal point processes to jointly model inter-arrival times and all packet- and flow-header fields. TempoNet captures fine-grained timing patterns and higher-order correlations such as host-pair behavior and seasonal trends, addressing key limitations of GAN-, LLM-, and Bayesian-based methods that fail to reproduce structured temporal variation. TempoNet produces temporally consistent, high-fidelity traces, validated on real-world datasets. Furthermore, we show that intrusion detection models trained on TempoNet-generated background traffic perform comparably to those trained on real data, validating its utility for real-world security applications.",
    "link": "http://arxiv.org/abs/2601.15663v1",
    "published_date": "2026-01-22T05:23:19",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15655",
    "title": "Event-VStream: Event-Driven Real-Time Understanding for Long Video Streams",
    "authors": [
      "Zhenghui Guo",
      "Yuanbin Man",
      "Junyuan Sheng",
      "Bowen Lin",
      "Ahmed Ahmed",
      "Bo Jiang",
      "Boyuan Zhang",
      "Miao Yin",
      "Sian Jin",
      "Omprakash Gnawal",
      "Chengming Zhang"
    ],
    "affiliations": [],
    "summary": "Real-time understanding of long video streams remains challenging for multimodal large language models (VLMs) due to redundant frame processing and rapid forgetting of past context. Existing streaming systems rely on fixed-interval decoding or cache pruning, which either produce repetitive outputs or discard crucial temporal information. We introduce Event-VStream, an event-aware framework that represents continuous video as a sequence of discrete, semantically coherent events. Our system detects meaningful state transitions by integrating motion, semantic, and predictive cues, and triggers language generation only at those boundaries. Each event embedding is consolidated into a persistent memory bank, enabling long-horizon reasoning while maintaining low latency. Across OVOBench-Realtime, and long-form Ego4D evaluations, Event-VStream achieves competitive performance. It improves over a VideoLLM-Online-8B baseline by +10.4 points on OVOBench-Realtime, achieves performance close to Flash-VStream-7B despite using only a general-purpose LLaMA-3-8B text backbone, and maintains around 70% GPT-5 win rate on 2-hour Ego4D streams.",
    "link": "http://arxiv.org/abs/2601.15655v1",
    "published_date": "2026-01-22T05:05:53",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15652",
    "title": "Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models",
    "authors": [
      "Manish Bhatt"
    ],
    "affiliations": [],
    "summary": "Hallucinations in Large Language Models (LLMs) -- generations that are plausible but factually unfaithful -- remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims).\n  Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises (\"Sycophancy\").\n  This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.",
    "link": "http://arxiv.org/abs/2601.15652v1",
    "published_date": "2026-01-22T05:00:21",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.ET"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15645",
    "title": "Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation",
    "authors": [
      "Zhiyao Ren",
      "Yibing Zhan",
      "Siyuan Liang",
      "Guozheng Ma",
      "Baosheng Yu",
      "Dacheng Tao"
    ],
    "affiliations": [],
    "summary": "Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accumulates during real consultations, which limits their support for reliable decision-making. We propose the first benchmark for assessing confidence in multi-turn interaction during realistic medical consultations. Our benchmark unifies three types of medical data for open-ended diagnostic generation and introduces an information sufficiency gradient to characterize the confidence-correctness dynamics as evidence increases. We implement and compare 27 representative methods on this benchmark; two key insights emerge: (1) medical data amplifies the inherent limitations of token-level and consistency-level confidence methods, and (2) medical reasoning must be evaluated for both diagnostic accuracy and information completeness. Based on these insights, we present MedConf, an evidence-grounded linguistic self-assessment framework that constructs symptom profiles via retrieval-augmented generation, aligns patient information with supporting, missing, and contradictory relations, and aggregates them into an interpretable confidence estimate through weighted integration. Across two LLMs and three medical datasets, MedConf consistently outperforms state-of-the-art methods on both AUROC and Pearson correlation coefficient metrics, maintaining stable performance under conditions of information insufficiency and multimorbidity. These results demonstrate that information adequacy is a key determinant of credible medical confidence modeling, providing a new pathway toward building more reliable and interpretable large medical models.",
    "link": "http://arxiv.org/abs/2601.15645v1",
    "published_date": "2026-01-22T04:51:39",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15628",
    "title": "CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models",
    "authors": [
      "Haibo Tong",
      "Zeyang Yue",
      "Feifei Zhao",
      "Erliang Lin",
      "Lu Jia",
      "Ruolin Chen",
      "Yinqian Sun",
      "Qian Zhang",
      "Yi Zeng"
    ],
    "affiliations": [],
    "summary": "Whether Large Language Models (LLMs) truly possess human-like Theory of Mind (ToM) capabilities has garnered increasing attention. However, existing benchmarks remain largely restricted to narrow paradigms like false belief tasks, failing to capture the full spectrum of human cognitive mechanisms. We introduce CogToM, a comprehensive, theoretically grounded benchmark comprising over 8000 bilingual instances across 46 paradigms, validated by 49 human annotator.A systematic evaluation of 22 representative models, including frontier models like GPT-5.1 and Qwen3-Max, reveals significant performance heterogeneities and highlights persistent bottlenecks in specific dimensions. Further analysis based on human cognitive patterns suggests potential divergences between LLM and human cognitive structures. CogToM offers a robust instrument and perspective for investigating the evolving cognitive boundaries of LLMs.",
    "link": "http://arxiv.org/abs/2601.15628v1",
    "published_date": "2026-01-22T03:59:19",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15625",
    "title": "Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors",
    "authors": [
      "Zhiwei Zhang",
      "Fei Zhao",
      "Rui Wang",
      "Zezhong Wang",
      "Bin Liang",
      "Jiakang Wang",
      "Yao Hu",
      "Shaosheng Cao",
      "Kam-Fai Wong"
    ],
    "affiliations": [],
    "summary": "Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution: following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO, a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator, then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.",
    "link": "http://arxiv.org/abs/2601.15625v1",
    "published_date": "2026-01-22T03:57:35",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15624",
    "title": "Explainable Deepfake Detection with RL Enhanced Self-Blended Images",
    "authors": [
      "Ning Jiang",
      "Dingheng Zeng",
      "Yanhong Liu",
      "Haiyang Yi",
      "Shijie Yu",
      "Minghe Weng",
      "Haifeng Shen",
      "Ying Li"
    ],
    "affiliations": [],
    "summary": "Most prior deepfake detection methods lack explainable outputs. With the growing interest in multimodal large language models (MLLMs), researchers have started exploring their use in interpretable deepfake detection. However, a major obstacle in applying MLLMs to this task is the scarcity of high-quality datasets with detailed forgery attribution annotations, as textual annotation is both costly and challenging - particularly for high-fidelity forged images or videos. Moreover, multiple studies have shown that reinforcement learning (RL) can substantially enhance performance in visual tasks, especially in improving cross-domain generalization. To facilitate the adoption of mainstream MLLM frameworks in deepfake detection with reduced annotation cost, and to investigate the potential of RL in this context, we propose an automated Chain-of-Thought (CoT) data generation framework based on Self-Blended Images, along with an RL-enhanced deepfake detection framework. Extensive experiments validate the effectiveness of our CoT data construction pipeline, tailored reward mechanism, and feedback-driven synthetic data generation approach. Our method achieves performance competitive with state-of-the-art (SOTA) approaches across multiple cross-dataset benchmarks. Implementation details are available at https://github.com/deon1219/rlsbi.",
    "link": "http://arxiv.org/abs/2601.15624v1",
    "published_date": "2026-01-22T03:55:46",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15609",
    "title": "When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL with Verifiable Rewards",
    "authors": [
      "Mingyuan Fan",
      "Weiguang Han",
      "Daixin Wang",
      "Cen Chen",
      "Zhiqiang Zhang",
      "Jun Zhou"
    ],
    "affiliations": [],
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is a central paradigm for turning large language models (LLMs) into reliable problem solvers, especially in logic-heavy domains. Despite its empirical success, it remains unclear whether RLVR elicits novel capabilities or merely sharpens the distribution over existing knowledge. We study this by formalizing over-sharpening, a phenomenon where the policy collapses onto limited modes, suppressing valid alternatives. At a high level, we discover finite-batch updates intrinsically bias learning toward sampled modes, triggering a collapse that propagates globally via semantic coupling. To mitigate this, we propose inverse-success advantage calibration to prioritize difficult queries and distribution-level calibration to diversify sampling via a memory network. Empirical evaluations validate that our strategies can effectively improve generalization.",
    "link": "http://arxiv.org/abs/2601.15609v1",
    "published_date": "2026-01-22T03:15:57",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15605",
    "title": "ToxiTwitch: Toward Emote-Aware Hybrid Moderation for Live Streaming Platforms",
    "authors": [
      "Baktash Ansari",
      "Shiza Ali",
      "Elias Martin",
      "Maryna Sivachenko",
      "Afra Mashhadi"
    ],
    "affiliations": [],
    "summary": "The rapid growth of live-streaming platforms such as Twitch has introduced complex challenges in moderating toxic behavior. Traditional moderation approaches, such as human annotation and keyword-based filtering, have demonstrated utility, but human moderators on Twitch constantly struggle to scale effectively in the fast-paced, high-volume, and context-rich chat environment of the platform while also facing harassment themselves. Recent advances in large language models (LLMs), such as DeepSeek-R1-Distill and Llama-3-8B-Instruct, offer new opportunities for toxicity detection, especially in understanding nuanced, multimodal communication involving emotes. In this work, we present an exploratory comparison of toxicity detection approaches tailored to Twitch. Our analysis reveals that incorporating emotes improves the detection of toxic behavior. To this end, we introduce ToxiTwitch, a hybrid model that combines LLM-generated embeddings of text and emotes with traditional machine learning classifiers, including Random Forest and SVM. In our case study, the proposed hybrid approach reaches up to 80 percent accuracy under channel-specific training (with 13 percent improvement over BERT and F1-score of 76 percent). This work is an exploratory study intended to surface challenges and limits of emote-aware toxicity detection on Twitch.",
    "link": "http://arxiv.org/abs/2601.15605v1",
    "published_date": "2026-01-22T03:12:17",
    "categories": [
      "cs.CL",
      "cs.SI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15599",
    "title": "Autonomous Business System via Neuro-symbolic AI",
    "authors": [
      "Cecil Pang",
      "Hiroki Sayama"
    ],
    "affiliations": [],
    "summary": "Current business environments require organizations to continuously reconfigure cross-functional processes, yet enterprise systems are still organized around siloed departments, rigid workflows, and hard-coded automation. Meanwhile large language models (LLMs) excel at interpreting natural language and unstructured data but lack deterministic, verifiable execution of complex business logic. To address this gap, here we introduce AUTOBUS, an Autonomous Business System that integrates LLM-based AI agents, predicate-logic programming, and business-semantics-centric enterprise data into a coherent neuro-symbolic AI architecture for orchestrating end-to-end business initiatives. AUTOBUS models an initiative as a network of tasks with explicit pre/post conditions, required data, evaluation rules, and API-level actions. Enterprise data is organized as a knowledge graph whose entities, relationships, and constraints are translated into logic facts and foundational rules, providing the semantic grounding for task reasoning. Core AI agents synthesize task instructions, enterprise semantics, and available tools into task-specific logic programs, which are executed by a logic engine that enforces constraints, coordinates auxiliary tools, and orchestrate execution of actions and outcomes. Humans define and maintain the semantics, policies and task instructions, curate tools, and supervise high-impact or ambiguous decisions, ensuring accountability and adaptability. We detail the AUTOBUS architecture, the anatomy of the AI agent generated logic programs, and the role of humans and auxiliary tools in the lifecycle of a business initiative.",
    "link": "http://arxiv.org/abs/2601.15599v1",
    "published_date": "2026-01-22T02:49:06",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15597",
    "title": "Neural Nonlinear Shrinkage of Covariance Matrices for Minimum Variance Portfolio Optimization",
    "authors": [
      "Liusha Yang",
      "Siqi Zhao",
      "Shuqi Chai"
    ],
    "affiliations": [],
    "summary": "This paper introduces a neural network-based nonlinear shrinkage estimator of covariance matrices for the purpose of minimum variance portfolio optimization. It is a hybrid approach that integrates statistical estimation with machine learning. Starting from the Ledoit-Wolf (LW) shrinkage estimator, we decompose the LW covariance matrix into its eigenvalues and eigenvectors, and apply a lightweight transformer-based neural network to learn a nonlinear eigenvalue shrinkage function. Trained with portfolio risk as the loss function, the resulting precision matrix (the inverse covariance matrix) estimator directly targets portfolio risk minimization. By conditioning on the sample-to-dimension ratio, the approach remains scalable across different sample sizes and asset universes. Empirical results on stock daily returns from Standard & Poor's 500 Index (S&P500) demonstrate that the proposed method consistently achieves lower out-of-sample realized risk than benchmark approaches. This highlights the promise of integrating structural statistical models with data-driven learning.",
    "link": "http://arxiv.org/abs/2601.15597v1",
    "published_date": "2026-01-22T02:44:33",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15596",
    "title": "DeepASMR: LLM-Based Zero-Shot ASMR Speech Generation for Anyone of Any Voice",
    "authors": [
      "Leying Zhang",
      "Tingxiao Zhou",
      "Haiyang Sun",
      "Mengxiao Bi",
      "Yanmin Qian"
    ],
    "affiliations": [],
    "summary": "While modern Text-to-Speech (TTS) systems achieve high fidelity for read-style speech, they struggle to generate Autonomous Sensory Meridian Response (ASMR), a specialized, low-intensity speech style essential for relaxation. The inherent challenges include ASMR's subtle, often unvoiced characteristics and the demand for zero-shot speaker adaptation. In this paper, we introduce DeepASMR, the first framework designed for zero-shot ASMR generation. We demonstrate that a single short snippet of a speaker's ordinary, read-style speech is sufficient to synthesize high-fidelity ASMR in their voice, eliminating the need for whispered training data from the target speaker. Methodologically, we first identify that discrete speech tokens provide a soft factorization of ASMR style from speaker timbre. Leveraging this insight, we propose a two-stage pipeline incorporating a Large Language Model (LLM) for content-style encoding and a flow-matching acoustic decoder for timbre reconstruction. Furthermore, we contribute DeepASMR-DB, a comprehensive 670-hour English-Chinese multi-speaker ASMR speech corpus, and introduce a novel evaluation protocol integrating objective metrics, human listening tests, LLM-based scoring and unvoiced speech analysis. Extensive experiments confirm that DeepASMR achieves state-of-the-art naturalness and style fidelity in ASMR generation for anyone of any voice, while maintaining competitive performance on normal speech synthesis.",
    "link": "http://arxiv.org/abs/2601.15596v1",
    "published_date": "2026-01-22T02:44:22",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15595",
    "title": "Data-Free Privacy-Preserving for LLMs via Model Inversion and Selective Unlearning",
    "authors": [
      "Xinjie Zhou",
      "Zhihui Yang",
      "Lechao Cheng",
      "Sai Wu",
      "Gang Chen"
    ],
    "affiliations": [],
    "summary": "Large language models (LLMs) exhibit powerful capabilities but risk memorizing sensitive personally identifiable information (PII) from their training data, posing significant privacy concerns. While machine unlearning techniques aim to remove such data, they predominantly depend on access to the training data. This requirement is often impractical, as training data in real-world deployments is commonly proprietary or inaccessible. To address this limitation, we propose Data-Free Selective Unlearning (DFSU), a novel privacy-preserving framework that removes sensitive PII from an LLM without requiring its training data. Our approach first synthesizes pseudo-PII through language model inversion, then constructs token-level privacy masks for these synthetic samples, and finally performs token-level selective unlearning via a contrastive mask loss within a low-rank adaptation (LoRA) subspace. Extensive experiments on the AI4Privacy PII-Masking dataset using Pythia models demonstrate that our method effectively removes target PII while maintaining model utility.",
    "link": "http://arxiv.org/abs/2601.15595v1",
    "published_date": "2026-01-22T02:43:12",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15593",
    "title": "Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow",
    "authors": [
      "Yangyang Zhong",
      "Yanmei Gu",
      "Zhengqing Zang",
      "Xiaomeng Li",
      "Yuqi Ding",
      "Xibei Jia",
      "Yuting Shen",
      "Zhenzhong Lan",
      "Liwang Zhu",
      "Weiping Liu",
      "Junlin Zhou",
      "Haisheng Liu",
      "Zhong Xin Yu",
      "Pengxin Luo",
      "Donglian Qi",
      "Yunfeng Yan",
      "Junbo Zhao"
    ],
    "affiliations": [],
    "summary": "Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100B parameters) on 58 benchmarks spanning knowledge, reasoning, and programming. The results show that MDLMs still lag behind comparably sized autoregressive models, mainly because parallel probabilistic modeling weakens inter-token dependencies. Meanwhile, MDLMs exhibit adaptive decoding behavior: their parallelism and generation order vary significantly with the task domain, the stage of reasoning, and whether the output is correct. On tasks that require \"backward information\" (e.g., Sudoku), MDLMs adopt a solution order that tends to fill easier Sudoku blanks first, highlighting their advantages. Finally, we provide theoretical motivation and design insights supporting a Generate-then-Edit paradigm, which mitigates dependency loss while retaining the efficiency of parallel decoding.",
    "link": "http://arxiv.org/abs/2601.15593v1",
    "published_date": "2026-01-22T02:39:36",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15589",
    "title": "Deep Learning for Perishable Inventory Systems with Human Knowledge",
    "authors": [
      "Xuan Liao",
      "Zhenkang Peng",
      "Ying Rong"
    ],
    "affiliations": [],
    "summary": "Managing perishable products with limited lifetimes is a fundamental challenge in inventory management, as poor ordering decisions can quickly lead to stockouts or excessive waste. We study a perishable inventory system with random lead times in which both the demand process and the lead time distribution are unknown. We consider a practical setting where orders are placed using limited historical data together with observed covariates and current system states. To improve learning efficiency under limited data, we adopt a marginal cost accounting scheme that assigns each order a single lifetime cost and yields a unified loss function for end-to-end learning. This enables training a deep learning-based policy that maps observed covariates and system states directly to order quantities. We develop two end-to-end variants: a purely black-box approach that outputs order quantities directly (E2E-BB), and a structure-guided approach that embeds the projected inventory level (PIL) policy, capturing inventory effects through explicit computation rather than additional learning (E2E-PIL). We further show that the objective induced by E2E-PIL is homogeneous of degree one, enabling a boosting technique from operational data analytics (ODA) that yields an enhanced policy (E2E-BPIL). Experiments on synthetic and real data establish a robust performance ordering: E2E-BB is dominated by E2E-PIL, which is further improved by E2E-BPIL. Using an excess-risk decomposition, we show that embedding heuristic policy structure reduces effective model complexity and improves learning efficiency with only a modest loss of flexibility. More broadly, our results suggest that deep learning-based decision tools are more effective and robust when guided by human knowledge, highlighting the value of integrating advanced analytics with inventory theory.",
    "link": "http://arxiv.org/abs/2601.15589v1",
    "published_date": "2026-01-22T02:26:32",
    "categories": [
      "cs.LG"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15588",
    "title": "YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models",
    "authors": [
      "Junyu Lin",
      "Meizhen Liu",
      "Xiufeng Huang",
      "Jinfeng Li",
      "Haiwen Hong",
      "Xiaohan Yuan",
      "Yuefeng Chen",
      "Longtao Huang",
      "Hui Xue",
      "Ranjie Duan",
      "Zhikai Chen",
      "Yuchuan Fu",
      "Defeng Li",
      "Lingyao Gao",
      "Yitong Yang"
    ],
    "affiliations": [],
    "summary": "As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or post-hoc rules, resulting in limited transparency, inflexible policies, or prohibitive inference costs. To this end, we present YuFeng-XGuard, a reasoning-centric guardrail model family designed to perform multi-dimensional risk perception for LLM interactions. Instead of producing opaque binary judgments, YuFeng-XGuard generates structured risk predictions, including explicit risk categories and configurable confidence scores, accompanied by natural language explanations that expose the underlying reasoning process. This formulation enables safety decisions that are both actionable and interpretable. To balance decision latency and explanatory depth, we adopt a tiered inference paradigm that performs an initial risk decision based on the first decoded token, while preserving ondemand explanatory reasoning when required. In addition, we introduce a dynamic policy mechanism that decouples risk perception from policy enforcement, allowing safety policies to be adjusted without model retraining. Extensive experiments on a diverse set of public safety benchmarks demonstrate that YuFeng-XGuard achieves stateof-the-art performance while maintaining strong efficiency-efficacy trade-offs. We release YuFeng-XGuard as an open model family, including both a full-capacity variant and a lightweight version, to support a wide range of deployment scenarios.",
    "link": "http://arxiv.org/abs/2601.15588v1",
    "published_date": "2026-01-22T02:23:18",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15578",
    "title": "MapViT: A Two-Stage ViT-Based Framework for Real-Time Radio Quality Map Prediction in Dynamic Environments",
    "authors": [
      "Cyril Shih-Huan Hsu",
      "Xi Li",
      "Lanfranco Zanzi",
      "Zhiheng Yang",
      "Chrysa Papagianni",
      "Xavier Costa Pérez"
    ],
    "affiliations": [],
    "summary": "Recent advancements in mobile and wireless networks are unlocking the full potential of robotic autonomy, enabling robots to take advantage of ultra-low latency, high data throughput, and ubiquitous connectivity. However, for robots to navigate and operate seamlessly, efficiently and reliably, they must have an accurate understanding of both their surrounding environment and the quality of radio signals. Achieving this in highly dynamic and ever-changing environments remains a challenging and largely unsolved problem. In this paper, we introduce MapViT, a two-stage Vision Transformer (ViT)-based framework inspired by the success of pre-train and fine-tune paradigm for Large Language Models (LLMs). MapViT is designed to predict both environmental changes and expected radio signal quality. We evaluate the framework using a set of representative Machine Learning (ML) models, analyzing their respective strengths and limitations across different scenarios. Experimental results demonstrate that the proposed two-stage pipeline enables real-time prediction, with the ViT-based implementation achieving a strong balance between accuracy and computational efficiency. This makes MapViT a promising solution for energy- and resource-constrained platforms such as mobile robots. Moreover, the geometry foundation model derived from the self-supervised pre-training stage improves data efficiency and transferability, enabling effective downstream predictions even with limited labeled data. Overall, this work lays the foundation for next-generation digital twin ecosystems, and it paves the way for a new class of ML foundation models driving multi-modal intelligence in future 6G-enabled systems.",
    "link": "http://arxiv.org/abs/2601.15578v1",
    "published_date": "2026-01-22T01:57:48",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15560",
    "title": "Relative Classification Accuracy: A Calibrated Metric for Identity Consistency in Fine-Grained K-pop Face Generation",
    "authors": [
      "Sylvey Lin",
      "Eranki Vasistha"
    ],
    "affiliations": [],
    "summary": "Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in high-fidelity image generation. However, evaluating their semantic controllability-specifically for fine-grained, single-domain tasks-remains challenging. Standard metrics like FID and Inception Score (IS) often fail to detect identity misalignment in such specialized contexts. In this work, we investigate Class-Conditional DDPMs for K-pop idol face generation (32x32), a domain characterized by high inter-class similarity. We propose a calibrated metric, Relative Classification Accuracy (RCA), which normalizes generative performance against an oracle classifier's baseline. Our evaluation reveals a critical trade-off: while the model achieves high visual quality (FID 8.93), it suffers from severe semantic mode collapse (RCA 0.27), particularly for visually ambiguous identities. We analyze these failure modes through confusion matrices and attribute them to resolution constraints and intra-gender ambiguity. Our framework provides a rigorous standard for verifying identity consistency in conditional generative models.",
    "link": "http://arxiv.org/abs/2601.15560v1",
    "published_date": "2026-01-22T00:58:59",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15558",
    "title": "From Generation to Collaboration: Using LLMs to Edit for Empathy in Healthcare",
    "authors": [
      "Man Luo",
      "Bahareh Harandizadeh",
      "Amara Tariq",
      "Halim Abbas",
      "Umar Ghaffar",
      "Christopher J Warren",
      "Segun O. Kolade",
      "Haidar M. Abdul-Muhsin"
    ],
    "affiliations": [],
    "summary": "Clinical empathy is essential for patient care, but physicians need continually balance emotional warmth with factual precision under the cognitive and emotional constraints of clinical practice. This study investigates how large language models (LLMs) can function as empathy editors, refining physicians' written responses to enhance empathetic tone while preserving underlying medical information. More importantly, we introduce novel quantitative metrics, an Empathy Ranking Score and a MedFactChecking Score to systematically assess both emotional and factual quality of the responses. Experimental results show that LLM edited responses significantly increase perceived empathy while preserving factual accuracy compared with fully LLM generated outputs. These findings suggest that using LLMs as editorial assistants, rather than autonomous generators, offers a safer, more effective pathway to empathetic and trustworthy AI-assisted healthcare communication.",
    "link": "http://arxiv.org/abs/2601.15558v1",
    "published_date": "2026-01-22T00:56:33",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15556",
    "title": "LLM or Human? Perceptions of Trust and Information Quality in Research Summaries",
    "authors": [
      "Nil-Jana Akpinar",
      "Sandeep Avula",
      "CJ Lee",
      "Brandon Dang",
      "Kaza Razat",
      "Vanessa Murdock"
    ],
    "affiliations": [],
    "summary": "Large Language Models (LLMs) are increasingly used to generate and edit scientific abstracts, yet their integration into academic writing raises questions about trust, quality, and disclosure. Despite growing adoption, little is known about how readers perceive LLM-generated summaries and how these perceptions influence evaluations of scientific work. This paper presents a mixed-methods survey experiment investigating whether readers with ML expertise can distinguish between human- and LLM-generated abstracts, how actual and perceived LLM involvement affects judgments of quality and trustworthiness, and what orientations readers adopt toward AI-assisted writing. Our findings show that participants struggle to reliably identify LLM-generated content, yet their beliefs about LLM involvement significantly shape their evaluations. Notably, abstracts edited by LLMs are rated more favorably than those written solely by humans or LLMs. We also identify three distinct reader orientations toward LLM-assisted writing, offering insights into evolving norms and informing policy around disclosure and acceptable use in scientific communication.",
    "link": "http://arxiv.org/abs/2601.15556v1",
    "published_date": "2026-01-22T00:53:38",
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15550",
    "title": "Common to Whom? Regional Cultural Commonsense and LLM Bias in India",
    "authors": [
      "Sangmitra Madhusudan",
      "Trush Shashank More",
      "Steph Buongiorno",
      "Renata Dividino",
      "Jad Kabbara",
      "Ali Emami"
    ],
    "affiliations": [],
    "summary": "Existing cultural commonsense benchmarks treat nations as monolithic, assuming uniform practices within national boundaries. But does cultural commonsense hold uniformly within a nation, or does it vary at the sub-national level? We introduce Indica, the first benchmark designed to test LLMs' ability to address this question, focusing on India - a nation of 28 states, 8 union territories, and 22 official languages. We collect human-annotated answers from five Indian regions (North, South, East, West, and Central) across 515 questions spanning 8 domains of everyday life, yielding 1,630 region-specific question-answer pairs. Strikingly, only 39.4% of questions elicit agreement across all five regions, demonstrating that cultural commonsense in India is predominantly regional, not national. We evaluate eight state-of-the-art LLMs and find two critical gaps: models achieve only 13.4%-20.9% accuracy on region-specific questions, and they exhibit geographic bias, over-selecting Central and North India as the \"default\" (selected 30-40% more often than expected) while under-representing East and West. Beyond India, our methodology provides a generalizable framework for evaluating cultural commonsense in any culturally heterogeneous nation, from question design grounded in anthropological taxonomy, to regional data collection, to bias measurement.",
    "link": "http://arxiv.org/abs/2601.15550v1",
    "published_date": "2026-01-22T00:44:26",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15549",
    "title": "VIOLA: Towards Video In-Context Learning with Minimal Annotations",
    "authors": [
      "Ryo Fujii",
      "Hideo Saito",
      "Ryo Hachiuma"
    ],
    "affiliations": [],
    "summary": "Generalizing Multimodal Large Language Models (MLLMs) to novel video domains is essential for real-world deployment but remains challenging due to the scarcity of labeled data. While In-Context Learning (ICL) offers a training-free adaptation path, standard methods rely on large annotated pools, which are often impractical in specialized environments like industrial or surgical settings since they require the experts' annotations. To bridge this gap, we introduce VIOLA (Video In-cOntext Learning with minimal Annotation), a label-efficient framework that synergizes minimal expert supervision with abundant unlabeled data. First, to maximize the efficiency of a strict annotation budget, we propose density-uncertainty-weighted sampling. Unlike standard diversity or uncertainty strategies that risk selecting visual outliers, our method leverages density estimation to identify samples that are simultaneously diverse, representative, and informative. Second, to utilize the remaining unlabeled data without noise propagation, we construct a hybrid pool and introduce confidence-aware retrieval and confidence-aware prompting. These mechanisms explicitly model label reliability, retrieving demonstrations based on a composite score of similarity and confidence while enabling the MLLM to adaptively distinguish between verified ground truths and noisy pseudo-labels. Extensive experiments across nine diverse benchmarks using four MLLMs demonstrate that our framework significantly outperforms various baselines in low-resource settings, achieving robust adaptation with minimal annotation costs.",
    "link": "http://arxiv.org/abs/2601.15549v1",
    "published_date": "2026-01-22T00:35:30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16108",
    "title": "Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources",
    "authors": [
      "Marzieh Adeli Shamsabad",
      "Hamed Ghodrati"
    ],
    "affiliations": [],
    "summary": "Climate disinformation has become a major challenge in today digital world, especially with the rise of misleading images and videos shared widely on social media. These false claims are often convincing and difficult to detect, which can delay actions on climate change. While vision-language models (VLMs) have been used to identify visual disinformation, they rely only on the knowledge available at the time of training. This limits their ability to reason about recent events or updates. The main goal of this paper is to overcome that limitation by combining VLMs with external knowledge. By retrieving up-to-date information such as reverse image results, online fact-checks, and trusted expert content, the system can better assess whether an image and its claim are accurate, misleading, false, or unverifiable. This approach improves the model ability to handle real-world climate disinformation and supports efforts to protect public understanding of science in a rapidly changing information landscape.",
    "link": "http://arxiv.org/abs/2601.16108v1",
    "published_date": "2026-01-22T16:55:48",
    "categories": [
      "cs.AI"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.16046",
    "title": "DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning",
    "authors": [
      "Junha Lee",
      "Eunha Park",
      "Minsu Cho"
    ],
    "affiliations": [],
    "summary": "Language-driven dexterous grasp generation requires the models to understand task semantics, 3D geometry, and complex hand-object interactions. While vision-language models have been applied to this problem, existing approaches directly map observations to grasp parameters without intermediate reasoning about physical interactions. We present DextER, Dexterous Grasp Generation with Embodied Reasoning, which introduces contact-based embodied reasoning for multi-finger manipulation. Our key insight is that predicting which hand links contact where on the object surface provides an embodiment-aware intermediate representation bridging task semantics with physical constraints. DextER autoregressively generates embodied contact tokens specifying which finger links contact where on the object surface, followed by grasp tokens encoding the hand configuration. On DexGYS, DextER achieves 67.14% success rate, outperforming state-of-the-art by 3.83%p with 96.4% improvement in intention alignment. We also demonstrate steerable generation through partial contact specification, providing fine-grained control over grasp synthesis.",
    "link": "http://arxiv.org/abs/2601.16046v1",
    "published_date": "2026-01-22T15:23:35",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15891",
    "title": "RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture",
    "authors": [
      "Anas Anwarul Haq Khan",
      "Mariam Husain",
      "Kshitij Jadhav"
    ],
    "affiliations": [],
    "summary": "Recent advances in medical vision language models guide the learning of visual representations; however, this form of supervision is constrained by the availability of paired image text data, raising the question of whether robust radiology encoders can be learned without relying on language supervision. In this work, we introduce RadJEPA, a self-supervised framework built on a Joint Embedding Predictive Architecture that learns without language supervision. Pre-trained solely on unlabeled chest X-ray images, the model learns to predict latent representations of masked image regions. This predictive objective differs fundamentally from both image text pre-training and DINO-style self-distillation: rather than aligning global representations across views or modalities, RadJEPA explicitly models latent-space prediction. We evaluate the learned encoder on disease classification, semantic segmentation, and report generation tasks. Across benchmarks, RadJEPA achieves performance exceeding state-of-the-art approaches, including Rad-DINO.",
    "link": "http://arxiv.org/abs/2601.15891v1",
    "published_date": "2026-01-22T12:11:53",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15780",
    "title": "Assessing Situational and Spatial Awareness of VLMs with Synthetically Generated Video",
    "authors": [
      "Pascal Benschop",
      "Justin Dauwels",
      "Jan van Gemert"
    ],
    "affiliations": [],
    "summary": "Spatial reasoning in vision language models (VLMs) remains fragile when semantics hinge on subtle temporal or geometric cues. We introduce a synthetic benchmark that probes two complementary skills: situational awareness (recognizing whether an interaction is harmful or benign) and spatial awareness (tracking who does what to whom, and reasoning about relative positions and motion). Through minimal video pairs, we test three challenges: distinguishing violence from benign activity, binding assailant roles across viewpoints, and judging fine-grained trajectory alignment. While we evaluate recent VLMs in a training-free setting, the benchmark is applicable to any video classification model. Results show performance only slightly above chance across tasks. A simple aid, stable color cues, partly reduces assailant role confusions but does not resolve the underlying weakness. By releasing data and code, we aim to provide reproducible diagnostics and seed exploration of lightweight spatial priors to complement large-scale pretraining.",
    "link": "http://arxiv.org/abs/2601.15780v1",
    "published_date": "2026-01-22T09:14:11",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15745",
    "title": "Hallucination Mitigating for Medical Report Generation",
    "authors": [
      "Ruoqing Zhao",
      "Runze Xia",
      "Piji Li"
    ],
    "affiliations": [],
    "summary": "In the realm of medical report generation (MRG), the integration of natural language processing has emerged as a vital tool to alleviate the workload of radiologists. Despite the impressive capabilities demonstrated by large vision language models (LVLMs) in understanding natural language, their susceptibility to generating plausible yet inaccurate claims, known as ``hallucinations'', raises concerns-especially in the nuanced and critical field of medical. In this work, we introduce a framework, \\textbf{K}nowledge-\\textbf{E}nhanced with Fine-Grained \\textbf{R}einforced Rewards \\textbf{M}edical Report Generation (KERM), to tackle the issue. Our approach refines the input to the LVLM by first utilizing MedCLIP for knowledge retrieval, incorporating relevant lesion fact sentences from a curated knowledge corpus. We then introduce a novel purification module to ensure the retrieved knowledge is contextually relevant to the patient's clinical context. Subsequently, we employ fine-grained rewards to guide these models in generating highly supportive and clinically relevant descriptions, ensuring the alignment of model's outputs with desired behaviors. Experimental results on IU-Xray and MIMIC-CXR datasets validate the effectiveness of our approach in mitigating hallucinations and enhancing report quality.",
    "link": "http://arxiv.org/abs/2601.15745v1",
    "published_date": "2026-01-22T08:13:59",
    "categories": [
      "cs.CL"
    ],
    "source": "arxiv"
  },
  {
    "id": "2601.15711",
    "title": "Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework",
    "authors": [
      "Shubham Shukla",
      "Kunal Sonalkar"
    ],
    "affiliations": [],
    "summary": "Fine-grained attribute prediction is essential for fashion retail applications including catalog enrichment, visual search, and recommendation systems. Vision-Language Models (VLMs) offer zero-shot prediction without task-specific training, yet their systematic evaluation on multi-attribute fashion tasks remains underexplored. A key challenge is that fashion attributes are often conditional. For example, \"outer fabric\" is undefined when no outer garment is visible. This requires models to detect attribute applicability before attempting classification. We introduce a three-tier evaluation framework that decomposes this challenge: (1) overall task performance across all classes (including NA class: suggesting attribute is not applicable) for all attributes, (2) attribute applicability detection, and (3) fine-grained classification when attributes are determinable. Using DeepFashion-MultiModal, which explicitly defines NA (meaning attribute doesn't exist or is not visible) within attribute label spaces, we benchmark nine VLMs spanning flagship (GPT-5, Gemini 2.5 Pro), efficient (GPT-5 Mini, Gemini 2.5 Flash), and ultra-efficient tiers (GPT-5 Nano, Gemini 2.5 Flash-Lite) against classifiers trained on pretrained Fashion-CLIP embeddings on 5,000 images across 18 attributes. Our findings reveal that: (1) zero-shot VLMs achieve 64.0% macro-F1, a threefold improvement over logistic regression on pretrained Fashion-CLIP embeddings; (2) VLMs excel at fine-grained classification (Tier 3: 70.8% F1) but struggle with applicability detection (Tier 2: 34.1% NA-F1), identifying a key bottleneck; (3) efficient models achieve over 90% of flagship performance at lower cost, offering practical deployment paths. This diagnostic framework enables practitioners to pinpoint whether errors stem from visibility detection or classification, guiding targeted improvements for production systems.",
    "link": "http://arxiv.org/abs/2601.15711v1",
    "published_date": "2026-01-22T07:33:41",
    "categories": [
      "cs.CV"
    ],
    "source": "arxiv"
  }
]